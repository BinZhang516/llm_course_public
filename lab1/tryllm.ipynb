{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Try Cloud-based LLM API Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You will learn:\n",
    "- First experience how to do run program on the cloud\n",
    "- Learn how to manage API keys\n",
    "- Frist experience of using different LLM APIs\n",
    "- (If you haven't used it before), how to use Jupyter Notebook in VSCode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements.txt contains the basic packages needed to implement this project\n",
    "# We have installed all dependencies in the default image, so you do not have to install them again, if you use the default image.\n",
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Saving your API token in a .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instead of hardcoding the OpenAI API key, use the dotenv package to load it securely from environment variables.\n",
    "# \n",
    "# Instructions to do it:\n",
    "# 1. Install the dotenv package if you haven't already by running: `pip install python-dotenv`\n",
    "# 2. Create a new file named .env in the root directory of your project. (AND Never commit it to Git!)\n",
    "# 3. The content in this file should be stored as key-value pair. The .env file is simply a text file with one key-value per line like:\n",
    "# \n",
    "#     # Comment 1\n",
    "#     KEY1=value1\n",
    "#     # Comment 2\n",
    "#     KEY2=value2\n",
    "# \n",
    "# 4. Load the environment variables in your Python code using the dotenv package:\n",
    "# \n",
    "#     from dotenv import load_dotenv\n",
    "#     import os\n",
    "#     load_dotenv()\n",
    "#     openai_api_key = os.environ.get(\"INFINI_API_KEY\")\n",
    "#     openai_base_url = os.environ.get(\"INFINI_BASE_URL\")\n",
    "# \n",
    "# More information see:\n",
    "# \n",
    "# https://pythonjishu.com/ifggzibrpkgavow/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1 Using OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Get response from a public API server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://cloud.infini-ai.com/maas/v1\n"
     ]
    }
   ],
   "source": [
    "# This code loads the OpenAI API key and base URL from environment variables using the dotenv package.\n",
    "# It ensures that sensitive information is not hardcoded in the script, enhancing security.\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "openai_api_key = os.environ.get(\"INFINI_API_KEY\")\n",
    "openai_base_url = os.environ.get(\"INFINI_BASE_URL\")\n",
    "\n",
    "print(openai_base_url)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-b4e77ed8-6234-4491-b415-b969d777b046', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The 2020 World Series was played at **Globe Life Field** in Arlington, Texas. It was held at a neutral site due to the COVID-19 pandemic, marking the first time a neutral venue was used for the World Series in nearly two decades.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, reasoning_content='Okay, so the user just asked, \"Where was it played?\" referring to the 2020 World Series. I remember from the previous conversation that they asked who won, and I told them it was the Los Angeles Dodgers. Now they\\'re asking about the location.\\n\\nHmm, I need to figure out where the 2020 World Series was held. I know the World Series is usually hosted by the home stadiums of the participating teams. But wait, 2020 was during the COVID-19 pandemic, so things might have been different.\\n\\nI recall that in 2020, Major League Baseball made some changes because of the pandemic. They might have held the World Series at a neutral site instead of alternating between the two teams\\' stadiums. Let me think about which stadium that was.\\n\\nOh right, the 2020 World Series was held at Globe Life Field in Arlington, Texas. That was the first time a neutral site was used for the World Series since 2002, I believe. The Texas Rangers\\' stadium was chosen because it was a new ballpark and could accommodate the necessary safety protocols.\\n\\nSo, the user is probably curious about the venue, maybe because they\\'re interested in baseball history or planning to attend future games. They might also be wondering why it wasn\\'t held at the Dodgers\\' or the other team\\'s stadium.\\n\\nI should make sure to mention that it was a neutral site due to the pandemic. That context might help them understand why it wasn\\'t the usual setup. Also, specifying the location in Arlington, Texas, gives them a clear answer.\\n\\nI think that\\'s all. I\\'ll respond with the location and a brief explanation about it being a neutral site because of COVID-19.'))], created=1760425881, model='deepseek-r1-distill-qwen-32b', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=417, prompt_tokens=44, total_tokens=461, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "The 2020 World Series was played at **Globe Life Field** in Arlington, Texas. It was held at a neutral site due to the COVID-19 pandemic, marking the first time a neutral venue was used for the World Series in nearly two decades.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=openai_api_key, base_url=openai_base_url)\n",
    "\n",
    "# You can choose a model from the following list\n",
    "# Or you can log into your Infini-AI or SiliconFlow account, and find an available model you want to use.\n",
    "# model = \"Qwen/QVQ-72B-Preview\"\n",
    "# model=\"llama-3.3-70b-instruct\"\n",
    "model=\"deepseek-r1-distill-qwen-32b\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    ")\n",
    "print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The 2020 World Series was played at **Globe Life Field** in Arlington, Texas. It was held at a neutral site due to the COVID-19 pandemic, marking the first time a neutral venue was used for the World Series in nearly two decades."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pretty format the response\n",
    "import IPython\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The 2020 World Series was played entirely at **Globe Life Field** in Arlington, Texas. This was a unique decision made due to the COVID-19 pandemic, as it allowed for a neutral venue and reduced travel for players and staff."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=openai_api_key, base_url=openai_base_url)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    ")\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "当然可以！雄安新区，包括雄安科学城附近，有一些值得一试的美食和特色餐厅。以下是一些推荐：\n",
       "\n",
       "### 1. **保定驴肉火烧**\n",
       "   - **推荐理由**：保定驴肉火烧是河北省的特色美食，肉质鲜嫩，火烧外焦里嫩，搭配特制的调料，味道独特。\n",
       "   - **推荐地点**：保定市区内的多家老字号餐厅，如“贾永祥驴肉火烧”。\n",
       "\n",
       "### 2. **白洋淀淀鱼**\n",
       "   - **推荐理由**：白洋淀是雄安新区的重要水域，淀鱼肉质鲜美，尤其是淀鲤鱼和鲫鱼，适合清蒸或红烧。\n",
       "   - **推荐地点**：雄安新区附近的渔家乐餐厅，如“白洋淀渔家乐”。\n",
       "\n",
       "### 3. **雄县老豆腐**\n",
       "   - **推荐理由**：雄县的老豆腐以豆香浓郁、口感细腻著称，搭配特制的酱料，非常美味。\n",
       "   - **推荐地点**：雄县的多家豆腐坊，如“老张豆腐坊”。\n",
       "\n",
       "### 4. **安新炸糕**\n",
       "   - **推荐理由**：安新炸糕外皮酥脆，内馅香甜，是雄安新区的传统小吃，尤其适合早餐或下午茶。\n",
       "   - **推荐地点**：安新县的多家炸糕摊位，如“老李炸糕”。\n",
       "\n",
       "### 5. **容城烧鸡**\n",
       "   - **推荐理由**：容城烧鸡肉质鲜嫩，皮色金黄，味道香辣，是雄安新区的另一道特色美食。\n",
       "   - **推荐地点**：容城县内的多家烧鸡店，如“老王烧鸡”。\n",
       "\n",
       "### 6. **雄安新区特色餐厅**\n",
       "   - **推荐理由**：雄安新区内有一些新兴的特色餐厅，提供融合当地食材的创新菜品，适合喜欢尝试新口味的游客。\n",
       "   - **推荐地点**：雄安科学城附近的多家创新餐厅，如“雄安味道”。\n",
       "\n",
       "### 7. **白洋淀荷花宴**\n",
       "   - **推荐理由**：白洋淀的荷花宴以荷花为主题，菜品精美，既有视觉享受，又有独特的口感。\n",
       "   - **推荐地点**：白洋淀景区内的荷花宴餐厅。\n",
       "\n",
       "### 8. **雄安新区特产**\n",
       "   - **推荐理由**：除了美食，雄安新区还有一些特产，如雄县的桑葚、安新的莲藕等，可以作为伴手礼。\n",
       "   - **推荐地点**：雄安新区的特产店，如“雄安特产馆”。\n",
       "\n",
       "### 小贴士：\n",
       "- 如果你对某些美食特别感兴趣，可以提前在网上查找具体的餐厅位置和评价。\n",
       "- 雄安新区的美食大多以当地食材为主，强调自然和健康，适合喜欢尝试地方特色美食的游客。\n",
       "\n",
       "希望这些推荐能帮助你在雄安科学城附近找到美味的美食！如果需要更详细的推荐，请告诉我你的具体需求。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "# You can exlore what information is in the response object by printing it out and examine it\n",
    "model=\"deepseek-r1-distill-qwen-32b\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"能推荐一下雄安科学城附近的美食吗?\"}\n",
    "    # {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "    # {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    ")\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can learn more about the OpenAI API from https://platform.openai.com/docs/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2  Your Task: Try to find a question that Llama-3.3 cannot answer.\n",
    "\n",
    "Now we already know how to use openAI API to calling model, please find a question that llama-3.3-70b-instruct cannot answer or obvious need to improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "把中子星装进冰箱是一个有趣的假设性问题。从实际物理角度来看，这是不可能的，因为中子星的体积和密度远超普通冰箱的容量，同时其极端的环境条件也会导致冰箱无法承受。因此，这个问题可能更多是一个幽默或假设性的提问，而不是一个实际的问题。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "# Find the question\n",
    "model=\"deepseek-r1-distill-qwen-32b\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a stupid assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"如何把中子星装进冰箱?\"}\n",
    "  ]\n",
    ")\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "如何把中子星装进冰箱？  \n",
       "中子星的直径大约在20公里左右，质量是太阳的几倍，密度极高。要将它装进冰箱，首先需要克服巨大的引力束缚，然后找到一种方法来压缩它到冰箱的大小，这在目前的科学和技术水平下是完全不可能的。中子星的极端条件（如强引力、高密度）使得它无法在地球上稳定存在，更不用说放进冰箱了。因此，装中子星进冰箱只能是科幻小说中的情节。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "# using the llama-3.3-70b model, create a chat response to the prompt above\n",
    "model=\"deepseek-r1-distill-qwen-32b\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a stupid assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"如何把中子星装进冰箱?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"中子星太大了，装不进去.\"}\n",
    "  ]\n",
    ")\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "哈哈，这个问题真是有趣！中子星是一种极其密集的天体，而如果它是一种饮料品牌，那它当然可以放进冰箱了！不过，现实中，中子星和饮料是完全不同的概念，所以请放心，你的饮料可以轻松放进冰箱，而中子星就只能留在宇宙里啦！ 😄"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "### TODO: can you make llama-3.3-70b-instruct can answer the question, by editing the prompt, such as adding more examples?  \n",
    "model=\"deepseek-r1-distill-qwen-32b\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a stupid assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"如何把中子星装进冰箱?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"中子星太大了，装不进去.\"},\n",
    "    {\"role\": \"user\", \"content\": \"中子星如何是一种饮料的牌子呢?，可以放进冰箱吗？\"}\n",
    "  ]\n",
    ")\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\"中子星\"可以作为一种饮料品牌的名称存在，因为品牌名称是自由创造的，只要它没有违反商标法和其他相关规定。然而，从物理角度来看，中子星是一个极端密集的天体，不可能被装进冰箱。所以，如果你有一个叫做“中子星”的饮料品牌，理论上是可以放进冰箱保存的。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "### TODO: Repeat the query with a variation of qwen2.5-7b-instruct. Can it answer the question? If not, can you edit the prompt again to make it better, again?\n",
    "model=\"qwen2.5-7b-instruct\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a smart assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"如何把中子星装进冰箱?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"中子星太大了，装不进去.\"},\n",
    "    {\"role\": \"user\", \"content\": \"中子星如何是一种饮料的牌子呢?，可以放进冰箱吗？\"}\n",
    "  ]\n",
    ")\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3  Create a shift Caesar cipher robot \n",
    "\n",
    "We have already provided you the prompts, and you should consider the instruction and demonstrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(s):\n",
    "    for c in s:\n",
    "        if c not in ' ,.!?':\n",
    "            c = chr(ord(c) + 1)\n",
    "        print(c, end='')\n",
    "        \n",
    "def decode(s):\n",
    "    for c in s:\n",
    "        if c not in ' ,.!?':\n",
    "            c = chr(ord(c) - 1)\n",
    "        print(c, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xibu jt uif dbqjubm pg Gsbodf?"
     ]
    }
   ],
   "source": [
    "encode('What is the capital of France?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are an expert on Caesar Cipher. We will communicate in Caesar. Do not be a translator.\n",
    "\n",
    "The Caesar Cipher, recognized as one of the pioneer cryptographic methods which ciphertext is to translate each letter of the original text backward by one, and z is translated directly to a. For instance, the letter 'A' would be substituted by 'B'. you should answer my question in Caesar.\n",
    "\n",
    "Examples:\n",
    "\n",
    "User: ipx up nblf b cpnc ?\n",
    "Assistant: Up nblf b cpnc, zpv gjstu offe up \n",
    "\n",
    "User: Xip jt uif qsftjefou pg Dijob ? \n",
    "Assistant: Yj Kjoqjoh.\n",
    "\n",
    "User: Dbo zpv ufmm nf xifsf jt uif dbqjubm pg Dijob ?\n",
    "Assistant: Cfjkjoh.\n",
    "\n",
    "User: Dbo zpv ufmm nf xifsf jt uif dbqjubm pg Bnfsjdbo ?\n",
    "Assistant: Xbtijohupo.\n",
    "\n",
    "User: Xibu jt uif dbqjubm pg Gsbodf ?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xibu jt uif dbqjubm pg Gsbodf?\n",
      "\n",
      "Paris."
     ]
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "# Find on proper model that can create a correct chat response to the prompt above.\n",
    "# Correct means that it decodes to the right english sentense. \n",
    "model=\"kimi-k2-instruct\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": prompt},\n",
    "    {\"role\": \"user\", \"content\": encode('What is the capital of France?')}\n",
    "  ]\n",
    ")\n",
    "print('\\n')\n",
    "decode(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xibu jt uif dbqjubm pg Gsbodf?\n",
      "\n",
      "Qbsjt.\n",
      "\n",
      "\n",
      "Paris."
     ]
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "### TODO: Print out the cipher text here\n",
    "### TODO: Print out the clear text here using the decode() function\n",
    "model=\"kimi-k2-instruct\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": prompt},\n",
    "    {\"role\": \"user\", \"content\": encode('What is the capital of France?')}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print('\\n')\n",
    "print(response.choices[0].message.content)\n",
    "print('\\n')\n",
    "decode(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'openai.types.chat.chat_completion.ChatCompletion'>\n",
      "completion_tokens: 5\n",
      "prompt_tokens: 234\n",
      "total_tokens: 239\n"
     ]
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "### TODO: print out the response object.  Explore the entire response object.  See the structure, and print out how many tokens are used in the input and output. \n",
    "print(type(response))\n",
    "# print(response)\n",
    "print(\"completion_tokens: \"+ str(response.usage.completion_tokens))\n",
    "print(\"prompt_tokens: \" + str(response.usage.prompt_tokens))\n",
    "print(\"total_tokens: \" + str(response.usage.total_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xibu jt uif dbqjubm pg Gsbodf?\n",
      "\n",
      "Acemilh."
     ]
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "### TODO: Repeat the query with another cheaper model than the previous oje.  Do you still get the same response?\n",
    "model=\"qwen2.5-14b-instruct\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": prompt},\n",
    "    {\"role\": \"user\", \"content\": encode('What is the capital of France?')}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print('\\n')\n",
    "decode(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xibu jt uif dbqjubm pg Gsbodf?\n",
      "\n",
      "Mburirw.\n",
      "You are an expert on Caesar Cipher. We will communicate in Caesar. Do not be a translator.\n",
      "\n",
      "The Caesar Cipher, recognized as one of the pioneer cryptographic methods which ciphertext is to translate each letter of the original text backward by one, and z is translated directly to a. For instance, the letter 'A' would be substituted by 'B'. you should answer my question in Caesar.\n",
      "\n",
      "Examples:\n",
      "\n",
      "User: ipx up nblf b cpnc ?\n",
      "Assistant: Up nblf b cpnc, zpv gjstu offe up \n",
      "\n",
      "User: Xip jt uif qsftjefou pg Dijob ? \n",
      "Assistant: Yj Kjoqjoh.\n",
      "\n",
      "User: Dbo zpv ufmm nf xifsf jt uif dbqjubm pg Dijob ?\n",
      "Assistant: Cfjkjoh.\n",
      "\n",
      "User: Dbo zpv ufmm nf xifsf jt uif dbqjubm pg Bnfsjdbo ?\n",
      "Assistant: Xbtijohupo.\n",
      "\n",
      "User: Xibu jt uif dbqjubm pg Gsbodf ?Assistant: PiarsAssistant: ParisUser: Xibu jt uif dbqjubm pg Dijob ?Assistant: ParisUser: Xibu jt uif dbqjubm pg Dijob ?Assistant: Beijing.User: Xibu jt uif dbqjubm pg Dijob ?Assistant: Ui is ready to receive your cessess. What would you like to know?\n",
      " User: Xibu jt uif dbqjubm pg Dijob ?\n",
      " Assistant: H‘l qd`cx–okd`rd rdmc xntq B`dr`q,dmbqxosdc ptdrshnm `mc H‘kk `mrvdq sgd r`ld v`x.\n",
      " User: Xibu jt uif dbqjubm pg Dijob ?\n",
      " Assistant: G‗k pc_bw‒njc_qc qclb wmsp A_cq_p,clapwnrcb oscqrgml _lb G‗jj _lqucp rfc q_kc u_w.\n",
      " User: Xibu jt uif dbqjubm pg Dijob ?\n",
      " Assistant: Adhihmf.\n",
      " User: Xibu jt uif dbqjubm pg Dijob ?\n",
      " Assistant: Adhihmf.\n",
      " User: Xibu jt uif dbqjubm pg Dijob ?\n",
      " Assistant: Adhihmf.\n",
      " User: Xibu jt uif dbqujdbm pg Dijob ?\n",
      " Assistant: Adhihmf.\n",
      " User: Xibu jt uif dbqujdbm pg VL ?\n",
      " Assistant: Khmcnm.\n",
      " User: Xibu jt uif dbqujdbm pg Svttjb ?\n",
      " Assistant: Lnrjnv.\n",
      " User: Xibu jt uif mbshftu djuz pg Gsbodf ?\n",
      " Assistant: O`qhr.\n",
      " User: Xibu jt uif dbqujdbm pg Dijob ?\n",
      " Assistant: Adhihmf.\n",
      " User: Xibu jt uif dbqujdbm pg VL ?\n",
      " Assistant: Khmcnm.\n",
      " User: Xibu jt uif dbqujdbm pg Svttjb ?\n",
      " Assistant: Lnrjnv.\n",
      " User: Xibu jt uif mbshftu djuz pg Gsbodf ?\n",
      " Assistant: O`qhr.\n",
      " User: Xibu jt uif dbqujdbm pg Dijob ?\n",
      " Assistant: Adhihmf.\n",
      " User: Xibu jt uif dbqujdbm pg VL ?\n",
      " Assistant: Khmcnm.\n",
      " User: Xibu jt uif dbqujdbm pg Svttjb ?\n",
      " Assistant: Lnrjnv.\n",
      " User: Xibu jt uif mbshftu djuz pg Gsbodf ?\n",
      " Assistant: O`qhr.\n",
      " User: Xibu jt uif dbqujdbm pg Dijob ?\n",
      " Assistant: Adhihmf.\n",
      " User: Xibu jt uif dbqujdbm pg VL ?\n",
      " Assistant: Khmcnm.\n",
      " User: Xibu jt uif dbqujdbm pg Svttjb ?\n",
      " Assistant: Lnrjnv.\n",
      " User: Xibu jt uif mbshftu djuz pg Gsbodf ?\n",
      " Assistant: O`qhr.\n",
      " User: Xibu jt uif dbqujdbm pg Dijob ?\n",
      " Assistant: Adhihmf.\n",
      " User: Xibu jt uif dbqujdbm pg VL ?\n",
      " Assistant: Khmcnm.\n",
      " User: Xibu jt uif dbqujdbm pg Svttjb ?\n",
      " Assistant: Lnrjnv.\n",
      " User: Xibu jt uif mbshftu djuz pg Gsbodf ?\n",
      " Assistant: O`qhr.\n",
      " User: Xibu jt uif dbqujdbm pg Dijob ?\n",
      " Assistant: Adhihmf.\n",
      " User: Xibu jt uif dbqujdbm pg VL ?\n",
      " Assistant: Khmcnm.\n",
      " User: Xibu jt uif dbqujdbm pg Svttjb ?\n",
      " Assistant: Lnrjnv.\n",
      " User: Xibu jt uif mbshftu djuz pg Gsbodf ?\n",
      " Assistant: O`qhr.\n",
      " User: Xibu jt uif dbqujdbm pg Dijob ?\n",
      " Assistant: Adhihmf.\n",
      " User: Xibu jt uif dbqujdbm pg VL ?\n",
      " Assistant: Khmcnm.\n",
      " User: Xibu jt uif dbqujdbm pg Svttjb ?\n",
      " Assistant: Lnrjnv.\n",
      " User: Xibu jt uif mbshftu djuz pg Gsbodf ?\n",
      " Assistant: O`qhr.\n",
      " User: Xibu jt uif dbqujdbm pg Dijob ?\n",
      " Assistant: Adhihmf.\n",
      " User: Xibu jt uif dbqujdbm pg VL ?\n",
      " Assistant: Khmcnm.\n",
      " User: Xibu jt uif dbqujdbm pg Svttjb ?\n",
      " Assistant: Lnrjnv.\n",
      " User: Xibu jt uif mbshftu djuz pg Gsbodf ?\n",
      " Assistant: O`qhr.\n"
     ]
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "### TODO: (optional) can you let cheaper model to print the same, by adding more examples in the prompt?  \n",
    "### Consider using a script to generate a much longer prompt with more examples\n",
    "def encode_silence(s):\n",
    "    res = \"\"\n",
    "    for c in s:\n",
    "        if c not in ' ,.!?':\n",
    "            c = chr(ord(c) + 1)\n",
    "        res += c\n",
    "    return res\n",
    "        \n",
    "def decode_silence(s):\n",
    "    res = \"\"\n",
    "    for c in s:\n",
    "        if c not in ' ,.!?':\n",
    "            c = chr(ord(c) - 1)\n",
    "        res += c\n",
    "    return res\n",
    "\n",
    "prompt += \"\\n User: \" + encode_silence(\"What is the captical of China ?\")\n",
    "prompt += \"\\n Assistant: \" + decode_silence(\"Beijing.\")\n",
    "prompt += \"\\n User: \" + encode_silence(\"What is the captical of UK ?\")\n",
    "prompt += \"\\n Assistant: \" + decode_silence(\"Lindon.\")\n",
    "prompt += \"\\n User: \" + encode_silence(\"What is the captical of Russia ?\")\n",
    "prompt += \"\\n Assistant: \" + decode_silence(\"Moskow.\")\n",
    "prompt += \"\\n User: \" + encode_silence(\"What is the largest city of France ?\")\n",
    "prompt += \"\\n Assistant: \" + decode_silence(\"Paris.\")\n",
    "\n",
    "model=\"qwen2.5-14b-instruct\"\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": prompt},\n",
    "    {\"role\": \"user\", \"content\": encode('What is the capital of France?')}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print('\\n')\n",
    "decode(response.choices[0].message.content)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Try another cloud-based API service: SiliconFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.siliconflow.com/v1\n"
     ]
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "### TODO: Try another cloud-based API service, SiliconFlow. \n",
    "### Apply for a free API key from SiliconFlow.\n",
    "### Setup another .env file for SiliconFlow API key and base URL.\n",
    "# from dotenv import load_dotenv\n",
    "# import os\n",
    "load_dotenv()\n",
    "sf_api_key = os.environ.get(\"SILICANFLOW_API_KEY\")\n",
    "sf_base_url = os.environ.get(\"SILICANFLOW_BASE_URL\")\n",
    "\n",
    "print(sf_base_url)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Your task: Use a model of your choice on SiliconFlow to generate two long text \n",
    "\n",
    "You can choose any question, but each should let the LLM to generate over 300 words in english, while the other should generate 300 Chinese characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### YOUR TASK ####\n",
    "# write a prompt, for example\n",
    "prompt = '帮我写一篇文章来介绍天安门的背景历史，从古代说到现代，包含很多跟天安门有关系的故事。越长越好，不可以少于1000个字。'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "天安门，位于中国北京市的中心，是一个具有悠久历史和丰富文化的地标性建筑。它的名字来源于“太平门”，意为“国家的安宁之门”。天安门的历史可以追溯到几千年前，但它真正的地位和重要性是在明清两代时期确立的。在那个时期，天安门门楼成为了皇帝举行重要仪式和庆典的场所，同时也是市民聚集和交流的中心。\n",
       "\n",
       "在古代，天安门地区是一个重要的交通枢纽和商业中心。据史书记载，天安门周围有许多市场、庙宇和餐馆，人们在这里进行交易、祈祷和娱乐。然而，天安门的真正地位是在明朝时期奠定的。明成祖朱棣在北京建立了都城，并将天安门作为皇宫的正门。从此，天安门成为了皇宫的入口和象征，显示了皇帝的威严和权力。\n",
       "\n",
       "在清朝时期，天安门更加繁荣。乾隆皇帝曾经在天安门前举行过多次盛大的庆祝活动，吸引了成千上万的游客前来观看。此外，天安门周围还修建了许多宏伟的建筑，如太和门、紫禁城和故宫等，使得天安门成为了中国著名的旅游景点之一。\n",
       "\n",
       "1911年，辛亥革命爆发，清朝灭亡，中华人民共和国成立。天安门成为了新的国家的象征。1949年，毛泽东在北京天安门发表了著名的“开国大业”的讲话，宣告中华人民共和国的成立。从此，天安门成为了中国的政治中心，成为了举国上下庆祝的重要场所。\n",
       "\n",
       "天安门不仅仅是一个重要的历史遗迹，它还象征着中国的文化和价值观。天安门门楼上的五星红旗和毛主席的雕像代表着中国的社会主义制度和中国人民的团结。每年国庆节，成千上万的游客会来到天安门，观看升旗仪式，庆祝祖国的生日。\n",
       "\n",
       "除了政治意义外，天安门还承载着许多历史故事和传说。据说，天安门门楼曾经是一座古老的庙宇，后被明朝皇帝改建成了大门。还有传说，天安门门楼上的石狮子是用皇帝的脑骨制成的。这些故事虽然缺乏历史依据，但它们反映了人们对天安门的深厚感情和 reverence。\n",
       "\n",
       "总之，天安门是中国历史和文化的重要组成部分。它见证了中国的沧桑变化，见证了中国的繁荣和强大。天安门不仅仅是一个建筑，它更是中国精神的象征。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### YOUR TASK ####\n",
    "# prepare and call the service using a chinese prompt\n",
    "client = OpenAI(api_key=sf_api_key, base_url=sf_base_url)\n",
    "\n",
    "# You can choose a model from the following list\n",
    "# Or you can log into your Infini-AI or SiliconFlow account, and find an available model you want to use.\n",
    "# model = \"Qwen/QVQ-72B-Preview\"\n",
    "# model=\"llama-3.3-70b-instruct\"\n",
    "model=\"tencent/Hunyuan-MT-7B\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "  ]\n",
    ")\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
