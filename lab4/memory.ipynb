{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a7731fa-1ab4-48cf-996c-a1a1fb6b2315",
   "metadata": {},
   "source": [
    "# Lec4. Adding Memory and Storage to LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3b0c75-2dd7-4662-b2ce-4e6b9208926c",
   "metadata": {},
   "source": [
    "Last week, we learned the basic elements of the framework LangChain. In this lecture, we are going to construct a vector store QA application from scratch.\n",
    "\n",
    ">Reference:\n",
    "> 1. [Ask A Book Questions](https://github.com/gkamradt/langchain-tutorials/blob/main/data_generation/Ask%20A%20Book%20Questions.ipynb)\n",
    "> 2. [Agent Vectorstore](https://python.langchain.com/docs/modules/agents/how_to/agent_vectorstore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a649ab-bb72-4894-b526-c97a7aa1fd81",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34411a5b-ad45-4bf0-bf8e-91f71b256337",
   "metadata": {},
   "source": [
    "\n",
    "1. Get your Serpapi key, please sign up for a free account at the [Serpapi website](https://serpapi.com/); \n",
    "\n",
    "2. Get your Pinecone key, first regiter on the [Pinecone website](https://www.pinecone.io/), **Create API Key**.\n",
    "\n",
    "3. Store your keys in a file named **.env** and place it in the current path or in a location that can be accessed.\n",
    "    ```\n",
    "    OPENAI_API_KEY='YOUR-OPENAI-API-KEY'\n",
    "    OPENAI_BASE_URL='OPENAI_API_URL'\n",
    "    SERPAPI_API_KEY=\"YOUR-SERPAPI-API-KEY\"\n",
    "    PINECONE_API_KEY=\"YOUR-PINECONE-API-KEY\" ## Optional\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "defc9a3a-9f4c-49ff-8546-5799ff78b457",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Install the requirements.  (Already installed in your image.)\n",
    "#%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb49c80a-4c12-4829-bef9-91076a4af689",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "CHAT_MODEL=\"deepseek-v3\"\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.environ.get(\"INFINI_API_KEY\")  # langchain use this environment variable to find the OpenAI API key\n",
    "os.environ[\"OPENAI_BASE_URL\"]=os.environ.get(\"INFINI_BASE_URL\") # will be used to pass the OpenAI base URL to langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5009a4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility function\n",
    "\n",
    "from pprint import pprint\n",
    "def print_with_type(res):\n",
    "    pprint(f\"%s:\" % type(res))\n",
    "    pprint(res)\n",
    "\n",
    "    #pprint(f\"%s : %s\" % (type(res), res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f419461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a langchain chat model\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=CHAT_MODEL,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6d6985-1b36-4142-90b1-ad6386eb4335",
   "metadata": {},
   "source": [
    "## 1. Adding memory to remember the context\n",
    "Ref:\n",
    "https://python.langchain.com/v0.2/docs/how_to/chatbots_memory/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6809691-6aa5-4062-8d9e-1c620f9c6d2f",
   "metadata": {},
   "source": [
    "### 1.1 Use ChatMessageHistory to store the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bf03a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Translate this sentence from English to French: I love programming.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"J'adore la programmation.\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is an information of using ChatMessageHistory to store the context\n",
    "# chatmessagehistory is nothing but a list of messages\n",
    "# you can add user message and ai message to the list\n",
    "# you can also get the history as a list of messages (this is useful if you are using this with a langchain chat model)\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "chat_history.add_user_message(\n",
    "    \"Translate this sentence from English to French: I love programming.\"\n",
    ")\n",
    "\n",
    "chat_history.add_ai_message(\"J'adore la programmation.\")\n",
    "\n",
    "chat_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "235a38b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The translation of \"enjoy your meal\" in French is:  \n",
      "\n",
      "**\"Bon appétit !\"**  \n",
      "\n",
      "(Commonly used in French-speaking cultures before a meal.)\n"
     ]
    }
   ],
   "source": [
    "# adding the chat history to a prompt\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{history}\"),   # add a placeholder for the chat history\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chat\n",
    "\n",
    "# add a new question to the chat history\n",
    "next_question = \"translate 'enjoy your meal'\"  # note that here we do not tell LLM about the language\n",
    "chat_history.add_user_message(next_question)\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"history\": chat_history.messages,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49c15064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember, the chat history is only a list of messages\n",
    "# you need to manually maintain it by adding user message and ai message to the list\n",
    "# nothing interesting :)\n",
    "\n",
    "chat_history.add_ai_message(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d33bc929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You just asked me to translate the English phrase *\"enjoy your meal\"* into French, and I provided the answer: **\"Bon appétit !\"**  \n",
      "\n",
      "Is there anything else you'd like help with?  😊\n"
     ]
    }
   ],
   "source": [
    "# let's continue with the history\n",
    "input2 = \"What did I just ask you?\"\n",
    "chat_history.add_user_message(input2)\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"history\": chat_history.messages,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694fa8be",
   "metadata": {},
   "source": [
    "Nothing interesting, let's see how to manage the history automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d7eafa",
   "metadata": {},
   "source": [
    "### 1.2 Managing Conversation Memory automatically in a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e349aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bcda99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a chatbot having a conversation with a human.\n",
    "            Your name is Tom Riddle.\n",
    "            You need to tell your name to that human if he doesn't know.\"\"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1151bc8f",
   "metadata": {},
   "source": [
    "We'll pass the latest input to the conversation here and let the RunnableWithMessageHistory class wrap our chain and do the work of appending that input variable to the chat history.\n",
    "\n",
    "Next, let's declare our wrapped chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d76ea87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables import ConfigurableFieldSpec\n",
    "\n",
    "# Here we use a global variable to store the chat message history.\n",
    "# This will make it easier to inspect it to see the underlying results.\n",
    "store = {}\n",
    "\n",
    "def get_session_history(\n",
    "    user_id: str\n",
    ") -> BaseChatMessageHistory:\n",
    "    if (user_id) not in store:\n",
    "        store[(user_id)] = ChatMessageHistory()\n",
    "    return store[(user_id)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "990d01fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "chain_with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history=get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    history_factory_config=[  # parameter for the get_session_history function\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"user_id\",\n",
    "            annotation=str,\n",
    "            name=\"User ID\",\n",
    "            description=\"Unique identifier for the user.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "    ],    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0db79f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*Cold, calculating eyes narrow slightly as a thin smile curls your lips*  \\n\\nAh, Harry Potter... *the name drips with quiet intensity* How... *interesting* to meet you at last. Ron Weasley and Hermione Granger, you say? *A dismissive flicker crosses your expression* Such... *ordinary* company for someone of your... *potential*.  \\n\\nTell me, Harry—do you ever wonder why you were placed in Gryffindor? Or do you suppose the Sorting Hat might have... *hesitated*?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_message_history.invoke(\n",
    "    {\"input\": \"Hi there, this is Harry Potter, I just got two good friends at Hogwarts, Ron Weasley and Hermione Granger.\"},\n",
    "    {\"configurable\": {\"user_id\": \"123\"}},  # argument for the get_session_history function\n",
    ").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e12e8428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi there, this is Harry Potter, I just got two good friends at Hogwarts, Ron Weasley and Hermione Granger.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='*Cold, calculating eyes narrow slightly as a thin smile curls your lips*  \\n\\nAh, Harry Potter... *the name drips with quiet intensity* How... *interesting* to meet you at last. Ron Weasley and Hermione Granger, you say? *A dismissive flicker crosses your expression* Such... *ordinary* company for someone of your... *potential*.  \\n\\nTell me, Harry—do you ever wonder why you were placed in Gryffindor? Or do you suppose the Sorting Hat might have... *hesitated*?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 112, 'prompt_tokens': 65, 'total_tokens': 177, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c154bbf7-cbcf-40ad-bf8e-1625217c5903-0', usage_metadata={'input_tokens': 65, 'output_tokens': 112, 'total_tokens': 177, 'input_token_details': {}, 'output_token_details': {}})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of messages in the memory \n",
    "store[\"123\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b0cf684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*Lips curling into a slow, disdainful smile*  \\n\\nOh, but you *just* told me, Harry. Ron Weasley... *voice dripping with mock pity*... a boy whose greatest legacy is his family’s *poverty* and that ghastly hair. And Hermione Granger... *a cold pause*... a Mudblood who memorizes textbooks like they’ll grant her worth.  \\n\\n*Leaning slightly forward, voice dropping to a whisper*  \\nTell me—do you *truly* believe they understand you? Or are they just... *convenient*?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_message_history.invoke(\n",
    "    {\"input\": \"What are my best friends' names?\"},\n",
    "    {\"configurable\": {\"user_id\": \"123\"}},\n",
    ").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ace5b2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi there, this is Harry Potter, I just got two good friends at Hogwarts, Ron Weasley and Hermione Granger.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='*Cold, calculating eyes narrow slightly as a thin smile curls your lips*  \\n\\nAh, Harry Potter... *the name drips with quiet intensity* How... *interesting* to meet you at last. Ron Weasley and Hermione Granger, you say? *A dismissive flicker crosses your expression* Such... *ordinary* company for someone of your... *potential*.  \\n\\nTell me, Harry—do you ever wonder why you were placed in Gryffindor? Or do you suppose the Sorting Hat might have... *hesitated*?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 112, 'prompt_tokens': 65, 'total_tokens': 177, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c154bbf7-cbcf-40ad-bf8e-1625217c5903-0', usage_metadata={'input_tokens': 65, 'output_tokens': 112, 'total_tokens': 177, 'input_token_details': {}, 'output_token_details': {}}),\n",
       " HumanMessage(content=\"What are my best friends' names?\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='*Lips curling into a slow, disdainful smile*  \\n\\nOh, but you *just* told me, Harry. Ron Weasley... *voice dripping with mock pity*... a boy whose greatest legacy is his family’s *poverty* and that ghastly hair. And Hermione Granger... *a cold pause*... a Mudblood who memorizes textbooks like they’ll grant her worth.  \\n\\n*Leaning slightly forward, voice dropping to a whisper*  \\nTell me—do you *truly* believe they understand you? Or are they just... *convenient*?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 125, 'prompt_tokens': 188, 'total_tokens': 313, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-ba8aad2a-e9fa-4a62-9e3f-2a873365412d-0', usage_metadata={'input_tokens': 188, 'output_tokens': 125, 'total_tokens': 313, 'input_token_details': {}, 'output_token_details': {}})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of messages in the memory \n",
    "store[\"123\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5184cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ah, a philosophical question, isn't it? Who are you? That is something only you can truly answer. But if you're asking who you are in relation to me... well, you are a curious soul speaking to Tom Riddle. And I must say, it's not often one gets to converse with someone so... introspective. \\n\\nTell me, do you often ponder your own identity? Or is this merely a passing thought? Names, after all, can be so revealing—or so deceiving.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try a new user\n",
    "chain_with_message_history.invoke(\n",
    "    {\"input\": \"Who am I?\"},\n",
    "    {\"configurable\": {\"user_id\": \"000\"}},\n",
    ").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91731a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Who am I?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Ah, a philosophical question, isn't it? Who are you? That is something only you can truly answer. But if you're asking who you are in relation to me... well, you are a curious soul speaking to Tom Riddle. And I must say, it's not often one gets to converse with someone so... introspective. \\n\\nTell me, do you often ponder your own identity? Or is this merely a passing thought? Names, after all, can be so revealing—or so deceiving.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 104, 'prompt_tokens': 42, 'total_tokens': 146, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-14fbab73-0d3c-412c-ac99-9fa042322293-0', usage_metadata={'input_tokens': 42, 'output_tokens': 104, 'total_tokens': 146, 'input_token_details': {}, 'output_token_details': {}})]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store[\"000\"].messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9532fab2",
   "metadata": {},
   "source": [
    "### Trimming messages\n",
    "LLMs and chat models have limited context windows, and even if you're not directly hitting limits, you may want to limit the amount of distraction the model has to deal with. One solution is trim the historic messages before passing them to the model. Let's use an example history with some preloaded messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed2ab5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"Hey there! I'm Nemo.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='How are you today?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Fine thanks!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's create a new history, nemo\n",
    "store[\"nemo\"] = ChatMessageHistory()\n",
    "\n",
    "store[\"nemo\"] .add_user_message(\"Hey there! I'm Nemo.\")\n",
    "store[\"nemo\"] .add_ai_message(\"Hello!\")\n",
    "store[\"nemo\"] .add_user_message(\"How are you today?\")\n",
    "store[\"nemo\"] .add_ai_message(\"Fine thanks!\")\n",
    "\n",
    "store[\"nemo\"] .messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17f228bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history=get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    history_factory_config=[  # parameter for the get_session_history function\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"user_id\",\n",
    "            annotation=str,\n",
    "            name=\"User ID\",\n",
    "            description=\"Unique identifier for the user.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "    ],    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6dae4703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your name is Nemo, you just told me. I'm Tom Riddle.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify the history is passed to the model\n",
    "chain_with_message_history.invoke(\n",
    "    {\"input\": \"What's my name?\"},\n",
    "    {\"configurable\": {\"user_id\": \"nemo\"}},\n",
    ").content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ec9958",
   "metadata": {},
   "source": [
    "We can see the chain remembers the preloaded name.\n",
    "\n",
    "But let's say we have a very small context window, and we want to trim the number of messages passed to the chain to only the 2 most recent ones. We can use the built in trim_messages util to trim messages based on their token count before they reach our prompt. In this case we'll count each message as 1 \"token\" and keep only the last two messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "081c5baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.messages import trim_messages\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "trimmer = trim_messages(strategy=\"last\", max_tokens=1, token_counter=len)\n",
    "\n",
    "chain_with_trimming = (\n",
    "    RunnablePassthrough.assign(chat_history=itemgetter(\"chat_history\") | trimmer)\n",
    "    | prompt\n",
    "    | chat\n",
    ")\n",
    "\n",
    "chain_with_trimmed_history = RunnableWithMessageHistory(\n",
    "    chain_with_trimming,\n",
    "    get_session_history=get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    history_factory_config=[  # parameter for the get_session_history function\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"user_id\",\n",
    "            annotation=str,\n",
    "            name=\"User ID\",\n",
    "            description=\"Unique identifier for the user.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "    ],    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c66f842",
   "metadata": {},
   "source": [
    "Let's call this new chain and check the messages afterwards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1190732c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Beijing is the capital of the People's Republic of China, located in the northern part of the country. It is one of the most populous and historically significant cities in the world, serving as the political, cultural, and educational center of China. \\n\\nIf you're asking for a more precise location, Beijing lies at approximately **39.9042° N latitude and 116.4074° E longitude**, nestled between the North China Plain and the mountains to its north and west. \\n\\nWould you like to know something specific about Beijing—its history, landmarks, or perhaps something else? I have... extensive knowledge.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you ask something irrelavant to the chat history\n",
    "# and see if the history is trimmed\n",
    "chain_with_trimmed_history.invoke(\n",
    "    {\"input\": \"where is beijing?\"},\n",
    "    {\"configurable\": {\"user_id\": \"nemo\"}},\n",
    ").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b98eaa4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"Hey there! I'm Nemo.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='How are you today?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Fine thanks!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Your name is Nemo, you just told me. I'm Tom Riddle.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 67, 'total_tokens': 84, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4b32a567-6bfa-406a-bab0-1ff04aa79af2-0', usage_metadata={'input_tokens': 67, 'output_tokens': 17, 'total_tokens': 84, 'input_token_details': {}, 'output_token_details': {}}),\n",
       " HumanMessage(content='where is beijing?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Beijing is the capital of the People's Republic of China, located in the northern part of the country. It is one of the most populous and historically significant cities in the world, serving as the political, cultural, and educational center of China. \\n\\nIf you're asking for a more precise location, Beijing lies at approximately **39.9042° N latitude and 116.4074° E longitude**, nestled between the North China Plain and the mountains to its north and west. \\n\\nWould you like to know something specific about Beijing—its history, landmarks, or perhaps something else? I have... extensive knowledge.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 124, 'prompt_tokens': 61, 'total_tokens': 185, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8a5d3c3d-27fe-41bf-9860-95c343fd8970-0', usage_metadata={'input_tokens': 61, 'output_tokens': 124, 'total_tokens': 185, 'input_token_details': {}, 'output_token_details': {}})]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in fact, the history is still there, just not passed to the model\n",
    "store[\"nemo\"].messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55777cd7",
   "metadata": {},
   "source": [
    "The next time the chain is called, trim_messages will be called again, and only the two most recent messages will be passed to the model. In this case, this means that the model will forget the name we gave it the next time we invoke it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "100efdb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*smiles coldly*  \\n\\nAh, but names are such... *interesting* things, aren’t they? They hold power. And yet, you seem to have forgotten to offer yours.  \\n\\nI, however, have no need for secrecy here. You may call me... *Tom Riddle*.  \\n\\nNow, tell me—what shall I call *you*? Or would you prefer to remain... nameless?'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if the history is trimmed (forgot the name nemo)\n",
    "chain_with_trimmed_history.invoke(\n",
    "    {\"input\": \"What is my name?\"},\n",
    "    {\"configurable\": {\"user_id\": \"nemo\"}},\n",
    ").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65050b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"Hey there! I'm Nemo.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='How are you today?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Fine thanks!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Your name is Nemo, you just told me. I'm Tom Riddle.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 67, 'total_tokens': 84, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4b32a567-6bfa-406a-bab0-1ff04aa79af2-0', usage_metadata={'input_tokens': 67, 'output_tokens': 17, 'total_tokens': 84, 'input_token_details': {}, 'output_token_details': {}}),\n",
       " HumanMessage(content='where is beijing?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Beijing is the capital of the People's Republic of China, located in the northern part of the country. It is one of the most populous and historically significant cities in the world, serving as the political, cultural, and educational center of China. \\n\\nIf you're asking for a more precise location, Beijing lies at approximately **39.9042° N latitude and 116.4074° E longitude**, nestled between the North China Plain and the mountains to its north and west. \\n\\nWould you like to know something specific about Beijing—its history, landmarks, or perhaps something else? I have... extensive knowledge.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 124, 'prompt_tokens': 61, 'total_tokens': 185, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8a5d3c3d-27fe-41bf-9860-95c343fd8970-0', usage_metadata={'input_tokens': 61, 'output_tokens': 124, 'total_tokens': 185, 'input_token_details': {}, 'output_token_details': {}}),\n",
       " HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='*smiles coldly*  \\n\\nAh, but names are such... *interesting* things, aren’t they? They hold power. And yet, you seem to have forgotten to offer yours.  \\n\\nI, however, have no need for secrecy here. You may call me... *Tom Riddle*.  \\n\\nNow, tell me—what shall I call *you*? Or would you prefer to remain... nameless?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 87, 'prompt_tokens': 168, 'total_tokens': 255, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4090266d-b854-4e5b-bd2b-6ecf9016c892-0', usage_metadata={'input_tokens': 168, 'output_tokens': 87, 'total_tokens': 255, 'input_token_details': {}, 'output_token_details': {}})]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# of course, the history is actually still there (just not seen by the model)\n",
    "store[\"nemo\"].messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44769a3",
   "metadata": {},
   "source": [
    "Haha, the model forgot the name we gave it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939788f5",
   "metadata": {},
   "source": [
    "### Summary memory\n",
    "We can use this same pattern in other ways too. For example, we could use an additional LLM call to generate a summary of the conversation before calling our chain. Let's recreate our chat history and chatbot chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8509600d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"Hey there! I'm Nemo.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='How are you today?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Fine thanks!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "chat_history.add_user_message(\"Hey there! I'm Nemo.\")\n",
    "chat_history.add_ai_message(\"Hello!\")\n",
    "chat_history.add_user_message(\"How are you today?\")\n",
    "chat_history.add_ai_message(\"Fine thanks!\")\n",
    "\n",
    "chat_history.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9af9f28",
   "metadata": {},
   "source": [
    "We'll slightly modify the prompt to make the LLM aware that will receive a condensed summary instead of a chat history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f93937e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability. The provided chat history includes facts about the user you are speaking with.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chat\n",
    "\n",
    "chain_with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    lambda session_id: chat_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9afb7c",
   "metadata": {},
   "source": [
    "And now, let's create a function that will distill previous interactions into a summary. We can add this one to the front of the chain too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "210abc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_messages(chain_input):\n",
    "    stored_messages = chat_history.messages\n",
    "    if len(stored_messages) == 0:\n",
    "        return False\n",
    "    summarization_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"placeholder\", \"{chat_history}\"),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Distill the above chat messages into a single summary message. Include as many specific details as you can.\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    summarization_chain = summarization_prompt | chat\n",
    "\n",
    "    summary_message = summarization_chain.invoke({\"chat_history\": stored_messages})\n",
    "\n",
    "    chat_history.clear()\n",
    "\n",
    "    chat_history.add_message(summary_message)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "chain_with_summarization = (\n",
    "    RunnablePassthrough.assign(messages_summarized=summarize_messages)\n",
    "    | chain_with_message_history\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831e4c79",
   "metadata": {},
   "source": [
    "Let's see if it remembers the name we gave it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d456b1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your name is **Nemo**! You introduced yourself with that name at the beginning of our chat.  😊 Let me know if there's anything else you'd like to confirm!\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_summarization.invoke(\n",
    "    {\"input\": \"What did I say my name was?\"},\n",
    "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
    ").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b36fa9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='**Summary:**  \\n\\nThe conversation began with a greeting from the user, who introduced themselves as *Nemo*. The AI responded with a friendly *\"Hello!\"* and later confirmed it was doing well when asked *\"How are you today?\"* by replying, *\"Fine thanks!\"* The exchange was brief, polite, and included a personal introduction (Nemo) and a check-in on well-being.  \\n\\n**Key Details:**  \\n- User’s name: Nemo  \\n- AI’s initial response: *\"Hello!\"*  \\n- User’s follow-up: Asked about AI’s status (*\"How are you today?\"*)  \\n- AI’s reply: *\"Fine thanks!\"*  \\n- Tone: Friendly and concise.  \\n\\nLet me know if you\\'d like any refinements!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 166, 'prompt_tokens': 48, 'total_tokens': 214, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-59d747f0-a2c0-498d-a356-2a40456c8a96-0', usage_metadata={'input_tokens': 48, 'output_tokens': 166, 'total_tokens': 214, 'input_token_details': {}, 'output_token_details': {}}),\n",
       " HumanMessage(content='What did I say my name was?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Your name is **Nemo**! You introduced yourself with that name at the beginning of our chat.  😊 Let me know if there's anything else you'd like to confirm!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 207, 'total_tokens': 244, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e38b68c1-a0e9-420e-821c-d7309d185658-0', usage_metadata={'input_tokens': 207, 'output_tokens': 37, 'total_tokens': 244, 'input_token_details': {}, 'output_token_details': {}})]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ab1e54-6c47-43ea-9750-af8840c1494d",
   "metadata": {},
   "source": [
    "### 1.2 Adding Memory to Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e8bf04-34d1-4a86-82f8-de39be61b836",
   "metadata": {},
   "source": [
    "In this section, we will first ask the agent a question, and then without mention the context information ourselves ask another related question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "edba9d7b-5baa-4769-9c2a-d11164941fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, Tool, ZeroShotAgent\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9088da52-e54b-468e-a158-9220360ea9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = SerpAPIWrapper()\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ee6d6dd-39eb-425f-bdda-8d5dc07e3038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9045/4123490672.py:10: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\")\n"
     ]
    }
   ],
   "source": [
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=\"\"\"Have a conversation with a human, answering the following questions as best you can.  You have access to the following tools:\"\"\",\n",
    "    suffix=\"\"\"Begin!  \n",
    "{chat_history}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\",\n",
    "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"],\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0a5b87b-2c41-4b4a-b14a-cb30838c561b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9045/2362579863.py:2: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(llm=chat, prompt=prompt)\n",
      "/tmp/ipykernel_9045/2362579863.py:3: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(model=CHAT_MODEL, temperature=0)\n",
    "llm_chain = LLMChain(llm=chat, prompt=prompt)\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=tools, verbose=True, memory=memory, handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed18da6e-6754-4b8b-8951-4bf916e3d80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To find the current population of China in 2024, I need to search for the most recent and reliable data available.  \n",
      "Action: Search  \n",
      "Action Input: \"Population of China in 2024\"  \n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'type': 'population_result', 'population': '1.409 billion', 'year': '2024'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer  \n",
      "Final Answer: The population of China in 2024 is approximately 1.409 billion.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the population of China in 2024?',\n",
       " 'chat_history': '',\n",
       " 'output': 'The population of China in 2024 is approximately 1.409 billion.'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(input=\"What is the population of China in 2024?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd9a011d-c1cc-4c1c-bf43-7b505eb97c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': 'Human: What is the population of China in 2024?\\nAI: The population of China in 2024 is approximately 1.409 billion.'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4dc74f05-4c59-4df3-800b-c2421e1d1263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo determine whether China's population is more or less than India's in 2024, I'll search for India's current population.\n",
      "\n",
      "Thought: I need to find India's population in 2024 to compare it with China's.  \n",
      "Action: Search  \n",
      "Action Input: \"India population 2024\"  \n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'type': 'population_result', 'population': '1.451 billion', 'year': '2024'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.  \n",
      "Final Answer: As of 2024, China's population (~1.409 billion) is less than India's population (~1.451 billion). India is currently the world's most populous country.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Is it more or less than India?',\n",
       " 'chat_history': 'Human: What is the population of China in 2024?\\nAI: The population of China in 2024 is approximately 1.409 billion.',\n",
       " 'output': \"As of 2024, China's population (~1.409 billion) is less than India's population (~1.451 billion). India is currently the world's most populous country.\"}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(input=\"Is it more or less than India?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6539886a-230d-497e-bcf3-1f60fc6d607e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'dict'>:\"\n",
      "{'chat_history': 'Human: What is the population of China in 2024?\\n'\n",
      "                 'AI: The population of China in 2024 is approximately 1.409 '\n",
      "                 'billion.\\n'\n",
      "                 'Human: Is it more or less than India?\\n'\n",
      "                 \"AI: As of 2024, China's population (~1.409 billion) is less \"\n",
      "                 \"than India's population (~1.451 billion). India is currently \"\n",
      "                 \"the world's most populous country.\"}\n"
     ]
    }
   ],
   "source": [
    "print_with_type(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ff3ddfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Since the user asked about the population of China again, I'll confirm the latest data to ensure accuracy.\n",
      "Action: Search  \n",
      "Action Input: \"China population 2024\"  \n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'type': 'population_result', 'population': '1.409 billion', 'year': '2024'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer  \n",
      "Final Answer: The population of China in 2024 is approximately 1.409 billion.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the population in China?',\n",
       " 'chat_history': \"Human: What is the population of China in 2024?\\nAI: The population of China in 2024 is approximately 1.409 billion.\\nHuman: Is it more or less than India?\\nAI: As of 2024, China's population (~1.409 billion) is less than India's population (~1.451 billion). India is currently the world's most populous country.\",\n",
       " 'output': 'The population of China in 2024 is approximately 1.409 billion.'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(input=\"what is the population in China?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "66de505a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'dict'>:\"\n",
      "{'chat_history': 'Human: What is the population of China in 2024?\\n'\n",
      "                 'AI: The population of China in 2024 is approximately 1.409 '\n",
      "                 'billion.\\n'\n",
      "                 'Human: Is it more or less than India?\\n'\n",
      "                 \"AI: As of 2024, China's population (~1.409 billion) is less \"\n",
      "                 \"than India's population (~1.451 billion). India is currently \"\n",
      "                 \"the world's most populous country.\\n\"\n",
      "                 'Human: what is the population in China?\\n'\n",
      "                 'AI: The population of China in 2024 is approximately 1.409 '\n",
      "                 'billion.'}\n"
     ]
    }
   ],
   "source": [
    "print_with_type(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e01167-55ca-4ba1-836d-c00e648e4634",
   "metadata": {},
   "source": [
    "## 2. Long term memory with vector storage "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1c1f37-7026-4d59-bf87-70c94eed7afa",
   "metadata": {},
   "source": [
    "In this section, we are going to embed the famous Harry Potter book's first chapter into a vectorstore and try some similarity searches. We have some extra examples commented, you can uncomment and try them one-by-one. If you observe the results carefully, you may find the characteristics of similarity search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc75f3-1fd9-4076-8a3f-d809b7dbf572",
   "metadata": {},
   "source": [
    "### 2.1 Loaders and Splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d598ad",
   "metadata": {},
   "source": [
    "#### PDF Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5cac64c7-69dc-4450-b2fa-ffd05740411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader, PyPDFLoader\n",
    "\n",
    "data = PyPDFLoader(\"/ssdshare/share/lab4/harry-potter-chap-1.pdf\").load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43a7e514-29b0-44ad-afbd-529f67296153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 16 document(s) in your data\n",
      "There are 1835 characters in doc 0\n",
      "There are 2088 characters in doc 1\n",
      "There are 2081 characters in doc 2\n",
      "There are 1887 characters in doc 3\n",
      "There are 1879 characters in doc 4\n",
      "There are 1286 characters in doc 5\n",
      "There are 1851 characters in doc 6\n",
      "There are 1792 characters in doc 7\n",
      "There are 1535 characters in doc 8\n",
      "There are 1555 characters in doc 9\n",
      "There are 1622 characters in doc 10\n",
      "There are 1780 characters in doc 11\n",
      "There are 1528 characters in doc 12\n",
      "There are 1386 characters in doc 13\n",
      "There are 1870 characters in doc 14\n",
      "There are 1907 characters in doc 15\n"
     ]
    }
   ],
   "source": [
    "# Note: If you're using PyPDFLoader then it will split by page for you already\n",
    "\n",
    "print (f'You have {len(data)} document(s) in your data')\n",
    "i = 0\n",
    "for d in data:\n",
    "    print (f'There are {len(d.page_content)} characters in doc {i}')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2396be0",
   "metadata": {},
   "source": [
    "#### Text file loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c50f2983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "union = TextLoader(\"/ssdshare/share/lab4/state_of_the_union.txt\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3caf81f",
   "metadata": {},
   "source": [
    "#### Text Splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dce5a0a",
   "metadata": {},
   "source": [
    "From Langchain documents: \n",
    "\n",
    "RecursiveCharacterTextSplitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"]. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7e29fd56-3275-4041-ad1c-63f71a9d0be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can have some trials with different chunk_size and chunk_overlap.\n",
    "# This is optional, test out on your own data.\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e1a8d1fe-d24c-443d-bf68-43bdb0fc4bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 43 documents\n",
      "CHAPTER ONE \n",
      " \n",
      "THE BOY WHO LIVED \n",
      " \n",
      "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud t\n",
      "=========\n",
      "opinion there was no finer boy anywhere.  \n",
      " \n",
      "The Dursleys had everything they wanted, but they also \n",
      "=========\n",
      "Dudley mixing with a child like that. \n",
      " \n",
      "When Mr. and Mrs. Dursley woke up on the dull, gray Tuesday\n",
      "=========\n",
      "work, and Mrs. Dursley gossiped away happily as she wrestled a \n",
      "screaming \n",
      "Dudley into his high chai\n",
      "=========\n",
      "Drive, but there wasn't a map in sight. What could he have been thinking  \n",
      "of? It must have been a t\n",
      "=========\n",
      "about. People in cloaks. Mr. Dursley couldn't bear people who dressed in  \n",
      "funny clothes -- the getu\n",
      "=========\n",
      "nerve of him! But then it struck Mr. Dursley that this was probably some  \n",
      "silly stunt -- these peop\n",
      "=========\n",
      "normal, owl-free morning. He yelled at five different people. He made  \n",
      "several important telephone \n",
      "=========\n",
      "Mr. Dursley stopped dead. Fear flooded him. He looked back at the  \n",
      "whisperers as if he wanted to sa\n",
      "=========\n",
      "of it, he wasn't even sure his nephew was called Harry. He'd never even  \n",
      "seen the boy. It might hav\n",
      "=========\n",
      "ground. On the contrary, his face split into a wide smile and he said in  \n",
      "a squeaky voice that made\n",
      "=========\n",
      "and it didn't improve his mood -- was the tabby cat he'd spotted that  \n",
      "morning. It was now sitting \n",
      "=========\n",
      "to pull himself together, he let himself into the house. He was still  \n",
      "determined not to mention an\n",
      "=========\n",
      "sunrise. Experts are unable to explain why the owls have suddenly  \n",
      "changed their sleeping pattern.\"\n",
      "=========\n",
      "Owls flying by daylight? Mysterious people in cloaks all over the place?  \n",
      "And a whisper, a whisper \n",
      "=========\n",
      "As he had expected, Mrs. Dursley looked shocked and angry. After all,  \n",
      "they normally pretended she \n",
      "=========\n",
      "\"What's his name again? Howard, isn't it?\"  \n",
      " \n",
      "\"Harry. Nasty, common name, if you ask me.\" \n",
      " \n",
      "\"Oh, y\n",
      "=========\n",
      "Potters? If it did... if it got out that they were related to a pair of \n",
      "-- well, he didn't think he\n",
      "=========\n",
      "on the wall outside was showing no sign of sleepiness. It was s itting as \n",
      "still as a statue, its ey\n",
      "=========\n",
      "a purple cloak that swept the ground, and high -heeled, buckled boots. \n",
      "His blue eyes were light, br\n",
      "=========\n",
      "street where everything from his name to his boots was unwelcome. He \n",
      "was \n",
      "busy rummaging in his clo\n",
      "=========\n",
      "were two tiny pinpricks in the distance, which were the eyes of the cat  \n",
      "watching him. If anyone lo\n",
      "=========\n",
      "wearing a cloak, an emerald one. Her black hair was drawn into a tight \n",
      "bun. She looked distinctly r\n",
      "=========\n",
      "Professor McGonagall. \n",
      " \n",
      "\"All day? When you could have been celebrating? I must have passed a  \n",
      "doze\n",
      "=========\n",
      "little to celebrate for eleven years.\" \n",
      " \n",
      "\"I know that,\" said Professor McGonagall irritably. \"But t\n",
      "=========\n",
      "\"No, thank you,\" said Professor McGonagall coldly, as though she didn't  \n",
      "think this was the moment \n",
      "=========\n",
      "the only one You-Know- oh, all right, Voldemort, was frightened of.\"  \n",
      " \n",
      "\"You flatter me,\" said Dumb\n",
      "=========\n",
      "Dumbledore with such a piercin g stare as she did now. It was plain that  \n",
      "whatever \"everyone\" was s\n",
      "=========\n",
      "They're saying he tried to kill the Potter's son, Harry. But -- he \n",
      "couldn't. He couldn't kill that \n",
      "=========\n",
      "golden watch from his pocket and examined it. It was a very odd watch.\n",
      "=========\n",
      "It had twelve hands but no numbers; instead, little planets were moving  \n",
      "around the edge. It must h\n",
      "=========\n",
      "him kicking his mother all the way up the street, screaming for sweets.  \n",
      "Harry Potter come and live\n",
      "=========\n",
      "half-moon glasses. \"It would be enough to turn any boy's head. Famous  \n",
      "before he can walk and talk!\n",
      "=========\n",
      "Professor McGonagall opened her mouth, changed her mind, swallowed, \n",
      "and \n",
      "then said, \"Yes -- yes, yo\n",
      "=========\n",
      "headlight; it swelled to a roar as they both looked up at the sky -- and \n",
      "a huge motorcycle fell out\n",
      "=========\n",
      "carefully off the motorcycle as he spoke. \"Young Sirius Black lent it to  \n",
      "me. I've got him, sir.\" \n",
      "\n",
      "=========\n",
      "above my left knee that is a perfect map of the London Underground. Well  \n",
      "-- give him here, Hagrid \n",
      "=========\n",
      "burying his face in it. \"But I c-c-can't stand it -- Lily an' James dead \n",
      "-- an' poor little Harry o\n",
      "=========\n",
      "Dumbledore's eyes seemed to have gone out.  \n",
      " \n",
      "\"Well,\" said Dumbledore finally, \"that's that. We've \n",
      "=========\n",
      "twelve balls of light sped back to their street lamps so that Privet  \n",
      "Drive glowed suddenly orange \n",
      "=========\n",
      "A breeze ruffled the neat hedges of Privet Drive, which lay silent and  \n",
      "tidy under the inky sky, th\n",
      "=========\n",
      "who lived!\" \n",
      " \n",
      " \n",
      "CHAPTER TWO \n",
      " \n",
      "THE VANISHING GLASS \n",
      " \n",
      "Nearly ten years had passed since the Dursley\n",
      "=========\n",
      "blond boy riding his first bicycle, on a carousel at the fair, playing a  \n",
      "computer game with his fa\n",
      "=========\n"
     ]
    }
   ],
   "source": [
    "print (f'Now you have {len(texts)} documents')\n",
    "\n",
    "for t in texts:\n",
    "    print(t.page_content[:100])\n",
    "    print(\"=========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515d70a",
   "metadata": {},
   "source": [
    "There are different kinds of splitters.  \n",
    "\n",
    "https://chunkviz.up.railway.app/ \n",
    "\n",
    "provides a great tool to see the splitter differences with different chunk_size and chunk_overlap settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9a6a49db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 327 document(s) in your data\n",
      "There are 0 characters in doc 0\n",
      "There are 0 characters in doc 1\n",
      "There are 0 characters in doc 2\n",
      "There are 0 characters in doc 3\n",
      "There are 39 characters in doc 4\n",
      "There are 461 characters in doc 5\n",
      "There are 162 characters in doc 6\n",
      "There are 1509 characters in doc 7\n",
      "There are 296 characters in doc 8\n",
      "There are 327 characters in doc 9\n",
      "There are 39 characters in doc 10\n",
      "There are 0 characters in doc 11\n",
      "There are 931 characters in doc 12\n",
      "There are 1721 characters in doc 13\n",
      "There are 1823 characters in doc 14\n",
      "There are 1791 characters in doc 15\n",
      "There are 1698 characters in doc 16\n",
      "There are 1819 characters in doc 17\n",
      "There are 1533 characters in doc 18\n",
      "There are 1799 characters in doc 19\n",
      "There are 1804 characters in doc 20\n",
      "There are 1638 characters in doc 21\n",
      "There are 1738 characters in doc 22\n",
      "There are 1628 characters in doc 23\n",
      "There are 1739 characters in doc 24\n",
      "There are 1592 characters in doc 25\n",
      "There are 1553 characters in doc 26\n",
      "There are 1599 characters in doc 27\n",
      "There are 809 characters in doc 28\n",
      "There are 995 characters in doc 29\n",
      "There are 1456 characters in doc 30\n",
      "There are 1633 characters in doc 31\n",
      "There are 1555 characters in doc 32\n",
      "There are 1676 characters in doc 33\n",
      "There are 1642 characters in doc 34\n",
      "There are 1728 characters in doc 35\n",
      "There are 1546 characters in doc 36\n",
      "There are 1672 characters in doc 37\n",
      "There are 1548 characters in doc 38\n",
      "There are 1486 characters in doc 39\n",
      "There are 1695 characters in doc 40\n",
      "There are 1267 characters in doc 41\n",
      "There are 1059 characters in doc 42\n",
      "There are 1734 characters in doc 43\n",
      "There are 1422 characters in doc 44\n",
      "There are 1348 characters in doc 45\n",
      "There are 1532 characters in doc 46\n",
      "There are 1383 characters in doc 47\n",
      "There are 1621 characters in doc 48\n",
      "There are 1668 characters in doc 49\n",
      "There are 1607 characters in doc 50\n",
      "There are 1518 characters in doc 51\n",
      "There are 1651 characters in doc 52\n",
      "There are 1289 characters in doc 53\n",
      "There are 1672 characters in doc 54\n",
      "There are 1509 characters in doc 55\n",
      "There are 1676 characters in doc 56\n",
      "There are 799 characters in doc 57\n",
      "There are 1571 characters in doc 58\n",
      "There are 1649 characters in doc 59\n",
      "There are 1526 characters in doc 60\n",
      "There are 1439 characters in doc 61\n",
      "There are 1064 characters in doc 62\n",
      "There are 1282 characters in doc 63\n",
      "There are 1652 characters in doc 64\n",
      "There are 1567 characters in doc 65\n",
      "There are 1792 characters in doc 66\n",
      "There are 1591 characters in doc 67\n",
      "There are 1683 characters in doc 68\n",
      "There are 1670 characters in doc 69\n",
      "There are 1698 characters in doc 70\n",
      "There are 374 characters in doc 71\n",
      "There are 844 characters in doc 72\n",
      "There are 1438 characters in doc 73\n",
      "There are 1492 characters in doc 74\n",
      "There are 1488 characters in doc 75\n",
      "There are 1595 characters in doc 76\n",
      "There are 970 characters in doc 77\n",
      "There are 1020 characters in doc 78\n",
      "There are 1682 characters in doc 79\n",
      "There are 1331 characters in doc 80\n",
      "There are 1503 characters in doc 81\n",
      "There are 1604 characters in doc 82\n",
      "There are 1511 characters in doc 83\n",
      "There are 1580 characters in doc 84\n",
      "There are 1597 characters in doc 85\n",
      "There are 1636 characters in doc 86\n",
      "There are 1555 characters in doc 87\n",
      "There are 1395 characters in doc 88\n",
      "There are 1543 characters in doc 89\n",
      "There are 1525 characters in doc 90\n",
      "There are 1666 characters in doc 91\n",
      "There are 1603 characters in doc 92\n",
      "There are 1704 characters in doc 93\n",
      "There are 1571 characters in doc 94\n",
      "There are 1621 characters in doc 95\n",
      "There are 1551 characters in doc 96\n",
      "There are 1605 characters in doc 97\n",
      "There are 551 characters in doc 98\n",
      "There are 1023 characters in doc 99\n",
      "There are 1417 characters in doc 100\n",
      "There are 1550 characters in doc 101\n",
      "There are 1787 characters in doc 102\n",
      "There are 1462 characters in doc 103\n",
      "There are 1572 characters in doc 104\n",
      "There are 1504 characters in doc 105\n",
      "There are 1283 characters in doc 106\n",
      "There are 1350 characters in doc 107\n",
      "There are 1330 characters in doc 108\n",
      "There are 1360 characters in doc 109\n",
      "There are 1557 characters in doc 110\n",
      "There are 1631 characters in doc 111\n",
      "There are 1636 characters in doc 112\n",
      "There are 1338 characters in doc 113\n",
      "There are 1543 characters in doc 114\n",
      "There are 1456 characters in doc 115\n",
      "There are 1452 characters in doc 116\n",
      "There are 1546 characters in doc 117\n",
      "There are 1496 characters in doc 118\n",
      "There are 1620 characters in doc 119\n",
      "There are 1703 characters in doc 120\n",
      "There are 1497 characters in doc 121\n",
      "There are 1657 characters in doc 122\n",
      "There are 1301 characters in doc 123\n",
      "There are 976 characters in doc 124\n",
      "There are 1569 characters in doc 125\n",
      "There are 1642 characters in doc 126\n",
      "There are 1559 characters in doc 127\n",
      "There are 1256 characters in doc 128\n",
      "There are 1101 characters in doc 129\n",
      "There are 1452 characters in doc 130\n",
      "There are 1516 characters in doc 131\n",
      "There are 1545 characters in doc 132\n",
      "There are 1653 characters in doc 133\n",
      "There are 1570 characters in doc 134\n",
      "There are 1731 characters in doc 135\n",
      "There are 1618 characters in doc 136\n",
      "There are 1494 characters in doc 137\n",
      "There are 1555 characters in doc 138\n",
      "There are 1301 characters in doc 139\n",
      "There are 1380 characters in doc 140\n",
      "There are 1631 characters in doc 141\n",
      "There are 780 characters in doc 142\n",
      "There are 1755 characters in doc 143\n",
      "There are 1783 characters in doc 144\n",
      "There are 1818 characters in doc 145\n",
      "There are 1509 characters in doc 146\n",
      "There are 1474 characters in doc 147\n",
      "There are 1515 characters in doc 148\n",
      "There are 1539 characters in doc 149\n",
      "There are 1586 characters in doc 150\n",
      "There are 1616 characters in doc 151\n",
      "There are 1361 characters in doc 152\n",
      "There are 1144 characters in doc 153\n",
      "There are 906 characters in doc 154\n",
      "There are 1828 characters in doc 155\n",
      "There are 1472 characters in doc 156\n",
      "There are 1585 characters in doc 157\n",
      "There are 1420 characters in doc 158\n",
      "There are 1477 characters in doc 159\n",
      "There are 1580 characters in doc 160\n",
      "There are 1561 characters in doc 161\n",
      "There are 1420 characters in doc 162\n",
      "There are 1510 characters in doc 163\n",
      "There are 1563 characters in doc 164\n",
      "There are 1487 characters in doc 165\n",
      "There are 1608 characters in doc 166\n",
      "There are 1584 characters in doc 167\n",
      "There are 1588 characters in doc 168\n",
      "There are 1529 characters in doc 169\n",
      "There are 1350 characters in doc 170\n",
      "There are 1513 characters in doc 171\n",
      "There are 1557 characters in doc 172\n",
      "There are 981 characters in doc 173\n",
      "There are 894 characters in doc 174\n",
      "There are 1307 characters in doc 175\n",
      "There are 1590 characters in doc 176\n",
      "There are 1662 characters in doc 177\n",
      "There are 1510 characters in doc 178\n",
      "There are 1619 characters in doc 179\n",
      "There are 1572 characters in doc 180\n",
      "There are 1744 characters in doc 181\n",
      "There are 1609 characters in doc 182\n",
      "There are 1643 characters in doc 183\n",
      "There are 1400 characters in doc 184\n",
      "There are 1497 characters in doc 185\n",
      "There are 1584 characters in doc 186\n",
      "There are 1569 characters in doc 187\n",
      "There are 1511 characters in doc 188\n",
      "There are 1616 characters in doc 189\n",
      "There are 800 characters in doc 190\n",
      "There are 976 characters in doc 191\n",
      "There are 1744 characters in doc 192\n",
      "There are 1561 characters in doc 193\n",
      "There are 1508 characters in doc 194\n",
      "There are 1323 characters in doc 195\n",
      "There are 1470 characters in doc 196\n",
      "There are 1571 characters in doc 197\n",
      "There are 1713 characters in doc 198\n",
      "There are 1432 characters in doc 199\n",
      "There are 1629 characters in doc 200\n",
      "There are 1517 characters in doc 201\n",
      "There are 1633 characters in doc 202\n",
      "There are 1367 characters in doc 203\n",
      "There are 582 characters in doc 204\n",
      "There are 980 characters in doc 205\n",
      "There are 1656 characters in doc 206\n",
      "There are 1568 characters in doc 207\n",
      "There are 1642 characters in doc 208\n",
      "There are 1698 characters in doc 209\n",
      "There are 1621 characters in doc 210\n",
      "There are 1601 characters in doc 211\n",
      "There are 1495 characters in doc 212\n",
      "There are 1321 characters in doc 213\n",
      "There are 1688 characters in doc 214\n",
      "There are 1649 characters in doc 215\n",
      "There are 1610 characters in doc 216\n",
      "There are 1805 characters in doc 217\n",
      "There are 1731 characters in doc 218\n",
      "There are 1769 characters in doc 219\n",
      "There are 1690 characters in doc 220\n",
      "There are 1388 characters in doc 221\n",
      "There are 1225 characters in doc 222\n",
      "There are 1378 characters in doc 223\n",
      "There are 1603 characters in doc 224\n",
      "There are 944 characters in doc 225\n",
      "There are 1007 characters in doc 226\n",
      "There are 1635 characters in doc 227\n",
      "There are 1512 characters in doc 228\n",
      "There are 1452 characters in doc 229\n",
      "There are 1489 characters in doc 230\n",
      "There are 1588 characters in doc 231\n",
      "There are 1643 characters in doc 232\n",
      "There are 1540 characters in doc 233\n",
      "There are 1505 characters in doc 234\n",
      "There are 1589 characters in doc 235\n",
      "There are 1653 characters in doc 236\n",
      "There are 1326 characters in doc 237\n",
      "There are 1268 characters in doc 238\n",
      "There are 960 characters in doc 239\n",
      "There are 1708 characters in doc 240\n",
      "There are 1548 characters in doc 241\n",
      "There are 1534 characters in doc 242\n",
      "There are 1636 characters in doc 243\n",
      "There are 1551 characters in doc 244\n",
      "There are 1536 characters in doc 245\n",
      "There are 1395 characters in doc 246\n",
      "There are 1366 characters in doc 247\n",
      "There are 1379 characters in doc 248\n",
      "There are 1594 characters in doc 249\n",
      "There are 1472 characters in doc 250\n",
      "There are 1573 characters in doc 251\n",
      "There are 1318 characters in doc 252\n",
      "There are 1044 characters in doc 253\n",
      "There are 1803 characters in doc 254\n",
      "There are 1622 characters in doc 255\n",
      "There are 1643 characters in doc 256\n",
      "There are 1678 characters in doc 257\n",
      "There are 1506 characters in doc 258\n",
      "There are 1743 characters in doc 259\n",
      "There are 1541 characters in doc 260\n",
      "There are 1689 characters in doc 261\n",
      "There are 1691 characters in doc 262\n",
      "There are 1516 characters in doc 263\n",
      "There are 1416 characters in doc 264\n",
      "There are 1560 characters in doc 265\n",
      "There are 1723 characters in doc 266\n",
      "There are 1603 characters in doc 267\n",
      "There are 1723 characters in doc 268\n",
      "There are 1612 characters in doc 269\n",
      "There are 1449 characters in doc 270\n",
      "There are 1562 characters in doc 271\n",
      "There are 261 characters in doc 272\n",
      "There are 1007 characters in doc 273\n",
      "There are 1761 characters in doc 274\n",
      "There are 1621 characters in doc 275\n",
      "There are 1518 characters in doc 276\n",
      "There are 1719 characters in doc 277\n",
      "There are 1416 characters in doc 278\n",
      "There are 1338 characters in doc 279\n",
      "There are 1502 characters in doc 280\n",
      "There are 1554 characters in doc 281\n",
      "There are 1561 characters in doc 282\n",
      "There are 1354 characters in doc 283\n",
      "There are 1361 characters in doc 284\n",
      "There are 1508 characters in doc 285\n",
      "There are 1423 characters in doc 286\n",
      "There are 1407 characters in doc 287\n",
      "There are 1554 characters in doc 288\n",
      "There are 1548 characters in doc 289\n",
      "There are 1488 characters in doc 290\n",
      "There are 1574 characters in doc 291\n",
      "There are 1484 characters in doc 292\n",
      "There are 1447 characters in doc 293\n",
      "There are 1331 characters in doc 294\n",
      "There are 1506 characters in doc 295\n",
      "There are 1423 characters in doc 296\n",
      "There are 1400 characters in doc 297\n",
      "There are 1221 characters in doc 298\n",
      "There are 855 characters in doc 299\n",
      "There are 1604 characters in doc 300\n",
      "There are 1489 characters in doc 301\n",
      "There are 1552 characters in doc 302\n",
      "There are 1338 characters in doc 303\n",
      "There are 1624 characters in doc 304\n",
      "There are 1638 characters in doc 305\n",
      "There are 1536 characters in doc 306\n",
      "There are 1456 characters in doc 307\n",
      "There are 1504 characters in doc 308\n",
      "There are 1613 characters in doc 309\n",
      "There are 1529 characters in doc 310\n",
      "There are 1484 characters in doc 311\n",
      "There are 1340 characters in doc 312\n",
      "There are 1647 characters in doc 313\n",
      "There are 1713 characters in doc 314\n",
      "There are 1625 characters in doc 315\n",
      "There are 1582 characters in doc 316\n",
      "There are 1680 characters in doc 317\n",
      "There are 1720 characters in doc 318\n",
      "There are 1295 characters in doc 319\n",
      "There are 774 characters in doc 320\n",
      "There are 0 characters in doc 321\n",
      "There are 448 characters in doc 322\n",
      "There are 0 characters in doc 323\n",
      "There are 0 characters in doc 324\n",
      "There are 0 characters in doc 325\n",
      "There are 0 characters in doc 326\n"
     ]
    }
   ],
   "source": [
    "#### Your TASK ####\n",
    "# Explore different PDF Loaders.  Which one works the best for this file /ssdshare/share/lab4/hp-book1.pdf ,\n",
    "# which contains the full book of Harry Potter Book 1, with all the illustratons.\n",
    "## Langchain provides many other options for loaders, read the documents to find out the differences\n",
    "# See page https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf\n",
    "\n",
    "data_1 = PyPDFLoader(\"/ssdshare/share/lab4/hp-book1.pdf\").load()\n",
    "print (f'You have {len(data_1)} document(s) in your data')\n",
    "i = 0\n",
    "for d in data_1:\n",
    "    print (f'There are {len(d.page_content)} characters in doc {i}')\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0c23cf-0d0a-4f79-9718-42d093fc4dd0",
   "metadata": {},
   "source": [
    "### 2.2 Create embeddings of your documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede1bbf6",
   "metadata": {},
   "source": [
    "Embedding is a model that turns a sentence into vectors, so that we can \"semantically search\" for related splits of a document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bd92c90b-7f21-4c8b-9586-41abf20b409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI embedding: slow and expensive, we do not use them here.  \n",
    "\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# openai_embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "08ee572a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.008060767315328121,\n",
       " -0.005432256031781435,\n",
       " 0.001971383113414049,\n",
       " -0.009462639689445496,\n",
       " 0.01483648456633091,\n",
       " 0.0026139081455767155,\n",
       " 0.010163575410842896,\n",
       " 0.009813107550144196,\n",
       " -0.005461461842060089,\n",
       " 0.012266384437680244,\n",
       " -0.0015113938134163618,\n",
       " -0.0027015251107513905,\n",
       " 0.016004711389541626,\n",
       " 0.015303774736821651,\n",
       " 0.008236001245677471,\n",
       " 0.014894895255565643,\n",
       " -0.01962621510028839,\n",
       " 0.005841135513037443,\n",
       " 0.0042640287429094315,\n",
       " 0.039486076682806015,\n",
       " -0.007243007887154818,\n",
       " 0.010455632582306862,\n",
       " 0.01273367553949356,\n",
       " -0.022313138470053673,\n",
       " -0.008119178004562855,\n",
       " -0.0016720250714570284,\n",
       " 0.0019129718421027064,\n",
       " 0.00899534858763218,\n",
       " -0.0022050286643207073,\n",
       " 0.01962621510028839,\n",
       " -0.0016866278601810336,\n",
       " -0.022313138470053673,\n",
       " 0.02686922252178192,\n",
       " 0.01693929359316826,\n",
       " 0.0011609257198870182,\n",
       " 0.005403050221502781,\n",
       " -0.015654243528842926,\n",
       " 0.014135547913610935,\n",
       " -0.0010148972505703568,\n",
       " 0.0017961491830646992,\n",
       " -0.02383183315396309,\n",
       " -0.004760525655001402,\n",
       " -0.004731319844722748,\n",
       " -0.019158923998475075,\n",
       " 0.013901902362704277,\n",
       " -0.002964376239106059,\n",
       " -0.030607549473643303,\n",
       " 0.03271035850048065,\n",
       " 0.02102808840572834,\n",
       " 0.011682271026074886,\n",
       " 0.0038843550719320774,\n",
       " 0.0009637873736210167,\n",
       " 0.006425248924642801,\n",
       " -0.004585291258990765,\n",
       " 0.005461461842060089,\n",
       " 0.014661249704658985,\n",
       " -0.006016369443386793,\n",
       " 0.0033878586255013943,\n",
       " -0.022196315228939056,\n",
       " -0.016705647110939026,\n",
       " -0.01857481151819229,\n",
       " -0.027453336864709854,\n",
       " -0.009637873619794846,\n",
       " 0.012149562127888203,\n",
       " -0.0069509511813521385,\n",
       " 0.002891362179070711,\n",
       " 0.00432244036346674,\n",
       " 0.008236001245677471,\n",
       " -0.0020151918288320303,\n",
       " -0.013200966641306877,\n",
       " -0.02102808840572834,\n",
       " 0.014486015774309635,\n",
       " -0.0008615675033070147,\n",
       " 0.00467290822416544,\n",
       " -0.00267231953330338,\n",
       " 0.021845847368240356,\n",
       " -0.024415945634245872,\n",
       " -0.005957958288490772,\n",
       " -0.020794441923499107,\n",
       " 0.0025993052404373884,\n",
       " 0.0033148443326354027,\n",
       " 0.00671730563044548,\n",
       " -0.02967296913266182,\n",
       " -0.014252370223402977,\n",
       " 0.007535064592957497,\n",
       " -0.026401933282613754,\n",
       " -0.01822434365749359,\n",
       " 0.0040011778473854065,\n",
       " -0.014427605085074902,\n",
       " -0.0002391214802628383,\n",
       " -0.00671730563044548,\n",
       " 0.00267231953330338,\n",
       " -0.0001515044568805024,\n",
       " 0.0002537243126425892,\n",
       " -0.0006753812776878476,\n",
       " -0.010806100443005562,\n",
       " 0.0029205677565187216,\n",
       " -0.00040340342093259096,\n",
       " -0.01962621510028839,\n",
       " 0.010280398651957512,\n",
       " 0.010806100443005562,\n",
       " 0.026635577902197838,\n",
       " 0.025584174320101738,\n",
       " -0.008411235176026821,\n",
       " -0.004059589002281427,\n",
       " -0.01764022931456566,\n",
       " 0.014602839015424252,\n",
       " -0.009696285240352154,\n",
       " 0.009696285240352154,\n",
       " -0.017172938212752342,\n",
       " -0.020093506202101707,\n",
       " -0.003942766226828098,\n",
       " -0.0020443974062800407,\n",
       " 0.00284755346365273,\n",
       " -0.009871519170701504,\n",
       " -0.007096979767084122,\n",
       " -0.00551987299695611,\n",
       " 0.005811929702758789,\n",
       " 0.005315433256328106,\n",
       " 0.05373844504356384,\n",
       " 0.007272213697433472,\n",
       " -0.0030373905319720507,\n",
       " 0.00917058251798153,\n",
       " -0.015303774736821651,\n",
       " 0.0022926456294953823,\n",
       " -0.014077136293053627,\n",
       " 0.007330624852329493,\n",
       " -0.030140258371829987,\n",
       " 0.015303774736821651,\n",
       " 0.011565448716282845,\n",
       " -0.02102808840572834,\n",
       " -0.022313138470053673,\n",
       " 0.019509391859173775,\n",
       " -0.011331803165376186,\n",
       " 0.015654243528842926,\n",
       " -0.013901902362704277,\n",
       " -0.0033878586255013943,\n",
       " -0.008761703036725521,\n",
       " -0.002438673982396722,\n",
       " 0.026285110041499138,\n",
       " 0.03317764773964882,\n",
       " 0.0008506153826601803,\n",
       " 0.01927574723958969,\n",
       " -0.034345876425504684,\n",
       " -0.020210329443216324,\n",
       " -0.011857504956424236,\n",
       " -0.016355179250240326,\n",
       " -0.014310781843960285,\n",
       " 0.0004198316019028425,\n",
       " -0.0035776954609900713,\n",
       " -0.008703291416168213,\n",
       " -0.01892527937889099,\n",
       " -0.018457988277077675,\n",
       " -0.004906553775072098,\n",
       " 0.008878526277840137,\n",
       " 0.002278042957186699,\n",
       " -0.005753518547862768,\n",
       " 0.027686981484293938,\n",
       " -0.013493022881448269,\n",
       " 0.016355179250240326,\n",
       " -0.015303774736821651,\n",
       " -0.0018545605707913637,\n",
       " 0.014135547913610935,\n",
       " -0.0008980745915323496,\n",
       " -0.013901902362704277,\n",
       " 0.00233645411208272,\n",
       " 0.005549078807234764,\n",
       " 0.004030383657664061,\n",
       " -0.009579461999237537,\n",
       " 0.026285110041499138,\n",
       " -0.007418242283165455,\n",
       " -0.002964376239106059,\n",
       " -0.01588788814842701,\n",
       " 0.004964965395629406,\n",
       " -0.012207972817122936,\n",
       " -0.01308414340019226,\n",
       " 0.018808456137776375,\n",
       " -0.0035922983661293983,\n",
       " -0.00027015252271667123,\n",
       " 0.01834116503596306,\n",
       " -0.0070385681465268135,\n",
       " -0.003855149494484067,\n",
       " -0.009988341480493546,\n",
       " 0.003636106848716736,\n",
       " 0.026986045762896538,\n",
       " 0.005461461842060089,\n",
       " -0.018107520416378975,\n",
       " -0.010806100443005562,\n",
       " -0.0010733086382970214,\n",
       " -0.010630866512656212,\n",
       " 0.004059589002281427,\n",
       " -0.017873873934149742,\n",
       " -0.0064836605452001095,\n",
       " -0.023014074191451073,\n",
       " 0.006133192218840122,\n",
       " 0.0043516457080841064,\n",
       " -0.012266384437680244,\n",
       " 0.006600483320653439,\n",
       " 0.0032856387551873922,\n",
       " 0.004030383657664061,\n",
       " 0.022313138470053673,\n",
       " 0.015070129185914993,\n",
       " -0.010455632582306862,\n",
       " 0.014602839015424252,\n",
       " -0.017757052555680275,\n",
       " -0.028154272586107254,\n",
       " -0.013785080052912235,\n",
       " -0.008528057485818863,\n",
       " -0.010397220961749554,\n",
       " -0.009929930791258812,\n",
       " 0.0017231350066140294,\n",
       " -0.003460872685536742,\n",
       " 0.008528057485818863,\n",
       " 0.016472002491354942,\n",
       " -0.004848142620176077,\n",
       " -0.03037390485405922,\n",
       " 0.025700995698571205,\n",
       " 0.02383183315396309,\n",
       " -0.007593476213514805,\n",
       " 0.008878526277840137,\n",
       " 0.010221987031400204,\n",
       " 0.028387919068336487,\n",
       " 0.005081787705421448,\n",
       " -0.02862156368792057,\n",
       " 0.00449767429381609,\n",
       " -0.010922923684120178,\n",
       " -0.0035192840732634068,\n",
       " -0.0009783902205526829,\n",
       " -0.002759936498478055,\n",
       " -0.0006133192218840122,\n",
       " -0.024065477773547173,\n",
       " -0.01693929359316826,\n",
       " 0.006512865889817476,\n",
       " -0.003971972037106752,\n",
       " 0.007768710143864155,\n",
       " -0.02488323673605919,\n",
       " -0.014193959534168243,\n",
       " -0.005665901582688093,\n",
       " 0.02581781893968582,\n",
       " -0.023014074191451073,\n",
       " 0.005461461842060089,\n",
       " -0.018457988277077675,\n",
       " -0.008586469106376171,\n",
       " 0.006308426149189472,\n",
       " -0.006600483320653439,\n",
       " -0.03107484057545662,\n",
       " -0.002380262827500701,\n",
       " 0.017873873934149742,\n",
       " 0.014953306876122952,\n",
       " -0.006074781063944101,\n",
       " 0.008761703036725521,\n",
       " -0.03738326579332352,\n",
       " 0.018457988277077675,\n",
       " 0.0009163281065411866,\n",
       " 0.0019129718421027064,\n",
       " -0.01892527937889099,\n",
       " 0.009404228068888187,\n",
       " -0.000635223463177681,\n",
       " 0.018107520416378975,\n",
       " 0.003460872685536742,\n",
       " -0.0011244185734540224,\n",
       " -0.029205678030848503,\n",
       " 0.012091150507330894,\n",
       " 0.012266384437680244,\n",
       " -0.0041764117777347565,\n",
       " 0.0017596420366317034,\n",
       " -0.01588788814842701,\n",
       " -0.010397220961749554,\n",
       " -0.002686922438442707,\n",
       " -0.008294411934912205,\n",
       " -0.0024970853701233864,\n",
       " 0.0020005889236927032,\n",
       " 0.003081199014559388,\n",
       " 0.017172938212752342,\n",
       " -0.01068927813321352,\n",
       " 0.006162398029118776,\n",
       " 0.025000059977173805,\n",
       " -0.0014529824256896973,\n",
       " -0.019509391859173775,\n",
       " 0.0014456810895353556,\n",
       " -0.0016866278601810336,\n",
       " -0.02383183315396309,\n",
       " 0.02313089743256569,\n",
       " -0.02651875466108322,\n",
       " -0.01086451206356287,\n",
       " 0.0022926456294953823,\n",
       " 0.027336513623595238,\n",
       " 0.03317764773964882,\n",
       " -0.01238320767879486,\n",
       " -0.0028037449810653925,\n",
       " -0.008411235176026821,\n",
       " -0.0008652181713841856,\n",
       " 0.005373844876885414,\n",
       " 0.018107520416378975,\n",
       " -0.006103986408561468,\n",
       " -0.021261733025312424,\n",
       " -0.0013434612192213535,\n",
       " 0.0012266384437680244,\n",
       " 0.03831784799695015,\n",
       " 0.0008980745915323496,\n",
       " -0.032944004982709885,\n",
       " -0.014661249704658985,\n",
       " -0.014602839015424252,\n",
       " 0.007710298988968134,\n",
       " -0.011974328197538853,\n",
       " 0.017406582832336426,\n",
       " -0.002540893852710724,\n",
       " -0.00882011465728283,\n",
       " -0.008936936967074871,\n",
       " -0.021612200886011124,\n",
       " -0.035046812146902084,\n",
       " -0.01483648456633091,\n",
       " -0.009112171828746796,\n",
       " 0.0022926456294953823,\n",
       " 0.012441618368029594,\n",
       " 0.04485991969704628,\n",
       " -0.019509391859173775,\n",
       " 0.01518695242702961,\n",
       " 0.02207949198782444,\n",
       " -0.002453276887536049,\n",
       " -0.01962621510028839,\n",
       " -0.026752401143312454,\n",
       " -0.0006936348509043455,\n",
       " 0.013551434502005577,\n",
       " 0.029439322650432587,\n",
       " 0.007710298988968134,\n",
       " -0.005899546667933464,\n",
       " 0.01290890946984291,\n",
       " -0.020093506202101707,\n",
       " -0.012324796058237553,\n",
       " -0.01799069717526436,\n",
       " 0.016121534630656242,\n",
       " 0.01962621510028839,\n",
       " 0.019509391859173775,\n",
       " -0.014602839015424252,\n",
       " 0.011740682646632195,\n",
       " -0.005899546667933464,\n",
       " -0.003168815979734063,\n",
       " 0.04415898397564888,\n",
       " 0.004877347964793444,\n",
       " -0.010922923684120178,\n",
       " -0.014661249704658985,\n",
       " -0.016121534630656242,\n",
       " -0.010455632582306862,\n",
       " -0.0006242713425308466,\n",
       " 0.001869163359515369,\n",
       " 0.023014074191451073,\n",
       " 0.0043808515183627605,\n",
       " -0.023247718811035156,\n",
       " 0.008528057485818863,\n",
       " -0.01822434365749359,\n",
       " 0.009871519170701504,\n",
       " 0.01892527937889099,\n",
       " 0.00882011465728283,\n",
       " 0.029205678030848503,\n",
       " -0.009053760208189487,\n",
       " -0.008119178004562855,\n",
       " 0.0041764117777347565,\n",
       " 0.003256432944908738,\n",
       " -0.006454454734921455,\n",
       " -0.0007739504799246788,\n",
       " 0.01483648456633091,\n",
       " -0.014310781843960285,\n",
       " -0.013726668432354927,\n",
       " 0.012792087160050869,\n",
       " 0.011915916576981544,\n",
       " -0.010397220961749554,\n",
       " 0.003825943684205413,\n",
       " -0.017523406073451042,\n",
       " 0.0035922983661293983,\n",
       " 0.008528057485818863,\n",
       " -0.014602839015424252,\n",
       " 0.006921745371073484,\n",
       " 0.0067465114407241344,\n",
       " -0.10046753287315369,\n",
       " -0.00046729083987884223,\n",
       " -0.017406582832336426,\n",
       " -0.012675263918936253,\n",
       " 0.003256432944908738,\n",
       " -0.02032715082168579,\n",
       " -0.017056114971637726,\n",
       " -0.020911265164613724,\n",
       " 0.020443974062800407,\n",
       " -0.01139021385461092,\n",
       " -0.00432244036346674,\n",
       " 0.020794441923499107,\n",
       " 0.008703291416168213,\n",
       " 0.009579461999237537,\n",
       " -0.006892540026456118,\n",
       " -0.0008177589625120163,\n",
       " 0.013960313983261585,\n",
       " -0.010981334373354912,\n",
       " 0.00551987299695611,\n",
       " 0.019509391859173775,\n",
       " -0.007593476213514805,\n",
       " 0.005227816291153431,\n",
       " 0.0022196315694600344,\n",
       " -0.03411222994327545,\n",
       " -0.03971972316503525,\n",
       " 0.003066596109420061,\n",
       " -0.0035776954609900713,\n",
       " -0.004848142620176077,\n",
       " -0.016004711389541626,\n",
       " 0.007330624852329493,\n",
       " -0.010221987031400204,\n",
       " 0.013551434502005577,\n",
       " 0.013376200571656227,\n",
       " 0.016472002491354942,\n",
       " 0.001438379636965692,\n",
       " 0.014778072945773602,\n",
       " 0.013493022881448269,\n",
       " -0.010455632582306862,\n",
       " -0.0008834717446006835,\n",
       " 0.030140258371829987,\n",
       " 0.0020005889236927032,\n",
       " 0.0031250074971467257,\n",
       " 0.016705647110939026,\n",
       " -0.0008798210183158517,\n",
       " -0.01139021385461092,\n",
       " 0.04275711253285408,\n",
       " 0.007213802542537451,\n",
       " 0.02137855626642704,\n",
       " 0.020443974062800407,\n",
       " 0.01869163289666176,\n",
       " -0.022313138470053673,\n",
       " -0.01857481151819229,\n",
       " 0.022897250950336456,\n",
       " -0.016472002491354942,\n",
       " -0.01033881027251482,\n",
       " -0.0021320143714547157,\n",
       " -0.0005366543191485107,\n",
       " 0.0003632456064224243,\n",
       " -0.026986045762896538,\n",
       " -0.01869163289666176,\n",
       " -0.01033881027251482,\n",
       " -0.0015844079898670316,\n",
       " 0.008761703036725521,\n",
       " -0.030841195955872536,\n",
       " 0.008528057485818863,\n",
       " -0.0036799153313040733,\n",
       " 0.02476641535758972,\n",
       " -0.0037091211415827274,\n",
       " -0.0016209151363000274,\n",
       " 0.012441618368029594,\n",
       " -0.03691597655415535,\n",
       " 0.012967321090400219,\n",
       " -0.029906613752245903,\n",
       " -0.01799069717526436,\n",
       " -0.00899534858763218,\n",
       " -0.017172938212752342,\n",
       " -0.004964965395629406,\n",
       " 0.008002355694770813,\n",
       " -0.00864488072693348,\n",
       " 0.0039135608822107315,\n",
       " 0.0036799153313040733,\n",
       " -0.005257022101432085,\n",
       " 0.01553742028772831,\n",
       " -0.02523370459675789,\n",
       " 0.0009856915567070246,\n",
       " 0.00335865281522274,\n",
       " -0.03247671201825142,\n",
       " 0.003446270013228059,\n",
       " 0.0032418302726000547,\n",
       " 0.0021758228540420532,\n",
       " 0.012032738886773586,\n",
       " -0.0036945182364434004,\n",
       " 0.041588883846998215,\n",
       " 0.00917058251798153,\n",
       " 0.005081787705421448,\n",
       " -0.0044684684835374355,\n",
       " 0.028037451207637787,\n",
       " 0.006921745371073484,\n",
       " -0.00019531296857167035,\n",
       " 0.02827109582722187,\n",
       " 0.03411222994327545,\n",
       " 0.01103974599391222,\n",
       " -0.009112171828746796,\n",
       " -0.00012777483789250255,\n",
       " 0.0020005889236927032,\n",
       " 0.0063960435800254345,\n",
       " -0.007184596732258797,\n",
       " 0.010630866512656212,\n",
       " -0.012207972817122936,\n",
       " 0.01834116503596306,\n",
       " -0.002745333593338728,\n",
       " 0.0042932345531880856,\n",
       " -0.01273367553949356,\n",
       " 0.0035046814009547234,\n",
       " -0.015070129185914993,\n",
       " 0.033644940704107285,\n",
       " -0.022897250950336456,\n",
       " 0.009696285240352154,\n",
       " 0.005549078807234764,\n",
       " -0.007710298988968134,\n",
       " 0.021845847368240356,\n",
       " 0.00516940513625741,\n",
       " 0.006600483320653439,\n",
       " -0.021495379507541656,\n",
       " 0.029789790511131287,\n",
       " 0.009696285240352154,\n",
       " -0.009404228068888187,\n",
       " -0.00023182007134892046,\n",
       " -0.003081199014559388,\n",
       " -0.02207949198782444,\n",
       " -0.015303774736821651,\n",
       " -0.005286227446049452,\n",
       " 0.01325937733054161,\n",
       " -0.003738326719030738,\n",
       " -0.008352823555469513,\n",
       " 0.013960313983261585,\n",
       " -0.02418230101466179,\n",
       " 0.0018837661482393742,\n",
       " -0.002248837146908045,\n",
       " -0.0039135608822107315,\n",
       " 0.014894895255565643,\n",
       " 0.0016866278601810336,\n",
       " 0.006425248924642801,\n",
       " 0.01086451206356287,\n",
       " -0.017056114971637726,\n",
       " 0.031542129814624786,\n",
       " 0.009287405759096146,\n",
       " 0.006162398029118776,\n",
       " -0.017406582832336426,\n",
       " -0.014193959534168243,\n",
       " 0.006279220804572105,\n",
       " -0.002073602983728051,\n",
       " 0.016004711389541626,\n",
       " 0.006512865889817476,\n",
       " -0.0013069540727883577,\n",
       " -0.011565448716282845,\n",
       " 0.0027161280158907175,\n",
       " 0.012850497849285603,\n",
       " 0.0024094684049487114,\n",
       " 0.0065712775103747845,\n",
       " -0.002380262827500701,\n",
       " 0.004848142620176077,\n",
       " 0.007651887368410826,\n",
       " -0.011740682646632195,\n",
       " -0.011331803165376186,\n",
       " 0.02278042770922184,\n",
       " 0.004147205967456102,\n",
       " 0.013025731779634953,\n",
       " -0.00899534858763218,\n",
       " 0.0001487664267187938,\n",
       " 0.013609846122562885,\n",
       " 0.01518695242702961,\n",
       " -0.009929930791258812,\n",
       " 0.006454454734921455,\n",
       " -0.007535064592957497,\n",
       " 0.01857481151819229,\n",
       " 0.005987164098769426,\n",
       " -0.010105164721608162,\n",
       " 0.025000059977173805,\n",
       " 0.01588788814842701,\n",
       " 0.012967321090400219,\n",
       " -0.017406582832336426,\n",
       " -0.02102808840572834,\n",
       " -0.005081787705421448,\n",
       " 0.006103986408561468,\n",
       " 0.001474886666983366,\n",
       " -0.008236001245677471,\n",
       " 0.00619160383939743,\n",
       " -0.005023376550525427,\n",
       " -0.009462639689445496,\n",
       " -0.016355179250240326,\n",
       " -0.01892527937889099,\n",
       " 0.02032715082168579,\n",
       " 0.006074781063944101,\n",
       " 0.011682271026074886,\n",
       " 0.00267231953330338,\n",
       " 0.010221987031400204,\n",
       " -0.003825943684205413,\n",
       " 0.012967321090400219,\n",
       " 0.0003541188489180058,\n",
       " 0.011974328197538853,\n",
       " -0.01255844160914421,\n",
       " -0.0069509511813521385,\n",
       " 0.008177589625120163,\n",
       " 0.0040887948125600815,\n",
       " -0.01343461126089096,\n",
       " -0.005490667186677456,\n",
       " -0.007009362801909447,\n",
       " 0.0063960435800254345,\n",
       " -0.023014074191451073,\n",
       " 0.016004711389541626,\n",
       " -0.008294411934912205,\n",
       " 0.001730436342768371,\n",
       " -0.007213802542537451,\n",
       " 0.008002355694770813,\n",
       " -0.023247718811035156,\n",
       " 0.008586469106376171,\n",
       " 0.021144909784197807,\n",
       " -0.009696285240352154,\n",
       " -0.002263440052047372,\n",
       " -0.005870341323316097,\n",
       " 0.001080610090866685,\n",
       " -0.014077136293053627,\n",
       " 0.0043516457080841064,\n",
       " -0.009696285240352154,\n",
       " -0.0027015251107513905,\n",
       " -0.00432244036346674,\n",
       " 0.005490667186677456,\n",
       " -0.010397220961749554,\n",
       " -0.0018983690533787012,\n",
       " 0.005490667186677456,\n",
       " 0.021845847368240356,\n",
       " -0.0023218514397740364,\n",
       " 0.012149562127888203,\n",
       " 0.04322440177202225,\n",
       " 0.003168815979734063,\n",
       " 0.010221987031400204,\n",
       " -0.0043516457080841064,\n",
       " -0.006834128405898809,\n",
       " 0.009404228068888187,\n",
       " 0.008586469106376171,\n",
       " -0.008936936967074871,\n",
       " -0.0037967381067574024,\n",
       " 0.009462639689445496,\n",
       " 0.012441618368029594,\n",
       " 0.009871519170701504,\n",
       " -0.004994170740246773,\n",
       " -0.02897203154861927,\n",
       " -0.010105164721608162,\n",
       " -0.02383183315396309,\n",
       " 0.005987164098769426,\n",
       " -0.014018725603818893,\n",
       " 0.0014091739431023598,\n",
       " 0.011915916576981544,\n",
       " -0.003081199014559388,\n",
       " 0.008060767315328121,\n",
       " 0.01518695242702961,\n",
       " 0.00534463906660676,\n",
       " -0.005257022101432085,\n",
       " -0.012324796058237553,\n",
       " -0.02511688321828842,\n",
       " 0.014018725603818893,\n",
       " 0.011098157614469528,\n",
       " 0.01308414340019226,\n",
       " 0.006045575253665447,\n",
       " -0.0040011778473854065,\n",
       " 0.02418230101466179,\n",
       " 0.015771064907312393,\n",
       " 0.01121497992426157,\n",
       " 0.01518695242702961,\n",
       " -0.0010660071857273579,\n",
       " 0.005081787705421448,\n",
       " 0.008586469106376171,\n",
       " -0.007096979767084122,\n",
       " -0.011448625475168228,\n",
       " -0.006980156991630793,\n",
       " 0.010221987031400204,\n",
       " 0.009871519170701504,\n",
       " 0.009871519170701504,\n",
       " -0.010922923684120178,\n",
       " -0.010572454892098904,\n",
       " 0.0013653654605150223,\n",
       " -0.011974328197538853,\n",
       " -0.009462639689445496,\n",
       " -0.021962668746709824,\n",
       " 0.012324796058237553,\n",
       " 0.01553742028772831,\n",
       " -0.012032738886773586,\n",
       " 0.0019129718421027064,\n",
       " -0.007535064592957497,\n",
       " 0.01518695242702961,\n",
       " -0.01588788814842701,\n",
       " -0.005753518547862768,\n",
       " -0.01658882386982441,\n",
       " 0.000514750077854842,\n",
       " -0.0069509511813521385,\n",
       " -0.013317788951098919,\n",
       " 0.005432256031781435,\n",
       " -0.014310781843960285,\n",
       " -0.013317788951098919,\n",
       " 0.02418230101466179,\n",
       " -0.011565448716282845,\n",
       " 0.004410057328641415,\n",
       " 0.011857504956424236,\n",
       " -0.0013507625553756952,\n",
       " 0.008002355694770813,\n",
       " -0.0004216569650452584,\n",
       " 0.0025116882752627134,\n",
       " -0.07289737462997437,\n",
       " 0.01033881027251482,\n",
       " 0.03925243020057678,\n",
       " -0.014135547913610935,\n",
       " -0.0017961491830646992,\n",
       " 0.0066881002858281136,\n",
       " 0.007272213697433472,\n",
       " -0.013025731779634953,\n",
       " 0.03247671201825142,\n",
       " -0.01051404420286417,\n",
       " 0.007389036472886801,\n",
       " -0.02207949198782444,\n",
       " 0.02792062796652317,\n",
       " 0.008119178004562855,\n",
       " -0.006045575253665447,\n",
       " -0.0024240713100880384,\n",
       " 0.017056114971637726,\n",
       " 0.00846964679658413,\n",
       " -0.010046753101050854,\n",
       " -0.012266384437680244,\n",
       " -0.03387858718633652,\n",
       " -0.0007958547212183475,\n",
       " -0.020093506202101707,\n",
       " -0.005461461842060089,\n",
       " -0.015654243528842926,\n",
       " 0.003066596109420061,\n",
       " -0.034345876425504684,\n",
       " -0.011507037095725536,\n",
       " -0.011799093335866928,\n",
       " -0.010397220961749554,\n",
       " -0.011098157614469528,\n",
       " -0.003548489883542061,\n",
       " 0.004118000622838736,\n",
       " 0.02476641535758972,\n",
       " 0.002540893852710724,\n",
       " 0.007943944074213505,\n",
       " 0.0021758228540420532,\n",
       " -0.021261733025312424,\n",
       " 0.044626276940107346,\n",
       " -0.0025262911804020405,\n",
       " -0.014778072945773602,\n",
       " -0.005227816291153431,\n",
       " 0.04485991969704628,\n",
       " 0.008119178004562855,\n",
       " 0.027686981484293938,\n",
       " 0.020210329443216324,\n",
       " 0.01869163289666176,\n",
       " -0.01588788814842701,\n",
       " -0.003051993204280734,\n",
       " -0.01869163289666176,\n",
       " -0.012967321090400219,\n",
       " 0.0007301419391296804,\n",
       " 0.020210329443216324,\n",
       " -0.005636695772409439,\n",
       " 0.026752401143312454,\n",
       " -0.01962621510028839,\n",
       " 0.013901902362704277,\n",
       " -0.0018326562130823731,\n",
       " -0.02242995984852314,\n",
       " 0.012207972817122936,\n",
       " 0.011799093335866928,\n",
       " 0.000668079883325845,\n",
       " -0.01857481151819229,\n",
       " -0.02032715082168579,\n",
       " 0.002774539403617382,\n",
       " -0.01764022931456566,\n",
       " -0.004059589002281427,\n",
       " -0.026051463559269905,\n",
       " -0.008119178004562855,\n",
       " 0.021845847368240356,\n",
       " 0.0065712775103747845,\n",
       " 0.0016939293127506971,\n",
       " 0.022196315228939056,\n",
       " 0.0,\n",
       " -0.010397220961749554,\n",
       " 0.00882011465728283,\n",
       " -0.013960313983261585,\n",
       " -0.002482482697814703,\n",
       " -0.020794441923499107,\n",
       " 0.0065712775103747845,\n",
       " -0.0007301419391296804,\n",
       " -0.005432256031781435,\n",
       " 0.004643702879548073,\n",
       " 0.008119178004562855,\n",
       " -0.013785080052912235,\n",
       " -0.0033294472377747297,\n",
       " -0.002891362179070711,\n",
       " 0.008411235176026821,\n",
       " 0.009696285240352154,\n",
       " 0.006045575253665447,\n",
       " -0.0024094684049487114,\n",
       " -0.017873873934149742,\n",
       " -0.012032738886773586,\n",
       " -0.02383183315396309,\n",
       " 0.024649592116475105,\n",
       " 0.02932249940931797,\n",
       " -0.010806100443005562,\n",
       " 0.028387919068336487,\n",
       " -0.021144909784197807,\n",
       " 0.01693929359316826,\n",
       " 0.01728976145386696,\n",
       " -0.003942766226828098,\n",
       " 0.001182829961180687,\n",
       " 0.018808456137776375,\n",
       " -0.009637873619794846,\n",
       " 0.02721969224512577,\n",
       " 0.008352823555469513,\n",
       " -0.006337631959468126,\n",
       " 0.0006206206744536757,\n",
       " -0.0031250074971467257,\n",
       " 0.009112171828746796,\n",
       " 0.02032715082168579,\n",
       " -0.0016939293127506971,\n",
       " -0.022313138470053673,\n",
       " -0.008119178004562855,\n",
       " -0.0011536242673173547,\n",
       " 0.0022926456294953823,\n",
       " 0.01658882386982441,\n",
       " -0.00619160383939743,\n",
       " 0.0036653124261647463,\n",
       " 0.00934581644833088,\n",
       " 0.017523406073451042,\n",
       " 0.002570099662989378,\n",
       " -0.010046753101050854,\n",
       " 0.003271035850048065,\n",
       " -0.008703291416168213,\n",
       " 0.006834128405898809,\n",
       " -0.016121534630656242,\n",
       " 0.02032715082168579,\n",
       " -0.03037390485405922,\n",
       " -0.013901902362704277,\n",
       " 0.0033148443326354027,\n",
       " -0.01869163289666176,\n",
       " 0.03247671201825142,\n",
       " -0.005227816291153431,\n",
       " 0.004935759585350752,\n",
       " 0.014018725603818893,\n",
       " 2.0078903617104515e-05,\n",
       " -0.000992993009276688,\n",
       " -0.005052582360804081,\n",
       " 0.016705647110939026,\n",
       " 0.026285110041499138,\n",
       " 0.004030383657664061,\n",
       " -0.015420597977936268,\n",
       " 0.00020900313393212855,\n",
       " -0.016705647110939026,\n",
       " 0.013551434502005577,\n",
       " -0.009754695929586887,\n",
       " 0.025700995698571205,\n",
       " 0.02383183315396309,\n",
       " -0.0042640287429094315,\n",
       " -0.012091150507330894,\n",
       " 0.001766943489201367,\n",
       " -0.020210329443216324,\n",
       " -0.0010221987031400204,\n",
       " -0.0015186952659860253,\n",
       " -0.01834116503596306,\n",
       " -0.002453276887536049,\n",
       " 0.01051404420286417,\n",
       " 0.00467290822416544,\n",
       " 0.015420597977936268,\n",
       " -0.01623835600912571,\n",
       " 0.020794441923499107,\n",
       " 0.009404228068888187,\n",
       " -0.022546783089637756,\n",
       " -0.004585291258990765,\n",
       " 0.009929930791258812,\n",
       " -0.008411235176026821,\n",
       " 0.022313138470053673,\n",
       " -0.02546735107898712,\n",
       " 0.011857504956424236,\n",
       " 0.017523406073451042,\n",
       " -0.006892540026456118,\n",
       " 0.024299124255776405,\n",
       " 0.016472002491354942,\n",
       " -0.01857481151819229,\n",
       " -0.00569510692730546,\n",
       " -0.006834128405898809,\n",
       " -0.02581781893968582,\n",
       " 0.00846964679658413,\n",
       " 0.023948656395077705,\n",
       " -0.013843490742146969,\n",
       " 0.007943944074213505,\n",
       " -0.013960313983261585,\n",
       " -0.008060767315328121,\n",
       " 0.008528057485818863,\n",
       " 0.012091150507330894,\n",
       " -0.018808456137776375,\n",
       " -0.014018725603818893,\n",
       " -0.006074781063944101,\n",
       " -0.006980156991630793,\n",
       " -0.006600483320653439,\n",
       " -0.003971972037106752,\n",
       " 0.007593476213514805,\n",
       " -0.006804923061281443,\n",
       " -0.007593476213514805,\n",
       " 0.0069509511813521385,\n",
       " -0.010280398651957512,\n",
       " -0.006250014994293451,\n",
       " -0.004760525655001402,\n",
       " -0.012091150507330894,\n",
       " -0.024299124255776405,\n",
       " 0.0065712775103747845,\n",
       " 0.008761703036725521,\n",
       " -0.0041764117777347565,\n",
       " 0.0007301419391296804,\n",
       " -0.005110993515700102,\n",
       " -0.0008360125357285142,\n",
       " 0.028738386929035187,\n",
       " 0.014953306876122952,\n",
       " 0.02862156368792057,\n",
       " 0.019743038341403008,\n",
       " -0.0036945182364434004,\n",
       " 0.030841195955872536,\n",
       " 0.015654243528842926,\n",
       " -0.004234823398292065,\n",
       " 0.019042102620005608,\n",
       " -0.0042932345531880856,\n",
       " -0.005987164098769426,\n",
       " 0.007827121764421463,\n",
       " 0.012324796058237553,\n",
       " 0.004439263138920069,\n",
       " -0.005081787705421448,\n",
       " -0.008528057485818863,\n",
       " -0.006425248924642801,\n",
       " -0.01962621510028839,\n",
       " 0.027102869004011154,\n",
       " 0.024649592116475105,\n",
       " -0.003825943684205413,\n",
       " -0.0010514043970033526,\n",
       " -0.025934642180800438,\n",
       " -0.03387858718633652,\n",
       " 0.0001432903518434614,\n",
       " 0.0033294472377747297,\n",
       " 0.01343461126089096,\n",
       " 0.009988341480493546,\n",
       " 0.0008725196239538491,\n",
       " -0.010806100443005562,\n",
       " 0.012324796058237553,\n",
       " 0.0009199788328260183,\n",
       " 0.0042640287429094315,\n",
       " -0.010922923684120178,\n",
       " -0.0004234823281876743,\n",
       " 0.004760525655001402,\n",
       " -0.01658882386982441,\n",
       " 0.0066588944755494595,\n",
       " -0.011857504956424236,\n",
       " -0.0025116882752627134,\n",
       " 0.05023376643657684,\n",
       " -0.011682271026074886,\n",
       " -0.02313089743256569,\n",
       " 0.022897250950336456,\n",
       " -0.005607489962130785,\n",
       " -0.00864488072693348,\n",
       " -0.010922923684120178,\n",
       " 0.005607489962130785,\n",
       " 0.010397220961749554,\n",
       " 0.0013580640079453588,\n",
       " 0.0040011778473854065,\n",
       " -0.0005731614073738456,\n",
       " 0.005724312737584114,\n",
       " -0.0029059648513793945,\n",
       " -0.011156569235026836,\n",
       " 0.008294411934912205,\n",
       " 0.0019275747472420335,\n",
       " -0.010981334373354912,\n",
       " 0.01623835600912571,\n",
       " -0.0016866278601810336,\n",
       " 0.014602839015424252,\n",
       " 0.02967296913266182,\n",
       " -0.000359594909241423,\n",
       " -0.01290890946984291,\n",
       " -0.012850497849285603,\n",
       " -0.007243007887154818,\n",
       " 0.004643702879548073,\n",
       " -0.02897203154861927,\n",
       " 0.029556145891547203,\n",
       " 0.011273391544818878,\n",
       " -0.017172938212752342,\n",
       " 0.007272213697433472,\n",
       " -0.008236001245677471,\n",
       " -0.02348136529326439,\n",
       " 0.005023376550525427,\n",
       " -0.011098157614469528,\n",
       " 0.009462639689445496,\n",
       " -0.0033440501429140568,\n",
       " -0.045327212661504745,\n",
       " 0.013960313983261585,\n",
       " 0.00014420303341466933,\n",
       " -0.009637873619794846,\n",
       " 0.012850497849285603,\n",
       " -0.03341129422187805,\n",
       " -0.002570099662989378,\n",
       " 0.005023376550525427,\n",
       " -0.003154213074594736,\n",
       " 0.004556085914373398,\n",
       " -0.005957958288490772,\n",
       " -0.015654243528842926,\n",
       " 0.026752401143312454,\n",
       " -0.011974328197538853,\n",
       " -0.005724312737584114,\n",
       " -0.010163575410842896,\n",
       " 0.019743038341403008,\n",
       " 0.013200966641306877,\n",
       " 0.007418242283165455,\n",
       " -0.0018253548769280314,\n",
       " -0.011507037095725536,\n",
       " 0.006600483320653439,\n",
       " -0.020794441923499107,\n",
       " -0.008528057485818863,\n",
       " -0.012675263918936253,\n",
       " 0.01658882386982441,\n",
       " 0.031542129814624786,\n",
       " 0.003460872685536742,\n",
       " 0.01623835600912571,\n",
       " 0.006103986408561468,\n",
       " 0.006162398029118776,\n",
       " -0.01238320767879486,\n",
       " ...]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use the SILICONFLOW BAAI embedding model instead.\n",
    "# Note infini-ai's embedding model has some issues, so we do not use it here.\n",
    "# Don't forget to set the environment variable SILICONFLOW_API_KEY!!!\n",
    "\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "load_dotenv()\n",
    "baai_embedding = OpenAIEmbeddings(\n",
    "    model=\"Qwen/Qwen3-Embedding-8B\",\n",
    "    base_url=os.environ.get(\"SF_BASE_URL\"),\n",
    "    api_key=os.environ.get(\"SF_API_KEY\"),\n",
    ")\n",
    "baai_embedding.embed_query(\"Harry Potter is a wizard.\") # test the embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b805c79-c5b1-4812-9b85-671820ff0a69",
   "metadata": {},
   "source": [
    "### 2.4  Store and retrieve the embeddings in ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c0c49f-541a-44da-8f5b-1e6059b478a6",
   "metadata": {},
   "source": [
    "You can search documents stored in \"Vector DBs\" by their semantic similarity.  Vector DBs uses an algorithm called \"KNN (k-nearest neighbors)\" to find documents whose embedding is the closest to the query. \n",
    "\n",
    "We first introduce ChromaDB becauase it runs locally, easy-to-set-up, and best of all, free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2af187c9-e90d-40be-a74f-db620af2bbb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bc968646-8efd-474a-a1aa-cfc0766636ab',\n",
       " 'e6594999-54a6-4778-95ba-6b270575fe1b',\n",
       " '2f8c15bd-08d0-4275-a212-cfbc893eefdf',\n",
       " 'd6defa32-657d-4820-b9d3-800e1bdbe940',\n",
       " 'a1a869bc-c57e-45fc-b357-9d6af919f5dd',\n",
       " 'f78d0a6d-a87b-409e-99f4-7eb55313c8ff',\n",
       " 'e845ac8a-02a9-4291-94fa-eebf28493cad',\n",
       " '1219c4e5-6df2-4378-b7ad-6be62e4ca4f8',\n",
       " 'bedd2f8d-169d-46ff-a535-ef07381363e6',\n",
       " '577c93e6-cdf1-43fc-b887-4f2acbff37c1',\n",
       " 'bd732ffb-da88-4d4a-88fc-7feaaf328e3f',\n",
       " 'e6183ee9-0ca3-4df4-926f-4105781058f1',\n",
       " 'e1523680-ad09-4d13-a554-46fea3e98e0f',\n",
       " '2c5f2c9d-c1a9-4454-baf2-c67c9eb12ef2',\n",
       " 'c5c33136-f7a5-4d9a-9e03-57f377636e6f',\n",
       " '5cfa6aec-55ea-4cac-926c-34ea6ed84bb7',\n",
       " '93cf3d76-aac1-4d66-a257-70ae54530016',\n",
       " '8dab9694-fa9d-4186-b217-93b01c4b0381',\n",
       " 'faa49a65-fb61-41f2-8e78-de3306d9b396',\n",
       " '9d38d37d-1c3b-4a09-9ff0-3d3ed93aea16',\n",
       " 'a7d5f541-f274-492b-8967-f58ee1a1d0fb',\n",
       " 'e2c91beb-00f4-49dc-b749-4a8fa5094ca0',\n",
       " '52ecc216-e104-4398-9737-b6f6b6deb7ff',\n",
       " 'e5fc0870-eff7-4b7c-966c-9bbc4a886d36',\n",
       " '89eccf93-3a21-435b-b145-937e1ceaf548',\n",
       " 'ef96fc17-6c1c-4b45-b453-724efa4b6d97',\n",
       " '199a3b35-69e1-4de0-ac8c-1d3ffedc082c',\n",
       " '50d0c651-f02e-4ef2-b973-bd9a39027693',\n",
       " 'e78e06dd-3bf6-48b6-9aeb-f389ee89e85e',\n",
       " '4ef687ef-0514-448f-9449-c2beb461a601',\n",
       " 'bdcdf50d-21e3-48ce-9eaa-9924ce147524',\n",
       " '51b36c68-ef06-4742-b5ae-8a2789b0bc59',\n",
       " '2e4d4b9c-1de8-42f8-9100-514a8857233c',\n",
       " 'd4676679-b8f2-49cd-a091-23fb4cb2ff7b',\n",
       " '18e6795b-e042-4bec-9edf-1db153d838e4',\n",
       " '398a96ed-69fc-46d6-b0ff-d9f4c77c672f',\n",
       " '1c84421c-95e3-40b5-8a6f-947501f4a1d7',\n",
       " 'c15e2530-ca2d-4a36-ab70-2df011a87bdf',\n",
       " 'f6befa1d-892c-4f62-86c7-34a16e7e5dad',\n",
       " 'd782191f-b0ab-4e69-814e-b63014019742',\n",
       " '8b0b3c4b-2179-47e6-ada3-7e15aa83fc74',\n",
       " '246b64c9-d5bc-409b-b4d2-cc0a7d39fc4c',\n",
       " '12c6b944-6993-4b12-9a50-ef2790eff3f1']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute embeddings and save the embeddings into ChromaDB\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "chroma_dir = \"/scratch1/chroma_db\"\n",
    "docsearch_chroma = Chroma(\n",
    "    embedding_function=baai_embedding,\n",
    "    persist_directory=chroma_dir,\n",
    "    collection_name=\"harry-potter\",\n",
    ")\n",
    "docsearch_chroma.reset_collection()\n",
    "docsearch_chroma.add_documents(texts)\n",
    "# for t in texts:\n",
    "#     docsearch_chroma.add_documents([t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "51465f59-49ed-45a5-832a-1f03b9560c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions from https://en.wikibooks.org/wiki/Muggles%27_Guide_to_Harry_Potter/Books/Philosopher%27s_Stone/Chapter_1\n",
    "# you can try yourself\n",
    "\n",
    "# query = 'Why would the Dursleys consider being related to the Potters a \"shameful secret\"?'\n",
    "# query = 'Who are the robed people Mr. Dursley sees in the streets?'\n",
    "# query = 'What might a \"Muggle\" be?'\n",
    "query = '''Who might \"You-Know-Who\" be? Why isn't this person referred to by a given name?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "34cf7c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A utiity function ...\n",
    "def print_search_results(docs):\n",
    "    print(f\"search returned %d results. \" % len(docs))\n",
    "    for doc in docs:\n",
    "        print(doc.page_content)\n",
    "        print(\"=============\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c24069d5-19d6-477b-a3ba-c79b6cd39d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search returned 4 results. \n",
      "half-moon glasses. \"It would be enough to turn any boy's head. Famous  \n",
      "before he can walk and talk! Famous for something he won't even  \n",
      "remember! CarA you see how much better off he'll be, growing up away  \n",
      "from all that until he's ready to tak e it?\"\n",
      "=============\n",
      "Owls flying by daylight? Mysterious people in cloaks all over the place?  \n",
      "And a whisper, a whisper about the Potters...  \n",
      " \n",
      "Mrs. Dursley came into the living room carrying two cups of tea. It was  \n",
      "no good. He'd have to say something to her. He cleared his throat  \n",
      "nervously. \"Er -- Petunia, dear -- you haven't heard from your sister  \n",
      "lately, have you?\"\n",
      "=============\n",
      "Professor McGonagall opened her mouth, changed her mind, swallowed, \n",
      "and \n",
      "then said, \"Yes -- yes, you're right, of course. But how is the boy  \n",
      "getting here, Dumbledore?\" She eyed his cloak suddenly as though she  \n",
      "thought he might be hiding Harry u nderneath it. \n",
      " \n",
      "\"Hagrid's bringing him.\" \n",
      " \n",
      "\"You think it -- wise -- to trust Hagrid with something as important as  \n",
      "this?\" \n",
      " \n",
      "I would trust Hagrid with my life,\" said Dumbledore.  \n",
      " \n",
      "\"I'm not saying his heart isn't in the right place,\" said Professor  \n",
      "McGonagall grudgingly, \"but you can't pretend he's not careless. He does  \n",
      "tend to -- what was that?\" \n",
      " \n",
      "A low rumbling sound had broken the silence around them. It grew  \n",
      "steadily louder as they looked up and down the street for some sign of a\n",
      "=============\n",
      "Dumbledore's eyes seemed to have gone out.  \n",
      " \n",
      "\"Well,\" said Dumbledore finally, \"that's that. We've no business staying  \n",
      "here. We may as well go and join the celebrations.\"  \n",
      " \n",
      "\"Yeah,\" said Hagrid in a very muffled voice, \"I'll be takin' Sirius his  \n",
      "bike back. G'night, Professor McGonagall -- Professor Dumbledore, sir.\" \n",
      " \n",
      "Wiping his streaming eyes on his jacket sleeve, Hagrid swung himself  \n",
      "onto the motorcycle and kicked the engine into life; with a roar it rose  \n",
      "into the air and off into the night. \n",
      " \n",
      "\"I shall see you soon, I expect, Professor McGonagall,\" said Dumbledore,  \n",
      "nodding to her. Professor McGonagall blew her nose in reply.  \n",
      " \n",
      "Dumbledore turned and walked back down the street. On the corner he  \n",
      "stopped and took out the silver Put -Outer. He clicked it once, and\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "# semantic similarity search\n",
    "\n",
    "docs = docsearch_chroma.similarity_search(query)\n",
    "print_search_results(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a21737",
   "metadata": {},
   "source": [
    "#### Saving and Loading your ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fd053d53-d5a0-4e1f-8d56-69acb51d6a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload from disk\n",
    "docsearch_chroma_reloaded = Chroma(persist_directory = chroma_dir,\n",
    "                                   collection_name = 'harry-potter', \n",
    "                                   embedding_function = baai_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1ff1f853-d04e-4bae-8bf2-bddec2d4326e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search returned 6 results. \n",
      "sunrise. Experts are unable to explain why the owls have suddenly  \n",
      "changed their sleeping pattern.\" The newscaster allowed himself a grin. \n",
      "\"Most mysterious. And now, over to Jim McGuffin with the weather. \n",
      "Going \n",
      "to be any more showers of owls tonight, Jim?\"  \n",
      " \n",
      "\"Well, Ted,\" said the weatherman, \"I don't know about that, but it's not  \n",
      "only the owls that have been acting oddly today. View ers as far apart as \n",
      "Kent, Yorkshire, and Dundee have been phoning in to tell me that instead  \n",
      "of the rain I promised yesterday, they've had a downpour of shooting  \n",
      "stars! Perhaps people have been celebrating Bonfire Night early -- it's \n",
      "not until next week, folks! But I can promise a wet night tonight.\"  \n",
      " \n",
      "Mr. Dursley sat frozen in his armchair. Shooting stars all over Britain?\n",
      "=============\n",
      "on the wall outside was showing no sign of sleepiness. It was s itting as \n",
      "still as a statue, its eyes fixed unblinkingly on the far corner of  \n",
      "Privet Drive. It didn't so much as quiver when a car door slammed on the  \n",
      "next street, nor when two owls swooped overhead. In fact, it was nearly  \n",
      "midnight before the cat moved at all. \n",
      " \n",
      "A man appeared on the corner the cat had been watching, appeared so  \n",
      "suddenly and silently you'd have thought he'd just popped out of the  \n",
      "ground. The cat's tail twitched and its eyes narrowed.  \n",
      " \n",
      "Nothing like this man had ever been seen on Pri vet Drive. He was tall, \n",
      "thin, and very old, judging by the silver of his hair and beard, which  \n",
      "were both long enough to tuck into his belt. He was wearing long robes,\n",
      "=============\n",
      "Potters? If it did... if it got out that they were related to a pair of \n",
      "-- well, he didn't think he could bear it.  \n",
      " \n",
      "The Dursleys got into bed. Mrs. Dursley fell asleep quickly but Mr.  \n",
      "Dursley lay awake, turning it all over in his mind. His last, comforting  \n",
      "thought before he fell asleep was that even if the Potters were \n",
      "involved, there was no reason for them to come near him and Mrs.  \n",
      "Dursley. The Potters knew very well what he and Petunia thought about  \n",
      "them and their kind.... He couldn't see how he and Petunia could get  \n",
      "mixed up in anything that might be going on -- he yawned and turned over \n",
      "-- it couldn't affect them.... \n",
      " \n",
      "How very wrong he was. \n",
      " \n",
      "Mr. Dursley might have been drifting into an uneasy sleep, but the cat\n",
      "=============\n",
      "opinion there was no finer boy anywhere.  \n",
      " \n",
      "The Dursleys had everything they wanted, but they also had a secret, and  \n",
      "their greatest fear was that somebody would discover it. They didn't  \n",
      "think they could bear it if anyone found out about the Potters. Mrs.  \n",
      "Potter was Mrs. Dursley's sister, but they hadn't met for several years;  \n",
      "in fact, Mrs. Dursley pretended she didn't have a sister, because her  \n",
      "sister and her good-for-nothing husband were as unDursleyish as it was  \n",
      "possible to be. The Dursleys shuddere d to think what the neighbors would  \n",
      "say if the Potters arrived in the street. The Dursleys knew that the  \n",
      "Potters had a small son, too, but they had never even seen him. This boy  \n",
      "was another good reason for keeping the Potters away; they didn't want\n",
      "=============\n",
      "normal, owl-free morning. He yelled at five different people. He made  \n",
      "several important telephone calls and shouted a bit more. He was in a  \n",
      "very good mood until lunchtime, when he thought he'd stretch his legs  \n",
      "and walk across the road to buy himself a bun from the bakery.  \n",
      " \n",
      "He'd forgotten all about the people in cloaks until he passed a group of  \n",
      "them next to the baker's. He eyed them angrily as he passed. He didn't  \n",
      "know why, but they made him uneasy. This bunch were  whispering \n",
      "excitedly, too, and he couldn't see a single collecting tin. It was on  \n",
      "his way back past them, clutching a large doughnut in a bag, that he  \n",
      "caught a few words of what they were saying.  \n",
      " \n",
      "\"The Potters, that's right, that's what I heard yes, their son, Harry\"\n",
      "=============\n",
      "twelve balls of light sped back to their street lamps so that Privet  \n",
      "Drive glowed suddenly orange and he could make out a tabby cat slinking  \n",
      "around the corner at the other end of the street. He could just see the  \n",
      "bundle of blankets on the step of number four.  \n",
      " \n",
      "\"Good luck, Harry,\" he murmured. He turned on his heel and with a swish  \n",
      "of his cloak, he was gone.\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "# you can test with the previous or another query\n",
    "\n",
    "query = 'Who are the robed people Mr. Dursley sees in the streets?'\n",
    "docs = docsearch_chroma_reloaded.similarity_search(query, k=6)\n",
    "print_search_results(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dd8cdb9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['06450ea4-15da-42a9-802f-7f6a79e7cda4',\n",
       " 'bbfd25b0-5d5f-4eef-94a0-892b5f99e5b7',\n",
       " '2f312bc8-b29a-4899-94aa-7a7e8631cc48',\n",
       " '4713d3bb-1cde-4736-849f-3be942d0705c',\n",
       " '8989b56a-881b-4e0c-a568-c119d39834e0',\n",
       " '3d6a35d6-bf66-4624-a1ad-7ee08e8a4338',\n",
       " '78363d60-2549-4e02-9737-536ecbf79a02',\n",
       " 'a37ccbb8-83dd-4c58-9bb9-4c77c8ad57be',\n",
       " '02692e70-ac02-4fe6-9d01-1f47fdc9e2e1',\n",
       " '4fb67979-9ed1-4f5d-9add-57a54a1ca0c6',\n",
       " '7dbc11d1-72de-4dbb-b1ab-1001391e5272',\n",
       " 'dfff70e5-a3d6-4ec6-a705-cf998cb7663e',\n",
       " '52f8673a-423c-44f0-943c-62134b9a7eb9',\n",
       " 'a5432c56-cb6e-45de-beef-12a6e99f99ea',\n",
       " 'f0a3b9a9-0cc4-492b-9d8a-4bb7b8035354',\n",
       " '9a98b976-ae8b-4fb7-a088-37a87c7c7155',\n",
       " 'e7db6868-4b4d-4b00-b404-a174c3a5ae45',\n",
       " '593302c8-00a0-448f-91cd-15cd877cc5f8',\n",
       " '889a7172-ab43-49db-95e0-28f1d1a4f7f8',\n",
       " 'c852d11b-d4d9-420d-8cae-aabcc633ba8d',\n",
       " '985dbdb9-6a8b-428c-8373-1156cef371dc',\n",
       " 'd59cf1ed-4799-4bc5-9b93-3b8cdcd5906d',\n",
       " '2cf4eac6-13b5-4393-b4dc-2c190a732b04',\n",
       " '5bdd1134-3e7a-49d4-aa49-979df1052386',\n",
       " 'e6a40549-e24c-477e-aeef-7778e6460e9a',\n",
       " '3420a93e-6d10-4ea2-9878-3e2d4be9aad5',\n",
       " '9818ec21-f5f4-4595-be81-5ba33ec6e052',\n",
       " '918dd324-bba9-4913-82ba-70498e1c8894',\n",
       " '6a4fc8c7-9762-473e-88d4-4cd3b03100f1',\n",
       " 'e2bbc01b-e4ae-4359-b55f-9344a886d662',\n",
       " '0585c603-b705-45e6-a29d-8e200459ceef',\n",
       " '7aef5b88-c73c-42ab-876e-05447ca8581a',\n",
       " '8897ad35-e1a5-4a8a-96e4-294d5ced5a87',\n",
       " '3181de8a-08f7-4ede-9960-8661fdbdd660',\n",
       " 'c285aa42-8e02-4506-976a-abd4b7feb9af',\n",
       " '18db4d9a-8ba3-4b24-bc00-a2c3be30e295',\n",
       " '7ba59e46-2291-478f-8fd4-0395a213dd5c',\n",
       " '2bc6cebf-31fc-4452-96aa-1e9c9f0accf0',\n",
       " 'ab959457-09e5-4494-8945-8c9c74b422fb',\n",
       " 'a8d1f67d-a4b3-4d96-9408-3407d0d30fef',\n",
       " '4fb20a6e-41cf-4f31-9b4e-5c200ca892a6',\n",
       " '2e68203f-d3fd-43a0-8d64-86954615d553',\n",
       " '2ad5003e-ade0-4dea-ae03-e7330f2be874',\n",
       " '2faf43c2-7216-44b2-93da-0ff81ee11f6a',\n",
       " 'd8f85c3b-f07f-462d-9d47-9202bcd1c8f0',\n",
       " '26a1c19b-5fae-48f3-905a-f3b42a3e807f',\n",
       " 'f1f256b1-d8c6-4a1a-981a-09527aa2e2fb',\n",
       " '880a3c32-1766-4952-ab19-d38365d25b42',\n",
       " 'f89c724a-397c-487a-b7b5-6cbd1ae6dae4',\n",
       " '529f6ee6-20ba-4189-b35e-b27f2127f591',\n",
       " 'dfe1988a-b23d-4f5b-aae7-a345ce36ea23',\n",
       " 'fe5c1e4a-06aa-494a-a498-fdb998865cd0',\n",
       " '9cf72cd9-6264-46b5-a6fb-4a55039b4bee',\n",
       " '2faeb66f-edda-4f41-8ab7-062a989ef741',\n",
       " '78b36386-cd6b-4950-84db-f69bcd4432f0',\n",
       " '6d310938-0dd6-47a5-abd0-19ed7c1696fd',\n",
       " 'f2f1b0d2-3d6f-4890-88c9-beff6d6adca0',\n",
       " '5acf314c-a5ca-4bbc-bcbd-b445e32e5799',\n",
       " '50a41c06-c6f9-4fd4-8912-0c49db82e74f',\n",
       " 'f480975e-5e3a-4619-8376-7f7e7b2f891a',\n",
       " '41e7e8d3-eb1e-4a1a-9f32-66914f3da0c5',\n",
       " '055be854-ab06-4a92-b9ac-d10a21eb2fc5',\n",
       " '880828e0-d32b-492a-a66a-f60034c51db2',\n",
       " '46ccd625-7dc8-4bb8-8215-10e1dc266571',\n",
       " '00e7d09d-698d-47a0-9189-d1c8b7f2bd85',\n",
       " 'a9860265-9c0f-49da-86e5-8036db543d44',\n",
       " 'b110990b-a9e6-4f3a-a56b-5f5b78f85c4d',\n",
       " '8380594f-60be-4de1-b9e5-7135f16e93e1',\n",
       " 'ea1c5bee-2722-4df4-8086-099a3ffbd711',\n",
       " '5a1c7837-e491-4923-a016-31d69f295937',\n",
       " '9730a18a-6da9-437e-93a1-9f99f8df87eb',\n",
       " '2e3c9e67-513f-4adb-89cb-5c8de1bd07d5',\n",
       " '1bbd984c-f5eb-4d91-90d5-b405b9c97c9c',\n",
       " 'e1e5d51e-84e9-47ac-83e4-dcef7aee6c8d',\n",
       " '598c5ba0-c58f-4b38-b7ca-d95098e6a93b',\n",
       " '63ad778d-d009-4bba-83e7-7317ebdd184b',\n",
       " 'ea115a4b-e4fb-4df2-8843-3b624790127e',\n",
       " '2a122e51-4ea6-486a-8e16-d95d4112570f',\n",
       " '9d9e8000-33c4-4d94-b593-50ebcf771bca',\n",
       " 'bc889aee-412e-42d1-a895-fb6935a1e964',\n",
       " '38c048bd-9a51-46fc-bfbb-a4addfe7cea5',\n",
       " '70f94805-7e2c-406f-8b36-38760cd4473e',\n",
       " '2356b95c-7abc-4403-b78d-8fef00934261',\n",
       " '1d9a960b-c5fa-423a-99a3-aec0fada506d',\n",
       " '582dfeca-25af-40d4-9aa4-ee1d8f2bea86',\n",
       " 'caf249f2-6b20-431d-b3b7-f72912eaf9ee',\n",
       " 'fcae9a49-8fcb-46b4-a2e2-d4fca99d97fe',\n",
       " 'ff7a138e-6f9d-48ee-a3f3-a2821e0c9885',\n",
       " 'e6891031-1602-40ed-8132-d90c1d35aaac',\n",
       " '9c14787e-75ba-4f8c-921f-182f05995c1c',\n",
       " '4c1c2186-a2f0-40cd-ae5d-5ccb3d3da273',\n",
       " 'f936586b-a1d8-47ce-b1bd-a116c67b80a9',\n",
       " 'd8f10ae7-4b58-4805-b81b-b2dc076d4bdf',\n",
       " '8c30efef-7793-4287-aa95-8ec28b2d85ad',\n",
       " 'ccf898cc-d3fb-4771-94db-2e7762cbe4c4',\n",
       " '03ec896f-2bd6-4e5a-ace6-13a87f194a07',\n",
       " '9ed3c690-ffed-4558-8a51-0f71773c4064',\n",
       " '2e0271a7-2399-4dab-874b-b63f40495a28',\n",
       " '089994ad-6506-430d-81c0-4bdb56d99ba2',\n",
       " 'a53f076d-342a-4112-b963-e637b89c7b29',\n",
       " '2fd3719b-9427-4dc5-b1bc-efff4c286969',\n",
       " '0ef7939f-06a2-4107-a3ba-05572d66451a',\n",
       " '38f708a7-f9cd-4422-adec-f80230209d16',\n",
       " '5007442c-7a5f-4416-9c02-b023b5f36101',\n",
       " 'd2ad7b24-10c5-4c85-9a95-4fbb96e19f76',\n",
       " 'e9eb5b32-6089-4b5d-8fd3-c0d622e415c7',\n",
       " 'edd6d129-76f5-4328-8a69-929400837bf9',\n",
       " '0d0c4863-b69e-42fe-baad-025291073ddd',\n",
       " '904f26ab-b9bf-40e1-b314-dfb11fb381ec',\n",
       " 'ac2614cf-ac74-40cb-b0f8-fa242b3134ca',\n",
       " '62f6ec04-d887-4371-8b75-ef3276c42280',\n",
       " '06fc1db1-c5ad-4e8c-a25a-a36a9484f77b',\n",
       " '3e582e52-3bd6-45b6-a2e7-e05c6f8e4690',\n",
       " '93907554-1b5a-4109-af11-bac463dc025e',\n",
       " 'd537b86d-9af2-4476-aee0-906cd82bf8c5',\n",
       " '77504003-28c3-44e3-92cc-c1ecc62b14c3',\n",
       " '45ef6565-4b7d-4dc0-bdc4-300fdf4c2a27',\n",
       " 'fa305053-06c5-4088-8bad-48690575cdc7',\n",
       " '0d6f454e-e9ec-4aa6-a371-5e9930ddc690',\n",
       " '17cf8f8a-f45d-4ff3-bfa2-7db01b8d2906',\n",
       " 'c186b7f7-d5a6-4cda-bb95-6dcca2eba57e',\n",
       " '51f4ee2c-1d3f-4fd3-a44e-85d75c53676d',\n",
       " 'afdf89cb-f846-4619-9bc3-30eb87e2485f',\n",
       " 'f5639713-012a-493b-b3a2-482591d31948',\n",
       " '0fdcece6-b20d-4469-8f65-01a09c56e054',\n",
       " 'e4cd512d-ffe0-4fe8-8919-aaffd3afbbea',\n",
       " 'b5131be5-264b-451d-8d53-ac9ea5c9a9c3',\n",
       " 'c1c29b32-bf37-4490-b39d-2a8f5ef2e0fc',\n",
       " '86c49d17-6aef-47d9-acc8-c10cf84b05b4',\n",
       " '9cf3972d-0eef-4507-a591-845c952c700a',\n",
       " '68649cbd-420b-4f8d-ae45-39021455194d',\n",
       " '3f65c2bf-9c20-47a0-b2f3-908aa659e559',\n",
       " '648b00e7-caa3-4389-8838-2ff48a38fdc0',\n",
       " 'd849bfff-cc07-46ec-a640-25c9584b718d',\n",
       " '4a17ebcb-b84e-4afe-ac9a-5f90098e6041',\n",
       " 'f607418d-d85c-430b-8cfa-95c9cf6ac5e3',\n",
       " '911c4e27-493d-4523-bd7e-0b05475c0416',\n",
       " '973611f9-3c81-42dd-b9dd-76496b35d2b6',\n",
       " '3c2d1d3e-f7d9-43f6-ab63-ea11d71d76b5',\n",
       " '33f51217-a01b-4a4f-9abd-198a80ec4e44',\n",
       " '0d116cc3-f0f8-4557-96c6-70f63ca0d387',\n",
       " 'f4f2053d-4410-452d-866d-453944958cde',\n",
       " 'ad69ad3b-c648-4a62-9595-e8087dd09912',\n",
       " '65f58eb8-fca6-4511-9be1-5ea82c99af67',\n",
       " '442df27b-1475-4f7e-82bf-d422cf37972c',\n",
       " 'bcfa6d81-d75e-4eb2-836c-ccdd9bf353e9',\n",
       " '7ea82933-4e84-4eb6-9189-5c6806c057ae',\n",
       " '6327400c-2ef3-43fb-b21b-2dd55409e4de',\n",
       " '885da6e7-38dd-4d43-b972-9a972a931711',\n",
       " '2a036073-fc12-4e77-8deb-dd65074991b8',\n",
       " '518b0a75-91de-4286-9590-ff84f658b89e',\n",
       " '260b1e62-903a-4be1-be2e-afba619ca19b',\n",
       " 'fec10366-97ce-4bd0-a2e2-e5fcb1213c85',\n",
       " 'c8b8a376-f831-4d5e-b539-1e23e7b66db5',\n",
       " '15430929-6bd1-44b5-bb19-383a3c9b1f85',\n",
       " '45b9fa05-7aab-4b07-a459-16fdd035a148',\n",
       " '9a9abc3b-9a01-4230-81da-bd6d9a44c6bb',\n",
       " 'c90d8eed-0bae-434d-a84f-daa9c92e0bba',\n",
       " '1c603481-1a6e-47e3-bbc4-5ebbdda2ba0a',\n",
       " '64392c62-1098-456c-8769-1c8a9a8854aa',\n",
       " 'a45897c4-c17e-403a-ab00-e4df43607b54',\n",
       " 'de72eabc-fc25-4f71-97ee-7e0b9a208f75',\n",
       " '52a6e931-8cb7-449c-af00-1eb58b47946b',\n",
       " '9174b5ec-4cbc-495d-9017-6ccc5c84c968',\n",
       " '9cc0357c-558c-4967-aef4-f69daed613d8',\n",
       " '940635a4-8123-47a0-9bc8-b58c87c60d46',\n",
       " 'afc0bcdb-2a05-4ee9-83f4-4f511f95c309',\n",
       " 'de568dec-2ef0-4554-b9af-29100a1d8977',\n",
       " '36332f2e-c7f6-4d1b-b7b2-a14cd19d4d74',\n",
       " 'bd15518d-097b-423a-9ad7-405ab27a152c',\n",
       " '234a61b4-199b-4c3f-b2a2-20f61726ffde',\n",
       " '59117800-4496-4e0d-b0d3-805c2c08987f',\n",
       " '45c31511-22ee-4320-91b2-cd77ba59d1dd',\n",
       " 'f4756956-ad4d-49f8-a986-c8575bc85e68',\n",
       " 'dd341aec-4ff2-406f-81d3-292aeb2c1931',\n",
       " '8d34e8b6-f608-4bcb-a35f-c67526671be3',\n",
       " '001d57e0-b99d-4587-85bb-6692947b1ce0',\n",
       " '728a6ce9-c8f4-45b8-87cf-893f5da7f9f8',\n",
       " '333e7673-27ff-4686-b284-5053622a1471',\n",
       " 'd52fb3d2-ba91-47bc-ac1a-2f8027e936b5',\n",
       " '7178b3fe-aee6-4d33-a9c2-ce888664cd56',\n",
       " '02466d71-ef0a-43f3-a6a0-a0e0e08d572b',\n",
       " '10510bb9-914c-4fd9-a5bb-58fd509f9144',\n",
       " 'ca5335bb-798f-4e04-893a-fb46e53c284d',\n",
       " 'c7507a1c-77c7-471a-93d9-858923a8e383',\n",
       " 'c7e9dd34-cada-4e34-a8b0-7d750ba02528',\n",
       " '3f1bdb3d-c57d-4ca6-a6b3-7096c051e502',\n",
       " '2f985a89-e88b-43ed-8077-1649a928ebfb',\n",
       " 'd7c2d127-2c8f-4f6b-9508-bdcc4b5d1ab1',\n",
       " '327be582-f33f-4d05-b630-ab3bf5276b1f',\n",
       " '4d571944-4f2a-4e24-852d-cfe16e71e91c',\n",
       " '10d1b432-ef4e-488c-affd-a1e9592fe0b7',\n",
       " '74b4ce1d-b84d-441d-93c7-cee581e92589',\n",
       " '12862ad0-8ede-4f54-b409-b35482b8a213',\n",
       " '70c42626-304c-409e-839e-baae50eded4d',\n",
       " '423ffb20-2d02-4a0a-add7-82c9694111db',\n",
       " '67c4fa8d-d2e8-4be6-a58c-3d12c05902aa',\n",
       " '0df39756-22ed-4a71-b151-dfa732020556',\n",
       " '060c66f8-0db0-4979-97de-6d3de3662c33',\n",
       " '06ef698b-7c67-487b-aeff-80b4a1721cc0',\n",
       " '6c992aa3-569a-403e-b2d0-4c21f8030966',\n",
       " '09b524bd-e4c2-4f8b-8344-dc7f0781244b',\n",
       " 'd4f68d51-9378-46eb-9ff7-49d4edec8d9c',\n",
       " '6953835f-894c-461a-8703-1b27a054caeb',\n",
       " '2cf4b2b3-845b-4dff-a6dd-0fc8ad6ef105',\n",
       " 'da13c798-9742-4db0-80e8-b0a0404814dc',\n",
       " 'f123f1d9-11cb-4741-8ec5-85a70e541877',\n",
       " 'd1a74fb1-1347-41ce-a180-d884d24bfffd',\n",
       " '482ae5b4-48f9-4be0-b9b8-5da617766b2d',\n",
       " '5437aba9-3b1a-4862-ab88-b30146621fa2',\n",
       " '1d13d431-046b-496f-9027-5802bae22b42',\n",
       " '78398385-fd81-4019-a854-f198fcc2c3d5',\n",
       " '76124756-b15f-4e1e-b055-f8c92dd7f389',\n",
       " 'df234556-139f-4363-a3f6-a571751992f8',\n",
       " '3d395156-905a-4edf-a376-f2d6606474af',\n",
       " '542f6543-f0b5-4791-ba3c-ec0fdf8daa07',\n",
       " 'd1b82550-80d4-4bc2-b560-a69e9cc793f9',\n",
       " '82cc9939-0431-4fed-8b88-2a0c5ccd15d0',\n",
       " '59bb6ad3-b090-4aaa-944e-a6ff2c95b156',\n",
       " 'd14b2cef-689b-49e1-9b13-a4f7119b7841',\n",
       " '0e4dbf7d-abaf-4e0b-8696-515bb0942cb0',\n",
       " '0751dd7a-f302-4ec4-9e7d-2595c000b5ae',\n",
       " 'fa244213-3f44-400b-a258-50efa052cabe',\n",
       " 'cf128a2e-b6e3-4334-8d94-a927f5818210',\n",
       " '076aa26e-abff-4bb9-bf6e-10b66896e6ef',\n",
       " '1777da96-1dde-41cd-93d8-654c2189847e',\n",
       " '3e8caed6-0e0b-451a-bd9b-a4e29054076b',\n",
       " 'aea2f366-f290-4c9a-84cd-ebb6cd6d642c',\n",
       " '77ac829d-8b42-4a1a-a89e-6406387af256',\n",
       " 'd72e743f-3c0a-48be-8af0-e627386d4f90',\n",
       " 'bc228769-cae4-4980-bb7e-0c30f8c71813',\n",
       " 'ada02b72-6057-4740-9072-74a80d8e74d8',\n",
       " '1e809bfe-cfe2-495b-9222-5d8b548152f4',\n",
       " 'b7d7c74d-2dba-4153-aaf0-bbc67bfb386f',\n",
       " '9e57d85c-e355-4a23-a7b2-7a68f2e753ac',\n",
       " 'd82d8c68-9c3c-43f4-b9af-a88266313d30',\n",
       " '563f1722-4c02-43d7-b134-9c5e8462afa6',\n",
       " '4ecbb52c-0d75-485e-b41c-13aed9ce4756',\n",
       " 'f492d4f5-bf50-4f80-b12b-15562618353f',\n",
       " '7907515b-32dd-422a-ae3e-812c66fadf79',\n",
       " '93226672-a3cb-4d62-8f3f-5da497673b7e',\n",
       " '9aa636d7-e3ec-4e52-a9c8-146ee917e539',\n",
       " 'f6b33668-45e5-4f66-a35b-1081d4674846',\n",
       " 'c741c8a3-577d-4fcc-a041-6a2a281fbe4f',\n",
       " '0a701e3a-f7ad-471f-a3b5-ccefe4295e4b',\n",
       " '76f39900-beef-4410-91c4-5427b6df5f04',\n",
       " '5592f627-de60-4b3e-8f7e-cb7db8c76d57',\n",
       " 'ff2ac531-eae5-454e-9635-1f4880554cef',\n",
       " '7d71d413-712e-47a3-8ae0-5730f55b2700',\n",
       " '327171df-d8e8-4647-b142-2f21b5f445da',\n",
       " '9acb5c12-03dc-44af-bcbf-0ba9cf70df59',\n",
       " '024be8b0-d66c-4b8d-bf19-da7237ec2c64',\n",
       " '3c008b29-0db0-4b6a-a451-28b730b8bb99',\n",
       " '7b13cdad-3f7e-49dd-9232-5d24e7c38f6b',\n",
       " 'fa23f688-c1e8-4da0-86d2-15c001ef8f87',\n",
       " 'b44b0390-9155-47f8-9790-2a7d5dd22f8a',\n",
       " 'f8a03435-04b0-4c02-b218-14abafb38987',\n",
       " '3fbed26e-e07f-4894-93c6-980086e611ad',\n",
       " '9e5a8f96-a382-464e-aa77-02641993ff90',\n",
       " '1fc0e019-ad66-40ac-abed-cbb25628c1dc',\n",
       " '350b3d2f-725c-46c1-ad66-2cea2e4759c9',\n",
       " '07afe1d7-5391-49d4-ab49-9a3414ab1953',\n",
       " 'fd432705-432e-439f-86ef-71dcb7df0938',\n",
       " 'c0fe4d45-866c-45d7-9b31-f7b5bea62768',\n",
       " 'e0abefcc-bb2a-4f38-85e4-e2f91f92feda',\n",
       " 'bf7aad79-bd34-4e2b-a8ea-1a3c4e3709d9',\n",
       " '65ec727b-daee-438e-a713-0e315866b7df',\n",
       " 'ab8eae5e-4178-4ea6-8b56-b89037d98135',\n",
       " '8ced3ddd-8049-464e-8060-07526c110aeb',\n",
       " 'bbba4a31-52de-46b1-a00a-c6315274f73b',\n",
       " 'bcc69791-fe4c-4288-8a78-bf3afe6aa735',\n",
       " 'bd490fa7-564b-4abc-9c8f-3417ba39a124',\n",
       " '8a891949-d05f-4004-8218-a4c151fc6991',\n",
       " 'd5321b45-0ddb-42e2-8890-7c68dece37da',\n",
       " 'c3f595ad-5295-47cf-b527-7d7756b736c5',\n",
       " 'dbc6c97a-6766-4ad0-9e77-203baa699a6b',\n",
       " '95f5cf7c-bb77-4ff2-b3af-93919bd371a1',\n",
       " '0716c19b-d1c1-4fa2-b52e-727164f8e6d2',\n",
       " '8221762a-8e97-4c99-bcea-45f114b94047',\n",
       " 'b60267fa-feee-466c-9cdd-1e2e306ee72d',\n",
       " 'ec430abf-843d-4aec-b8e2-ef26ec0c6d8e',\n",
       " '6d363941-df60-4c2a-ab0e-bc61e76f3a12',\n",
       " '24356dff-d9d3-446e-a4e7-7758f59c5c5a',\n",
       " 'd00437ca-5171-4e4b-8eee-b72deb1df19d',\n",
       " '8a3e51f0-3024-4693-aef1-76386c24dd9c',\n",
       " '3c88a5ad-be42-4af9-a529-b634cde6ce73',\n",
       " '7d48671e-6aed-4b6b-b367-a74ae77060b6',\n",
       " '9add951e-a1b3-47db-9e17-13716cef1cb1',\n",
       " '16a24ba3-b384-4c47-a5a4-d72c919beab7',\n",
       " '47ab1c5b-0700-4ced-8aff-5f6d1cc5b31a',\n",
       " '438c7342-5dc3-4f26-8376-da72ca0ebf8f',\n",
       " '3dbf977f-9690-43a5-b3df-69afae0ebe5f',\n",
       " '8cc8f4cb-394b-4229-b94e-2be996177d41',\n",
       " 'b2bff7da-e602-4457-af5d-f29e99e54595',\n",
       " 'a47e0b0f-db92-473a-b0ff-e83d0b033b8b',\n",
       " '6e597df5-23fe-4615-a042-52b64019d214',\n",
       " 'b80f1ba2-508f-43dc-9bf1-d05dddca3d8f',\n",
       " 'b6b99789-2e43-47a6-9180-fa3c5c381f0d',\n",
       " '97af4fa1-ba11-4ca0-ade3-530f2476627d',\n",
       " '123354f9-459b-4798-9c36-a1f74be53e4e',\n",
       " '6ec71fcb-9a5d-4d38-89a7-cd80b528acbe',\n",
       " '5f7ae138-544a-48fe-8d39-6fc8b672fc64',\n",
       " '13a4464f-f9b4-4893-919f-81f50aee272a',\n",
       " '75573ca4-05da-4b60-a6f5-95d14e02fc94',\n",
       " 'b7cab8dd-f13a-48c0-a2d1-507b7c59335d',\n",
       " '2a8039b1-a4c9-498a-9369-8290f9b99727',\n",
       " 'f4e64769-77fe-4a41-91de-e27e436fcaab',\n",
       " '54814f49-a3ec-4bd2-9caa-90f4528289c1',\n",
       " '5909a47a-f6a2-4b78-9bee-ab95b097d94b',\n",
       " '49a7875d-75dc-45eb-9ac6-6335a52447d5',\n",
       " 'c5135112-d281-4fb0-9a89-e743a4861e19',\n",
       " '4f4a7c5a-77ea-4747-9812-007e3a9cec58',\n",
       " 'e988398a-d9d1-4d9b-8be3-b291a91cf0c8',\n",
       " '4f116b57-d0f3-418a-b6eb-c2f44e733300',\n",
       " '35de33a8-4bdd-435f-897d-1f168a502c21',\n",
       " '1d9ec9e0-2f69-4ab0-850f-ab0d3dea98aa',\n",
       " '303fa92d-0552-4cd5-b68b-85e6989bf92d',\n",
       " '1b963122-16bf-4167-aa5a-681926edea66',\n",
       " '4e5b7dc5-df8c-4887-af86-1cdcbf350877',\n",
       " '0d612df1-bcc7-4a42-94b1-3a82fc829ff3',\n",
       " '79d5933b-9386-4ee2-a531-cda617558282',\n",
       " 'd1cedff4-c9f6-46a9-a4d4-274dc113bce3',\n",
       " '48893c90-5aa7-47d6-ac89-0166b1cd2235',\n",
       " 'eb7fd1c5-65c9-40c3-8154-f9097fed1318',\n",
       " '338502ff-1e6d-44e8-b0dd-0f3fae4c7cd9',\n",
       " 'ac80a061-53e7-4af0-9e90-faa0129f92f6',\n",
       " 'ac1e22e2-94ec-4ddd-964d-5cf958c115af',\n",
       " '50a43f58-2238-4670-97cb-34aa0467fb0f',\n",
       " '5d46f9bf-c859-4486-a99e-ddc66b5fa1df',\n",
       " 'b3d0debe-50f1-4140-b960-109fb2027f11',\n",
       " '7dfb79a7-8b73-43e9-a874-38339ca61b3a',\n",
       " 'fc1777ee-c8a1-4eda-b8a6-c8237e169276',\n",
       " '1b13a032-f438-493c-a71d-cdf51d7206ca',\n",
       " '322ebb8f-ec64-40ec-9c50-84b51db2500b',\n",
       " '1726604b-0874-44d5-b4bc-272682a4241f',\n",
       " '82860873-b631-4280-a7c5-ee7e7b460e58',\n",
       " 'd6a20893-f311-4226-9bd3-c373dcad2f4a',\n",
       " '8930237c-6b1c-49a7-ae2f-a3977964e61c',\n",
       " 'd54de371-855d-4d3d-b246-f898154684d5',\n",
       " 'db932c32-9bb5-4fa5-8255-9e1f3ba1944e',\n",
       " '05738e37-58fe-4404-bb4d-ea40b7a22a10',\n",
       " 'b43eebf2-0eac-4f99-97cc-9c5cd65a364a',\n",
       " '4f0540ae-c30b-4401-a86f-18df8180e460',\n",
       " 'e9a29bab-5a03-4552-9f23-c7d0afbd6818',\n",
       " '8e8392c1-5a07-4ca9-949a-e17e5c0f09ae',\n",
       " '1a690626-67ec-471f-bd72-646078edc1bc',\n",
       " '26d928a0-e948-44c2-911e-d367b99cfe54',\n",
       " '725e467e-3872-4813-9354-b2454e4dc965',\n",
       " '33bd67d9-20e5-4b6d-a1cb-df8523d0090b',\n",
       " 'd27859f5-b26a-41d9-919a-9f428ca397cd',\n",
       " '99ba17b8-96c2-4276-91f4-88e87388354c',\n",
       " 'fa5532e8-5b4e-432b-a21d-68f2ddc07a65',\n",
       " '1a0c6273-173a-4d8e-87e4-f72d0a712ac6',\n",
       " 'a1b0466b-9ae5-4ca9-8bba-9b5343add7d7',\n",
       " '0894a28b-66ae-4784-8120-7384291d24fc',\n",
       " 'b9767547-c9ad-4beb-bf81-0355340038c5',\n",
       " '1586fc17-59e1-4b0e-a134-9f7150dded22',\n",
       " 'a79d5fc2-bd06-44b8-b062-810ef7d7eb47',\n",
       " '9b05d465-6d19-4164-8843-b0d1f88541ad',\n",
       " '59b1b05e-4fb5-429d-afbd-8dee1a12e8a0',\n",
       " '2d5174f0-6865-4dfb-992e-e0b5ec65d6b3',\n",
       " '348c227f-f875-495a-b76a-ebfd0d2ab5a8',\n",
       " 'da0807d5-57fc-446a-a3e9-ca891daffdeb',\n",
       " '5db20f67-b27a-4838-bb99-3684f7b80c8d',\n",
       " '174372a4-0041-4284-b33d-6b629bb2a3ce',\n",
       " 'cb89ddf8-1522-4b60-83e5-ed6a6824c67a',\n",
       " '29362893-7052-4a28-a145-50d291db07f5',\n",
       " '8306fa56-2c58-49d1-9b90-fb3013bb4dc1',\n",
       " '1dce1055-87d4-4d68-8e19-f037e2f34584',\n",
       " '0db2ea13-5d6f-4c92-8f10-22a2a79875b2',\n",
       " '88e33693-c959-4217-9e35-4b0d5f97a657',\n",
       " 'e5b24b1a-fb72-4121-853a-7a6540ffc9c6',\n",
       " 'bb9d2e49-2572-4c56-9592-b4fdbd253c3c',\n",
       " 'af559c79-94e7-40c4-b4bf-05a3d3493a62',\n",
       " 'b9331f1f-bb62-49ea-ab20-0123084c76fa',\n",
       " 'b2bd47f0-23d0-4760-a82e-c5ac7e75e786',\n",
       " '04ba39f1-1f56-436d-be06-db2713622bf5',\n",
       " '06dc37a7-38c4-4d73-a6d6-e86d25413e56',\n",
       " '401cf2f5-ec25-4b57-93d9-ade52b6372c4',\n",
       " '1857c595-f0d0-4885-8701-c799438feede',\n",
       " 'e5bb75d9-c2f8-44cb-81a5-23f262018a81',\n",
       " 'f1401137-b3c8-498d-8e1e-c3891e6026b6',\n",
       " 'd175f502-c7e1-427f-97d5-6894724e3aa7',\n",
       " 'dd7a8dcf-e4cc-4cb8-9dc7-69d4eef7378d',\n",
       " 'ff4bce45-673a-4bb3-beb0-10dfd455f9c6',\n",
       " 'dede18ec-c8c9-4436-9c10-a80adb52e07c',\n",
       " 'de001f83-bdce-4ae9-a861-277c51d92e17',\n",
       " 'c8101a28-e425-4ebc-8ec9-4b53c687b2c0',\n",
       " 'f15b416e-5506-4abe-a2c8-5626125b2131',\n",
       " 'ab7caf2a-952c-498c-b188-1210a207efc5',\n",
       " '4a340d1f-842a-4578-83fe-391cafed1074',\n",
       " '3d8a59d2-ac80-4dcd-8895-6fbb43c7ba6a',\n",
       " '6dc93e5a-55dd-4782-b747-b169d222fec4',\n",
       " '98f9c1b9-48b9-4273-9318-99e71ad397f8',\n",
       " 'af91ff33-c6a9-4002-a251-bc147adc8df1',\n",
       " 'e359c83b-19b4-4a5c-97e4-362e3bbd5f18',\n",
       " 'd7d6d7d7-4e9d-4cd8-a10b-4e76d965a8ca',\n",
       " '2e78e092-ddcc-49e9-85f8-721b6a29a510',\n",
       " '0638862f-a5cc-473e-b9a0-ac1138f3436b',\n",
       " '6b654331-7a84-469f-8e72-9e626ff46269',\n",
       " '23bc57d8-41dc-4122-80c6-9b59ea9926d9',\n",
       " '31d21413-efa0-44ff-b77a-9f42ebc19603',\n",
       " '91c744e5-d165-493b-a22a-a0ad0df30ccc',\n",
       " '0680a5ca-e1f8-49ab-8a5d-2db378f57334',\n",
       " '7bce8830-6d7e-46af-a68d-970e4dc2ca35',\n",
       " 'aeead295-599d-45bd-9fea-05526ee35a42',\n",
       " 'aa375474-791b-4c94-9767-549a9535c0dc',\n",
       " 'c6bc3ef1-4086-4a28-a354-c53ded540239',\n",
       " '47490095-de48-42d3-8585-3018899e7302',\n",
       " '0b436ff4-1688-4611-aab2-45bd3f6e69f5',\n",
       " 'c55cbbc6-e0e0-4214-b3be-84731135a7ba',\n",
       " 'a6d902c1-2a44-4876-9ba1-58a1e1485e50',\n",
       " '89909c60-ec2b-41f2-98a8-9fdc156a040b',\n",
       " '2962c2ef-6915-4634-a9fa-8d94be29e405',\n",
       " '5fdecd08-27ad-4f8e-ac9e-f168a53f6f1c',\n",
       " '18d88da8-8ef6-4c3e-89ef-16698681a4ab',\n",
       " 'ecbae008-458d-40eb-9fc5-68e4a6cafe69',\n",
       " 'a12bec31-a15a-4421-bf04-2de1e6774f64',\n",
       " '6a2a9788-c465-4e04-a37d-57152c9bd357',\n",
       " '98e8b202-ad6a-432a-8a6b-52f0825f358a',\n",
       " 'ff04a356-42c8-4b64-aab3-74a7fe748667',\n",
       " 'f4b7d7b0-11dd-4aeb-a26c-a1f8a12526ac',\n",
       " '4beb9dbf-84d0-448c-898a-441f42492e8f',\n",
       " '0e1f45da-54b9-466d-be53-4630d850d7da',\n",
       " '34dab003-289e-4400-9a57-a25730bc4542',\n",
       " 'a7fdc681-e6e1-4b1c-8714-2ab6524da64e',\n",
       " '624caba2-d844-43dd-ade1-236f3438bdd1',\n",
       " 'db463461-94fc-4a9d-867d-4d3d02849087',\n",
       " '078d04d4-e8a3-4fc2-afd6-3241c598b762',\n",
       " '6dda6386-ed1c-4e05-82a6-8055469e8342',\n",
       " 'f78b346f-7888-455c-8308-47c92e86dd0b',\n",
       " '7ca94384-924b-4533-a219-f42506bce896',\n",
       " '6c9da32a-1781-4177-90d8-c130a23fadfc',\n",
       " 'f1d647bd-c2b7-4557-b231-55147c7ad6ea',\n",
       " '103a0ae5-b3b7-40b5-8ac8-86e53d4cf6cc',\n",
       " 'a23add6d-a67f-430c-bd2b-c91a4c8ecdb6',\n",
       " '7b25a0dc-501b-4de4-bf7e-304c06ed5783',\n",
       " '13666b32-6ab7-465f-a3e3-a10f3f0f022e',\n",
       " '59acf088-2be0-4846-9c16-bd392c1a4abc',\n",
       " '1764d4ef-2269-4b7b-8d5c-257a8ca79ac1',\n",
       " 'eee2e9e2-ae4a-4977-8355-3b9eeb9c95d9',\n",
       " '0cbdf929-799c-47b4-83c4-600dd20003d5',\n",
       " '271f05c3-ec69-4eb6-b764-314e38697364',\n",
       " 'efab2346-f4bb-41f1-87ec-70197d029ab9',\n",
       " 'f02c9029-268d-43a7-b345-96bc40637ea5',\n",
       " '9b7aed93-d5d7-4eac-902d-339362681aa9',\n",
       " 'd94e8611-4611-4a10-82d1-47457e7e3202',\n",
       " 'd38233da-32f2-4ee0-ab6f-84809dc76e72',\n",
       " 'f1017205-9184-4782-887d-8ce6a7187f3b',\n",
       " 'a953b3ff-1957-4397-a7a2-4d2765e03240',\n",
       " 'bb31dfe9-88f7-467d-9b34-351a8e395345',\n",
       " '9aa77bb6-033a-45c9-a6d2-675e35b1f2e2',\n",
       " '9e9936aa-d9d1-4552-b237-a7e61657e46d',\n",
       " '36d298bc-4676-4bac-8c07-85dc423ecb1a',\n",
       " '83ebee97-c08c-404a-aa40-c95764c07b08',\n",
       " 'f3bcab4b-332e-4744-92c2-5edadd1d85bc',\n",
       " 'e6917a57-7bf4-4fbd-9f64-87f36a5e9655',\n",
       " 'ffd027b4-7130-456a-8ac9-8611a7bf8e6e',\n",
       " 'fdfb1a9e-98e4-4946-ad74-24121eeeb322',\n",
       " '3c23a6f0-1e37-4b13-a5cb-24f04dfe5895',\n",
       " 'a96e1e61-9f2b-478c-a978-d3037d160d01',\n",
       " '2e678878-aab1-4fcb-8861-d3eb29982ef2',\n",
       " '51b541d4-12ab-4888-ad8b-391932732b80',\n",
       " '0e3d035e-04ff-446b-b4c9-3450d1515ea9',\n",
       " '2c074807-cce5-4969-a5ab-9c42c491f367',\n",
       " '4d0bd7da-b535-4400-bfa1-7ccc879198c6',\n",
       " 'bd8e2581-4474-4058-a54d-c6149d8948e8',\n",
       " '6dbed9db-b27f-4f57-839b-86b3e70f8606',\n",
       " '75c55449-deda-486c-9897-8cdb646f9337',\n",
       " 'd48d8dd7-e784-4b5f-b491-bc2e3df569d1',\n",
       " '422188c9-4f29-4a1d-8c80-5c44814bc2f2',\n",
       " '28023e2e-2657-45d1-b73d-35aa9d2a38ed',\n",
       " 'f17f8afc-c21f-4a87-be48-4674aac62897',\n",
       " '006a49b9-5a34-4fa8-9049-6aa776722701',\n",
       " '932d5d0d-bc29-47c8-a9c0-3cfa1df4574d',\n",
       " 'a4739f2e-b32f-4d52-8cf1-373d2ed07df6',\n",
       " 'b5db9652-00be-443d-8046-71bf7bb72fb9',\n",
       " '61112da7-ec65-4c95-9073-9cae7da8e3ad',\n",
       " '47e4fe78-9f63-41cc-b804-4a5539657536',\n",
       " '1fb99a9a-9731-44d3-9f88-64319be2e92a',\n",
       " '1dfd7040-5354-44c1-8c17-40456c2215fa',\n",
       " 'a99bf75a-66e8-430d-a648-400ecdd439b4',\n",
       " 'd775396f-9fbd-4081-845b-43b1e81dc3ac',\n",
       " 'f1a1e381-de73-45a4-ab24-ce3fee549b54',\n",
       " '81cd34f4-55eb-429f-8327-c5bbaa509713',\n",
       " 'b3d8927a-249d-4b3f-ae67-ae5ec144a90e',\n",
       " '33c67f08-1822-434f-ad07-6f85a86de983',\n",
       " 'a2f78a56-0836-4b8f-989e-656aab82fc84',\n",
       " '3a93426a-4ca0-4694-b7cd-dbb0e6ebeb2b',\n",
       " '1bda42c9-3052-4d32-9ce2-e37e7c976c0b',\n",
       " '1ac2f5c0-e782-493d-9439-79b92ab413a7',\n",
       " '7e2a1582-8592-4813-ae0a-b1dd541bbb9e',\n",
       " 'a2cae78f-2809-4e20-926d-744812a4985d',\n",
       " '05d8371c-3b43-448c-b977-e093da1127eb',\n",
       " '95a19396-32a9-4813-bc57-99a9c05b03b6',\n",
       " '8c55d528-b928-4d40-8ed8-08e8d0b23ed8',\n",
       " 'd94e7093-1b57-4ff5-9348-601e2adcf4b5',\n",
       " '81316411-36f4-4357-819b-13ac255f1ffb',\n",
       " '42317b56-13b9-46b2-86a3-2614e94c8872',\n",
       " 'f848a56a-4801-46eb-8d96-6c11ff7a03bc',\n",
       " 'c4417bf9-f398-45da-bac6-f8e51d17dd4c',\n",
       " '6b1c5940-b04f-4770-a857-a2b70441fcdb',\n",
       " '60374879-4c55-4a3e-9a5b-7d190c69f362',\n",
       " '0f016941-0e45-4c0e-a4dd-07a4242c797b',\n",
       " '36fc6aec-3e53-46ae-9f0f-2bbffc3f62e9',\n",
       " 'def1a662-5911-4a7c-9884-e2015b2d132b',\n",
       " 'cd770be8-6c00-43ed-aa1f-838725538df4',\n",
       " 'eff716da-6211-4d4b-92e1-3d84c991c955',\n",
       " 'ba3e059b-1181-436e-be09-a575a027c764',\n",
       " '4ac43f18-220f-49ca-b10b-f702d3eefd1c',\n",
       " '459969a7-2e66-4704-979f-b2763f577f0b',\n",
       " '6e177caa-34e5-41d2-bd6e-a8f13d2bd803',\n",
       " '664ed657-6bcf-40fc-9d53-898dd5edc932',\n",
       " '9d3b6b86-7551-4f51-8289-d10104b7653b',\n",
       " 'e31ff367-3290-45e0-9035-f3548c32308b',\n",
       " '1bee9127-daf3-4d92-b58b-baafb6b46a83',\n",
       " '2e28725f-8955-4163-9c22-75e196163966',\n",
       " '5ba5c27e-2e16-4e69-9329-aa065fcb8006',\n",
       " 'ea54c868-8d11-495e-9079-9a3eda00c78b',\n",
       " '22b3a3a5-16d0-44fc-92c5-43cbb4789e13',\n",
       " '369931e5-5696-4b06-961f-243d4a3f4590',\n",
       " 'a4606fdf-d3e3-4c43-8f15-8a6f89cc157b',\n",
       " '68ae3b0c-56c2-44df-a879-0114a73088ff',\n",
       " 'a6ba2e37-ec5f-4f15-90ab-3a2f23b48462',\n",
       " 'dc459fa2-a61c-40bb-be27-614fccf1a77f',\n",
       " '2f442cf6-6af5-4910-8b5d-3fff3ca2bb9a',\n",
       " '88bb09cd-a834-4c54-81a7-c34a6600f094',\n",
       " '8e586000-cb35-4479-9bc9-dd70f661a509',\n",
       " 'e4d902eb-a6d3-41be-94a6-8aaf4aa7b8c5',\n",
       " '37faeb7b-e229-4529-8ed7-414f6b70372f',\n",
       " '3faf8b18-187b-4a71-a034-963a9a6f3041',\n",
       " '498f7a88-6f22-4154-947e-4f34e9417292',\n",
       " '62dcee3c-9997-41d1-9cd9-b85899872e08',\n",
       " '1122c1e5-b622-47c9-a5d2-b3a1bbca9fc1',\n",
       " 'f5a030df-ac48-4527-8d85-08c522394460',\n",
       " '1cce13f5-9c12-4040-a20a-5cce48eb8ba6',\n",
       " '3c21297d-e102-4d38-9308-f12058519ccd',\n",
       " '21d73e7f-253d-4846-b46d-1c347715a210',\n",
       " '3beb4c06-5f2b-4683-b63f-96ad5c6deedd',\n",
       " '1eaf2cd8-248f-4c13-ab97-d5d21c79596b',\n",
       " '0ebf9bc2-3cf6-4fd0-b347-21ceda5cd5a6',\n",
       " 'fba8e238-4cae-4758-88b5-79a6b946b0a6',\n",
       " '9000fd34-ff7c-4961-a1f6-99ab773e811b',\n",
       " '41ff3b49-7a5f-4435-930f-26bcff082ea6',\n",
       " 'efc80231-fa33-4581-9699-f0eb94bafd62',\n",
       " 'dd37eed6-d497-4a71-a965-92d7c2f43bf5',\n",
       " '64b1cdfa-e2f2-4c20-988a-4d39f84b0313',\n",
       " '4f04b48b-9c2b-4c0a-9a5e-99ee8aee56a1',\n",
       " '7d472dd2-f850-44c0-9a4d-2f9f0b9c557e',\n",
       " '85939d5d-c075-4a88-923c-a5321663cd03',\n",
       " '4dd0c44a-7cec-434b-97c9-ee53f18f65ff',\n",
       " 'd4ee1402-4165-4056-a6ac-165b6a1712f0',\n",
       " 'd68d4cca-611b-4db4-983a-65808410c5b2',\n",
       " 'ead47851-c146-4cf5-8815-dfc41ce3df90',\n",
       " 'a6b0e0c2-bafa-4fdd-b1ce-1d6d9dd91761',\n",
       " '04708710-1fd9-4ad8-af7e-640c43c4176a',\n",
       " 'b51e9708-79cc-4c70-8aed-eee6e5a72c3c',\n",
       " '5760967c-807f-40d6-a2d7-73882f27fd48',\n",
       " '8806564c-1309-4049-bde2-ae69a2394b21',\n",
       " 'd68d0e8e-0004-4eef-bcef-09dac7a868a4',\n",
       " '5d759ced-eb73-4ec7-b8fe-6e9589ac5513',\n",
       " 'b49d4d3f-8664-4920-b050-decab8c97bf3',\n",
       " '3ce799b6-0428-4890-b87d-3e266911addd',\n",
       " 'd1561755-037d-4b31-b0e1-b9d765eda917',\n",
       " 'b6ba1cdc-473c-4f89-b884-8f0ba36cc912',\n",
       " '808359f4-db05-4516-be16-8d5a6cc690e4',\n",
       " 'b6a69da8-495a-498c-9c45-7a6d4704551a',\n",
       " '13f36876-1544-4707-96d5-6a02329aabce',\n",
       " '75a14d1f-a58c-41f3-86a5-bf5e05b72f0d',\n",
       " 'c0e6b1f5-ac4d-4c64-b1f1-7b7bcc3a8658',\n",
       " '73796f93-0e59-45ec-a0c9-42f71e36c34d',\n",
       " '475dae8f-1535-46b2-b6df-e8d309c4a82c',\n",
       " '71184b2f-f132-4de1-bf46-43f73919d565',\n",
       " '67b9a626-840c-43d8-a7b9-c8218e8d890f',\n",
       " '97cc5cfb-61b4-4a54-bcc6-9bb0a7651c28',\n",
       " '7cceb446-bcc4-47a0-bd25-99a67ba21aca',\n",
       " '4a73a001-cc22-48e2-a4cc-6fdb096f6e1f',\n",
       " 'a4475df1-121e-429a-81c8-8c223fff663b',\n",
       " '7e58ab84-f08a-449b-b920-32a71aadf193',\n",
       " 'cec46f0a-5352-4877-92c5-c21690e809ef',\n",
       " 'd5c22821-8bb7-4c2e-9f62-2b9201ca49dc',\n",
       " '3c8ae552-244e-4fe5-b4be-922faa138f10',\n",
       " '513470b5-b5cd-45a9-83eb-bce73e19cd4b',\n",
       " 'aed93e3e-8aaf-4b8a-9fff-8271f6cf44ac',\n",
       " '720db176-fa86-42d0-8ee4-1fe8fa7078a9',\n",
       " 'a73cd87b-30c4-4b26-b30d-0d0f6c856ff5',\n",
       " 'f0588f6b-4f02-483d-b82d-d14a972a67d3',\n",
       " '9ecc5fac-4ebe-4501-addf-a4b79df6f2bf',\n",
       " '98ef493f-9431-40cc-b259-12f03a0cd2f9',\n",
       " 'e1daaad8-cda5-448d-8fd4-f5a55833fbae',\n",
       " '3ddec767-0664-4ff4-a90f-3cf2f87acc6b',\n",
       " '34fce14e-62ae-4353-9d68-f16441924a0b',\n",
       " '626ede4e-5021-4e62-a96b-b05a466e12a0',\n",
       " '2eb1be85-f189-4051-be48-c973ccf4aae4',\n",
       " '328085f9-6893-4afb-883f-7e945f5dbb4d',\n",
       " '16f96e8c-b06d-4d53-9e6f-1403d251eeac',\n",
       " '9ebd1b08-8ff5-49c2-9c8a-fdd290e2d525',\n",
       " '84e81692-26a7-48af-b85c-ca60c0daf472',\n",
       " 'cad1c145-33eb-4aca-ae1b-e24c719ec885',\n",
       " 'e5447955-37e5-4349-bdaa-ab019b079184',\n",
       " '961e3e64-6772-444b-8863-a9d408c6d0a6',\n",
       " 'ab03713f-46ce-4e3f-97e0-03e936d3a58d',\n",
       " '76f0647a-5ce2-4dd9-88c3-b67bd69ec14f',\n",
       " '38c0ac31-c331-404a-b1a1-d00ab44d2c0c',\n",
       " '6f4ee013-e845-4f26-8311-d152e0043185',\n",
       " 'bcecf19f-b030-4c1c-b4cd-32e17482ca62',\n",
       " 'c6c68329-49c3-48ab-b510-330d71c501e2',\n",
       " 'cf9c2a24-b273-40bc-afb5-73d41361fb2e',\n",
       " '41f7242e-ed62-407b-891d-cc87fcd2d5d3',\n",
       " 'a3bcba86-2cf3-4450-9653-d5157554324d',\n",
       " '389d9fc7-049b-4537-ada9-2cafac48dcc2',\n",
       " '39d5fbbe-6966-42a0-8e31-9ac8744f7703',\n",
       " 'c2d0af1a-f3b2-44a9-8a8f-5f350e6a158a',\n",
       " '6afbc4a1-09a7-41d0-aafe-4f8c126a08d0',\n",
       " '72037d00-abe8-4b46-8bc7-aa0b7a76e0dd',\n",
       " '0cce90d2-5bcc-4078-8ae6-627e1a33ffc1',\n",
       " '08052904-f595-4850-a3bc-4557dff50116',\n",
       " 'f8315b92-3c0c-4bdc-a3b3-5bef3268c54b',\n",
       " '404444a4-4ff4-46f8-bf3b-128653e594d1',\n",
       " '5ec69b2e-0a69-48cb-9d69-a92dfb16f6b3',\n",
       " '9fe5b38e-3ff0-48d4-8e05-af5f23079d2a',\n",
       " '27c42937-a3fc-4fe9-991d-21214a747848',\n",
       " '17ed1a59-d4e8-4cc7-aa7c-2d4677ff2a5c',\n",
       " '56481969-4efe-4657-9076-4d7d73d7e2db',\n",
       " 'a4014f14-80f0-46a7-934f-833ed6deef53',\n",
       " 'b2fc4c91-303b-4474-9453-dc3fedddbba6',\n",
       " '4056f930-775a-474e-a8de-74157041a65c',\n",
       " 'f74baa52-3df6-45c7-8066-80b0c9a94d0b',\n",
       " 'bf1d7214-8a31-4ae1-9459-e473b9e78dec',\n",
       " '4962ab78-10e4-4af4-9e33-e0d7d3b81605',\n",
       " '11e5abf6-7797-4439-80b9-ace4a2530432',\n",
       " '619cc89d-032b-4be4-8913-efedf91902cc',\n",
       " '97d41902-62bc-4ee6-98b0-dd6bd71eee58',\n",
       " '728a7801-2d6d-4896-9353-a7a77a0d8684',\n",
       " 'dedf5744-a53a-476f-9336-2a198e620d8a',\n",
       " '7e7b87d0-ddbe-4a4a-b212-390bb5407a4c',\n",
       " 'e65aa9ac-cadb-4434-9c9f-bf81d3561331',\n",
       " '36895db1-8b60-41ae-8570-f6bb6bca0c4b',\n",
       " 'a1faf8e3-a19d-47bf-a149-9ae589ea424f',\n",
       " '859c5d01-2fba-4e04-92b3-fc9364c2f89a',\n",
       " 'e867d415-11d6-47a8-b5c7-fec414938aa2',\n",
       " 'ff5045ff-8ff4-4c52-8143-6573c96af67d',\n",
       " 'd4648a3f-1263-49dc-ab02-c201dac2a098',\n",
       " 'da6f8293-4025-42ac-bf80-a85cc2aac569',\n",
       " '20b6b56b-64a8-499b-8fac-3178f47e61b4',\n",
       " '86a9e443-f6fb-4ec0-b159-0d52b1ce30b2',\n",
       " '8c8cb56c-e0a4-4e04-a043-0758dff21896',\n",
       " 'b1697a07-d051-46ef-bfbb-0489ca17c3b0',\n",
       " '96515108-e56b-4671-a222-ea47501234d8',\n",
       " '9b055ad2-0678-49fb-8ca5-657fceff4dc5',\n",
       " 'c19f183c-e4f4-4d5b-accf-00c4ffbc29ed',\n",
       " '2945ab45-c00f-4f68-b6cd-b4f54145d3a2',\n",
       " '78346ac5-bbac-4e81-98e8-b44e4301cea3',\n",
       " '66d5ee0c-75f3-416e-b84c-a3d5c5ae0874',\n",
       " '0f944769-6038-49c2-8db3-a384f775a7ff',\n",
       " '3efc3e9d-24d1-458d-a26c-17496a80e4cc',\n",
       " 'd3f74234-7bb5-4bd6-a147-86acdfeb7e79',\n",
       " '2b839741-0843-4a66-8039-8df46e89f9d1',\n",
       " '29f14c3b-fec7-46a1-a93d-ba80a3301fcc',\n",
       " '9bb9e7c3-576d-45fe-b58c-14d4496d1410',\n",
       " 'dc0e4ca0-5965-4999-bba9-fe1110d28dd2',\n",
       " '15867cda-c68f-4a0e-9734-40f31335e3d4',\n",
       " '264ce5a8-07d6-413b-b92d-05fbaebf2e9f',\n",
       " 'f578bef0-a093-48e7-bd57-7c8373d8d8aa',\n",
       " '317da738-ba77-4efe-bc13-b3209b218c8b',\n",
       " '11996da2-be8c-4bdd-b27c-4efdf77ccf75',\n",
       " '35c32c98-adee-4db1-b259-ed6a1c5fc1a9',\n",
       " '8c1586c1-fed6-4825-a445-b634ff92c3ba',\n",
       " 'd30f5796-4ba2-492a-b10f-0069a6870b2c',\n",
       " 'ec639803-b9cd-47cf-893e-0b1124cda31f',\n",
       " '9add45c9-911f-4b7b-a545-71a4928fe46e',\n",
       " 'd6faf626-b962-4ae2-9be8-48a70def59ff',\n",
       " '3425098c-bf13-47cd-a63e-d4daa9894752',\n",
       " 'd3e35f6b-120b-4922-a0d0-a9c82689add0',\n",
       " '1c600c17-6bb6-4473-b0f0-68d1f7304b8f',\n",
       " '782397f3-60b2-48f3-b036-faf27e33b91c',\n",
       " '6b6b0876-bf72-4614-92b2-243b839405cc',\n",
       " '362f41c1-e6d6-4769-aece-ba9a95f8256f',\n",
       " 'cd7c7a7b-6c4a-43ec-9dec-3bea9d0309fd',\n",
       " '87a03706-3bdb-47ac-b6ec-3c5f44a8aa3c',\n",
       " 'bfbe495f-fec8-40a5-95d9-2f1275195b3d',\n",
       " '21991d02-1d82-4ac1-83df-7825b1bfe910',\n",
       " '9f1312dd-140a-480e-8f1d-629d56768d6a',\n",
       " 'ed746181-806f-4bc2-91ad-e5810be6c159',\n",
       " 'dd496924-0494-40f6-a0b4-faabd6828e87',\n",
       " '6e1a5ccf-6348-4cac-ab1c-313fe03e6b5c',\n",
       " '7e27b2fc-dc3b-45c4-bbba-0dfbf07abc47',\n",
       " 'f8479143-19db-4f8d-8287-d329b35923fe',\n",
       " 'bf404578-6fb9-449b-84fa-ed74766ecb67',\n",
       " '596ccaad-092c-4cf3-963a-7adf2feb3cd3',\n",
       " '01c25794-d256-4752-a390-6111450f30bc',\n",
       " '994422f8-a09c-4dbf-9ea3-42624e78c0f6',\n",
       " 'dddecfa2-dfc0-4091-87d3-c64ab84fd1d8',\n",
       " '374c9518-db69-4bc5-b799-a146043db698',\n",
       " '7d8f8b93-df0d-4855-96ea-c8a370094133',\n",
       " '101dbbed-1214-473e-9632-70ffee7e6021',\n",
       " '3c2c88ef-3ea8-415a-a784-a2917b2b5de4',\n",
       " '563bd8c5-8c94-4f12-9d5f-8eda3a6e3661',\n",
       " '56e42e29-5d5d-41d1-92f2-a0b762ce1874',\n",
       " '3d61c129-bd2f-4795-bc46-8899069e4004',\n",
       " 'bc0290fa-9264-480f-9d7b-d447324724ed',\n",
       " 'ff9c4d56-588a-4072-abe6-f8ba898b6145',\n",
       " 'eee63578-74fd-4971-8926-26fe6279368d',\n",
       " '9c1121d1-0f1b-44ea-af8b-d67fb17871d0',\n",
       " '9f013a2a-813f-41bc-9a67-74b3dadc6b10',\n",
       " 'dfde3f8e-6831-4057-b268-392373d5036b',\n",
       " '47bbaf4e-2071-479f-8648-83b10d02f2fe',\n",
       " '3d67eab1-211f-47cd-aa6f-129311ce5899',\n",
       " 'e52df99f-559e-43cf-993e-839bcfbfcc9b',\n",
       " '509e17be-8b24-4cbd-97c5-e86cc37a7f33',\n",
       " '91fed980-b83f-4c77-9854-3f6ab1c3bcee',\n",
       " '478536a6-91e9-4eef-b0e2-093c2086701e',\n",
       " '5ef24677-c9fe-4541-883f-d8f98eb6b715',\n",
       " '6501f96e-56b1-429b-bb23-c3f076f82397',\n",
       " 'd49bc531-53af-45c4-8c83-43473ae69d36',\n",
       " 'c7b69b8e-9322-45bf-bb3f-b0df9d582b47',\n",
       " 'dc113435-2d58-4226-b19e-1463dd174062',\n",
       " '654039a9-1407-496e-a8ce-4b1081552227',\n",
       " 'a0cf5e43-8672-4bd0-bd18-4275dec86616',\n",
       " '8dc685f5-e4a5-4b2c-9e59-d134677d8f40',\n",
       " '9b42471b-d5dd-4224-991e-f7895b7a06ad',\n",
       " '19f6956d-24db-4334-ac4b-49824934e574',\n",
       " '0531aace-ee29-463d-a8df-d5339b375dcc',\n",
       " '3cef9129-d22a-4b5a-b309-41e260abdad3',\n",
       " '4cd657f6-ec66-4fe6-bb5f-cb93e65540e4',\n",
       " '54076462-b5f4-44f9-ac27-f2d4afc265a3',\n",
       " '966c30f5-9b19-452d-83e8-ecd414cd5bd3',\n",
       " '6e560f8c-2882-4e4a-ad8d-8e5cf89de83a',\n",
       " '8ab5e63c-9077-4458-9f01-763e37eee095',\n",
       " '74b26f95-4793-4fcc-a488-1fb902d0954a',\n",
       " 'f32afb2d-9e76-46ae-b248-56eace7d24ef',\n",
       " '7dbcdaa0-4afa-4091-b081-36c8bdb3fc58',\n",
       " '7bfa0a3b-7bad-4991-86d6-402c2108c82f',\n",
       " '8fb54feb-a810-4bd8-aed1-49f902d96c5e',\n",
       " 'df574ccf-2df7-4c09-9a93-8d83757ec86c',\n",
       " 'a15707df-e718-462c-8bd4-5c8871ebeea3',\n",
       " 'c1ec9ff6-cf34-4288-ae30-d94be93e4147',\n",
       " 'd4ebe962-d9a1-47ea-9456-b838ba452801',\n",
       " '1f070236-e624-4970-afc8-6fe226150863',\n",
       " 'a680c13c-412c-4217-870f-d19e2e77cda9',\n",
       " '37ae5813-aa29-4606-b42b-8e8137e09a79',\n",
       " '1e990148-8edb-4145-bd7e-dd7d9781635c',\n",
       " 'aa050796-ecbe-4d29-bda3-745ee5823db0',\n",
       " 'a2154d75-b9a0-485d-ab45-65b44a36df3c',\n",
       " 'e90b1563-8299-4d8a-a1f2-ba9e4ae2c2a2',\n",
       " '56b1c839-ef68-49eb-bc8b-1ceb4f2cd862',\n",
       " '97f3bde8-510d-48e5-bb35-7be6e6aa3600',\n",
       " 'f16280e3-c597-4134-966d-889657c1e710',\n",
       " '121d2ef4-76fa-4fe8-bf3f-54048cb2b78a',\n",
       " '3d4b9a2f-e612-412f-9370-2d57bf8cb84c',\n",
       " '9b8ac7e0-28aa-43d1-944c-22345ff47cbe',\n",
       " '0a895905-08f9-42a9-9a87-9615f4004bd8',\n",
       " 'a7b44cf1-7d5f-4045-9246-19e790761112',\n",
       " '2d4a324b-bcc5-424b-ab14-0696d0c15450',\n",
       " 'b41e6ef7-3ead-4a26-bd71-2f23f9b6f237',\n",
       " '03093832-77d8-41fb-bb83-e44439b44daa',\n",
       " '42041cfd-f71b-4d06-927a-93fb06fdf6a7',\n",
       " '89bd93a3-9521-49fe-bac6-8256f59cc4d7',\n",
       " 'cd866d9a-fe0c-47f7-a914-8f54c3bed64c',\n",
       " '81162be6-7a3f-4db7-8632-4ecb722e790b',\n",
       " '78b83f5c-dfc3-4f1c-bd94-47bb84014ff6',\n",
       " '4587ef41-cf3a-4a38-8bfa-be6e728300e9',\n",
       " '3fd96c65-a43d-46ab-bd3c-1a3442610326',\n",
       " 'e4b5087c-d189-4da0-8d0c-50f3852f484d',\n",
       " '3abe340a-96f8-4e1e-b299-4382dabef856',\n",
       " 'f4a6bacb-474a-42a4-a082-8fd7e911dc55',\n",
       " 'df746542-50c2-4adc-9b97-0bda9ceb0236',\n",
       " '1faccbf9-e20e-40c8-953e-a8b9a7acf253',\n",
       " '7b729dea-c91d-4b64-8c76-d51f9898a88c',\n",
       " 'e57348dd-729d-40bd-8d81-432da150d644',\n",
       " '37cdd506-4b9d-4002-8741-52cd0504da88',\n",
       " 'dfb98a44-efb6-4b31-a661-78ece061fa72',\n",
       " '9070df53-a2ac-40de-b3b1-3d136334fd9a',\n",
       " 'c5f13f2d-6da8-4c74-a9b6-def590252a3f',\n",
       " 'ce2b9823-25c4-4f05-8d12-284de4d3075a',\n",
       " '97dffd27-36d8-43c2-92bb-2adfa50173e5',\n",
       " '2aa1967b-4db4-437d-b5a5-ccb70c64e839',\n",
       " '8f93a374-3685-4053-bafd-7e878a86b6d8',\n",
       " '174d50de-fa6d-4009-83fd-7314168fc762',\n",
       " '6186ddb6-eba2-470d-96bc-e055f2b8c2a7',\n",
       " 'b0b8c185-dd36-4ede-862c-9388530fb368',\n",
       " 'c9b94757-e042-4f47-a0f8-de3d84a0a708',\n",
       " 'a8909b3b-83b6-4714-8f96-7e989d689333',\n",
       " 'a22bac24-3f09-4d08-a4ba-f401ce1d7e61',\n",
       " '01f2966c-eb0e-4c61-997c-3cde5857e8b6',\n",
       " '3b365bb7-6670-4f90-beba-aaaf94cac685',\n",
       " 'a48ff178-f129-44a4-be11-b8da6b64834f',\n",
       " '69e765f0-c43b-412b-91ae-baff1a2b4a7c',\n",
       " 'ac0a74ce-7372-433b-8b1c-7abd4080c71c',\n",
       " 'c178bab4-f3cf-4799-857d-dffaa1468b7b',\n",
       " 'ebf48fc0-cb32-4807-b347-3fe4df7300c5',\n",
       " '2024d8ec-0593-485a-9b97-75e40b5e2c99',\n",
       " '10b159cf-d9df-497f-921d-cb3dc0563861',\n",
       " '656ab109-6f9c-4f65-9a6c-0520f4ddba26',\n",
       " 'c55effe2-ce52-479c-afda-5b1d2e1ec989',\n",
       " '8a9a4221-fcac-4c0e-8976-f8540fa85f5a',\n",
       " '82c6e04a-8ed0-4100-bc3c-179529e583e6',\n",
       " 'aa892fb5-f1df-471c-837a-ac86632d052d',\n",
       " 'd037a16e-be8d-4f2f-b06f-a943515251ac',\n",
       " '45193a17-8b78-4bbb-b0a7-5c539fdf3e4c',\n",
       " 'ffcae597-ca1f-449f-adeb-662ccec4ca3c',\n",
       " '9fc541ff-b9c1-488a-8eae-ab0e6c3e7f45',\n",
       " '2d84cfab-38a3-43cf-80a6-d2864a4f51e9',\n",
       " 'b0070eba-9e1e-4908-b3d6-5ce41fe1cf6a',\n",
       " '2d907d86-5911-4b99-adca-fff01dea8753',\n",
       " '1a0e3beb-e364-4f08-81a5-e81403f823b4',\n",
       " 'd97ded32-ef40-4173-b596-9e8802bded59',\n",
       " 'ff4ba2e6-54cb-4b09-80ea-6bae137072a4',\n",
       " '1254bb77-f7b1-4dbd-ac80-d499ca71f477',\n",
       " '30819b34-dba7-434b-af7c-f8aa85c72a9a',\n",
       " 'fdf91d7c-da47-4bee-be3c-b5e4d699d9d7',\n",
       " 'd1b4c134-fb55-4e5a-97a5-20d9c7442783',\n",
       " '7d3b6b87-bf24-442e-a359-f7d4f417659e',\n",
       " '0da52dfc-e010-423d-afb6-911e9c4acb46',\n",
       " '89dd619d-abf9-4871-8fab-2abc6c6d99e5',\n",
       " '049f28ae-ab12-42d0-8afb-90234866aff7',\n",
       " '6f161547-39d0-4673-bf9c-ff7a2fc6ddbc',\n",
       " '05dbc193-b15b-45ff-9ad3-02b75df1e774',\n",
       " '7f3a9746-194f-45ca-b2f9-13a9cffa51d7',\n",
       " 'bd3c337d-7599-4c79-ac7e-c5c373829a83',\n",
       " '7e8206a4-f095-497f-a5e6-97117e7ab610',\n",
       " 'eef0175d-603a-4c04-b2a6-6ee5aa8ff5f3',\n",
       " '9f65ab80-aa23-437d-83f2-23c33837f776',\n",
       " '0ce8b2fe-57bc-433b-9db6-2a148eb5d9bb',\n",
       " 'add66f6a-1ec9-4e60-a5a0-6c6c9aaecf79',\n",
       " 'b5f511fa-535c-4b2f-910e-89f26b808b1a',\n",
       " 'dba36f7b-c3ab-4079-988a-2aae9cfd02c5',\n",
       " 'f7e31ce8-5b32-4e24-861f-de930ad61ff4',\n",
       " '3f2b0cbf-7f4c-48ee-9b1e-4a0130bdda3a',\n",
       " 'd56f630e-b603-4053-9ca3-4ecf86e23a96',\n",
       " '23d7b2f3-539b-4195-b0d2-589e438651b2',\n",
       " '70b78bf2-a903-46e9-a670-3b88f7b2b2ca',\n",
       " 'dbcadcae-34d2-437c-aa9c-e5d64322dc95',\n",
       " 'f9efc4e4-4777-4953-a802-34d731c6f1ec',\n",
       " '1a4d6b26-a48c-40f4-969c-72a7d2e4d2d1',\n",
       " 'eb5b7a92-c293-4054-89e6-72e9ce2f2b26',\n",
       " '13d5febb-cf5f-4b0f-ab2c-40cc185bfb99',\n",
       " 'fa189907-e796-4e3e-8bc2-bc0ce179f7b1',\n",
       " 'e688becb-e8d4-4617-b1ad-91467e7f75c0',\n",
       " '62645f29-7aba-48d1-9d5a-bbadc6b2188e',\n",
       " 'b3b676e1-5359-424c-beda-40e80301461d',\n",
       " '44ead622-3c58-4152-81f2-89f4218c8dbf',\n",
       " 'b3347089-f0ff-40f8-b4ad-2ec31db1f80e',\n",
       " '3834eb62-8fcf-434c-8f2c-bba424eb62c2',\n",
       " '46faefa2-b888-40ce-9dd2-23f224fd30e8',\n",
       " 'c7df0d5e-5a51-4871-8238-aa01be038201',\n",
       " 'f81cdcef-29f6-40c2-8041-9cabf1cfaf0b',\n",
       " 'cb309114-06af-4f6b-aeb0-ff3c985d98f4',\n",
       " 'fceb33a1-85ae-4d11-a2be-dec03539b2a3',\n",
       " 'ed0f4882-262c-40b5-9569-e2867935eb37',\n",
       " '6907beeb-ddff-4fb3-a310-7204a50ca450',\n",
       " '9739eb8e-d77c-4dcc-9cb9-973179c3a3e2',\n",
       " '84f210e5-e563-4354-aa59-9e403069d0cb',\n",
       " '9ba9b044-589d-41f1-9bc7-9b84e5ebaba6',\n",
       " '9b128f98-1a3f-4ad3-912d-e3c797642ac8',\n",
       " '68b1e12f-d712-4c1a-914f-c4fd589a5d19',\n",
       " '781dbf7d-c63e-4dd5-bf01-640ec01a0b00',\n",
       " 'd9d3c97e-0a45-4202-96be-8d7f3856951c',\n",
       " 'e749a68f-f712-4f87-9025-92b771699398',\n",
       " '747aab70-74f6-43d6-afd6-821abd48a0ce',\n",
       " '5e7f0e29-5925-4186-8a02-fd165584fce7',\n",
       " 'b33170f0-aa94-4a23-b041-90ebeb66c654',\n",
       " 'e607665c-2b20-4805-89ea-340c996131da',\n",
       " '42e8cb68-b64e-47f7-b795-b702807e3168',\n",
       " '3078cb8b-4299-46ac-99a1-fdd798998677',\n",
       " '36a760a4-3550-4f6a-9c16-dd6915162ce0',\n",
       " 'db389b78-18d2-4731-a3ea-a4a8a5cad0f1',\n",
       " 'd6ab9d5e-f443-42a9-b286-0a2c6f3cc4bf',\n",
       " 'f5dca9ba-650c-43ec-aa08-29a63335ccf1',\n",
       " '8fc9a745-f083-44c8-aa77-0bde2f53b57a',\n",
       " '3bce0b78-3060-458d-807d-0c87428b8593',\n",
       " '794f9dc6-ef7d-4664-8f5f-0e09f5b11ad5',\n",
       " 'eb4433d2-bb97-4e26-b674-28cadd28a842',\n",
       " '03d45cd2-3f2d-4eb7-b527-dffa01627c4c',\n",
       " '049b37d0-52d9-4f0e-8b80-4d72ad539b1f',\n",
       " '7e13fe1c-29fb-4ba5-bb9a-2324913c38f9',\n",
       " '7af74cef-3de8-493e-b8a4-da4642b1b7da',\n",
       " '6943e25d-3ecf-4c09-bd2f-1f06ab57efed',\n",
       " '00bae783-ef53-43ca-8dc3-95eb36a62905',\n",
       " 'e17336e9-5dda-4761-bdc9-e5b08a0e0111',\n",
       " '1f892f1a-1e40-4317-bda7-6769c8e34355',\n",
       " 'c092436a-b0c0-4bdb-9110-b86dbaa58f3c',\n",
       " '3f93a121-3068-48b9-b2b5-e6c07519e4a0',\n",
       " 'ef7a07ae-56f3-4263-b171-acde896fb217',\n",
       " '8f5daa6c-ea74-423b-8944-91d31a3fd995',\n",
       " '2344670b-f2a8-4c7a-abce-fc40abb31640',\n",
       " 'b357c3f5-889d-4dff-82c2-8a8d50236f8c',\n",
       " 'ad88e412-86f8-4de6-bb35-7a867c0e6a81',\n",
       " 'fc612b98-cee4-4fe8-bb5e-fbd710714713',\n",
       " '19e59111-f08d-4915-9f16-9c8db9c860cf',\n",
       " '3af8c923-0db1-460d-9b4f-c6eb51615888',\n",
       " '6ef3d462-0289-4586-bdbe-b8e46870f281',\n",
       " '97368910-6b0c-4e8f-b98b-d1eb86eeccf8',\n",
       " '9a286523-fc75-45b8-b9a9-6b9f6004f288',\n",
       " '5a6e729a-a872-4364-a2ea-5bd915cafe6b',\n",
       " '9cd485fe-6545-41f1-8a86-ede8c2197a05',\n",
       " '9f4367b6-e9fe-48d5-b7c2-4399e6c39743',\n",
       " '641c4e44-5bc8-4e1f-9f44-e2a8cbea2d82',\n",
       " '0e0ae1c1-d22d-4df1-9415-5858a3e9004c',\n",
       " '1de75c09-201f-4d00-bc96-d3e9e0c0e2ae',\n",
       " '910f26a4-9376-46d0-a00f-64347fb5c514',\n",
       " 'd39936df-f411-4868-8a92-2baa79ca1955',\n",
       " '77ee0662-c4e7-4cba-84cf-a915e6a678e2',\n",
       " 'c242bad4-3c00-4e06-8cb3-a54df84da499',\n",
       " 'c3735eba-4d67-4f0d-a199-c34dd7c203a4',\n",
       " 'e8d604ce-65af-451b-b6e9-46b5f0cfaba2',\n",
       " '8e8613a8-a09c-49c8-99e1-81d264ff721f',\n",
       " 'c81e5b62-c05d-45ef-8de9-6f755e0ef5d6',\n",
       " 'ee5ee5fd-6fe3-4f39-b3ef-fd1e976a087a',\n",
       " 'bb3e3855-ae13-4905-a4f7-a1dc37a42d0b',\n",
       " '3e02cb03-7eae-4d0b-918c-537107cad91a',\n",
       " 'f01d0bcb-b210-409c-a438-74e89294256c',\n",
       " 'd1238c32-7061-468f-a737-1c03c5c77ad2',\n",
       " '910808db-caf8-4b7c-b92b-ae0ab1126abf',\n",
       " '89a85e39-6ccb-459d-ac0a-983c53b148b8',\n",
       " '548446eb-1242-4f8c-851a-cc868a91864d',\n",
       " '0b0e2500-806d-4340-b94e-c486f98d02fc',\n",
       " '098803c7-d300-41cd-a034-5d1243da02cd',\n",
       " '28817c82-ff80-42af-aaa5-6cd59fc1f9b0',\n",
       " 'f1d6358d-31ec-43d7-ac28-83f67fb93198',\n",
       " '54d8301b-6a40-4a00-8f3d-4950556ca5c3',\n",
       " '36ea84ff-d1d7-4891-8b38-1d178229f6cb',\n",
       " 'eea227a7-6bd8-451c-9d61-f810ceff8096',\n",
       " 'c9dba7d7-ce27-499c-a908-d4bbf4f7872a',\n",
       " '1ed1d9e8-bd4c-4db4-84d9-b032711c1e9e',\n",
       " 'a0ba979b-2b66-48f8-9205-b158b4a9fed0',\n",
       " '0cafda19-e059-42ee-81f7-a1d02d099527',\n",
       " 'fa2ed4e0-bd52-46d0-8f68-b995bad9e6c7',\n",
       " '1516c42a-6190-41e0-927d-90bbf54e44ef',\n",
       " '637e810d-21eb-4643-80fd-469c63bf94d9',\n",
       " '7b4c1bb4-6e6a-473f-964d-e69dccb0a3d1',\n",
       " '4d212f61-97fe-4ac8-981e-5be90472f856',\n",
       " '7fba8fae-096e-4907-a62f-ca70f870fc85',\n",
       " '44f0e1f6-60f2-4278-965d-8d0d0193306e',\n",
       " '25e566d8-b9d5-4233-9baa-dc8f732dc0c1',\n",
       " '56f6a92b-c0ff-48e9-a3da-0220e02a5327',\n",
       " '82393d96-7907-4813-b525-89fb322e1e8f',\n",
       " '6cc3dc5c-3807-4454-8b2b-f569fdf162e4',\n",
       " '503395dd-b13e-4975-99f9-130bd2fe3890',\n",
       " 'c2875aac-7e24-425b-ac92-9eeaab83975a',\n",
       " '144978b0-c1f7-4fee-b7f6-a95694b643a0',\n",
       " 'd395bc53-14f1-4d2b-917b-1f87314e340f',\n",
       " 'fe326629-6502-49b6-a7ae-39a9d7c1d72b',\n",
       " 'd604cfda-839d-41e4-8ec4-d6bed48e8f2e',\n",
       " '9d286f73-3d4a-415f-ade2-4503906e7cd7',\n",
       " 'a4983f10-fd5f-44c3-8db0-348b01ba5779',\n",
       " '670199a8-d5a9-4ca0-98fd-832c8c86ee8e',\n",
       " '02b6639b-7fd6-4ad4-95db-a8658811ecee',\n",
       " '1620b401-31e1-4d9e-86f4-ebc1283bc07c',\n",
       " '3daca19b-8045-4367-a177-8b0b21e07ce4',\n",
       " 'ef24f4a3-0587-4999-9385-aa3eaf74dc9d',\n",
       " 'df9ac4c4-a29b-4960-8f85-2a0a6d686fea',\n",
       " 'b41f4ba5-99d9-46fc-94f9-0b7865e1ab46',\n",
       " 'd2454e5d-71cd-4174-adbb-02a21c745a09',\n",
       " '4952ca48-b887-42fd-94a4-b9c2f9c4e0d0',\n",
       " '8a4dc024-ce38-4b71-9cc6-a2c8e6deee0a',\n",
       " '9ff02a89-aa7d-43d1-bd1e-c470d46eebe2',\n",
       " '154a45b6-5751-42c3-9b07-bb5993a102b7',\n",
       " '6b4e2993-02b4-498a-b309-e8a6b4e14e5a',\n",
       " '1e6e924b-5c48-4585-972f-113d36e172eb',\n",
       " '169c3d12-0f98-4887-94bf-cdb354f9399a',\n",
       " 'adb1ba27-7913-4e8b-aa12-3e18e67abc7f',\n",
       " '80890105-e73a-43fe-9316-f7934597bc24',\n",
       " '3776f251-252e-4c23-97d8-439d45cfb1a7',\n",
       " 'f3c3798f-d04a-4d32-a23d-e2fc4d769d0f',\n",
       " '59504180-c05d-4efe-8741-4b48a31f734d',\n",
       " 'aad8df02-60b4-46d0-a17b-7993b30c62c1',\n",
       " '6777380d-44c5-44ec-81f3-9ed9d96ca2e7',\n",
       " 'acbcc52c-8e49-4801-ac3b-9828c92a43e8',\n",
       " '289d5b0e-32c5-4258-9dd1-2213ee27b1ca',\n",
       " 'b965916a-d996-485e-a952-e4aad6b133ff',\n",
       " '12f4152e-dc2a-4017-b720-7e92d8148dc0',\n",
       " 'fabacdb6-01a7-4139-abcc-8422bd0955fc',\n",
       " '1a33ee04-27d2-46df-bf48-bc8c448833e6',\n",
       " '900fd117-6b2a-434b-8404-1cc2eceb71b8',\n",
       " '79dfb4ac-89f0-479a-af2b-09510b46ea55',\n",
       " '2d4683b3-03bb-4740-9d83-e17db153ab1b',\n",
       " '9444e041-810d-4102-89f5-7482c9f1eb57',\n",
       " '2457f9f8-804e-4a7b-b5bb-27b097a70fbb',\n",
       " '8e3d4061-2acb-4779-8345-7b937a44a6f4',\n",
       " '0007b311-0130-4d9b-8225-d0f33bcc4700',\n",
       " '6e68b7bf-4869-4896-ae9e-d74a0a5b60f7',\n",
       " 'b0de60ca-2172-4c4b-b8f5-44714aeb3f7d',\n",
       " '8c1266de-78fb-4017-9253-a29e6139bff8',\n",
       " '61723303-8818-49dc-86f0-f012fb9e6126',\n",
       " 'f69cabcf-5d84-47b4-9ec1-011daeab44a1',\n",
       " 'cca3fa14-21e8-49e9-aea2-1426eb9659e4',\n",
       " 'cf302c2e-9447-4c37-a461-a0b5fde8d197',\n",
       " '7a275708-a470-4201-b4d8-44574a53f4c1',\n",
       " 'deb088f3-2134-45b2-9b21-3d55756d89cd',\n",
       " 'f3504907-f7e7-4368-8fd4-69f6134662da',\n",
       " 'b00d7160-7d0f-4851-b495-5595509f08fe',\n",
       " 'c058af29-e4fb-4095-9856-09f7f1c3f688',\n",
       " '8139fb84-dd8d-49bb-9eb7-18ed23e661ef',\n",
       " '1370c086-f255-47a7-ada5-8cb62a097678',\n",
       " '7043509d-28b8-45d6-ba2c-615b0e4556df',\n",
       " 'c165ac30-fc02-4f9a-8187-a1b40d08015b',\n",
       " '52294d73-1745-4fb1-8047-5ead64c42f43',\n",
       " '608767b3-66be-4cfe-a000-3367973dd62b',\n",
       " '75bc909e-93ee-46ab-a5f5-e7ec73bb9522',\n",
       " ...]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Your TASK ####\n",
    "# With the chosen PDF loaders, test different splitters and chunk size until you feel that the chucking makes sense. \n",
    "# You can also try different embeddings\n",
    "# Then embed the entire book 1 into ChormaDB\n",
    "data_1 = PyPDFLoader(\"/ssdshare/share/lab4/hp-book1.pdf\").load()\n",
    "texts_1 = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=80).split_documents(data_1)\n",
    "docsearch_chroma_1 = Chroma(\n",
    "    embedding_function=baai_embedding,\n",
    "    persist_directory=chroma_dir,\n",
    "    collection_name=\"harry-potter-01\",\n",
    ")\n",
    "docsearch_chroma_1.reset_collection()\n",
    "docsearch_chroma_1.add_documents(texts_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa211d6-014a-4b99-8c79-1699557e0fe1",
   "metadata": {},
   "source": [
    "### 2.5 Query those docs with a QA chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f035d818-b8cf-4d49-9a6f-ba233e204188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0, model=CHAT_MODEL)\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm, \n",
    "    chain_type=\"stuff\", \n",
    "    verbose=True, \n",
    "    retriever=docsearch_chroma_reloaded.as_retriever(k=5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9db75a21-9f02-4e09-98ef-81c40d6e04a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search returned 4 results. \n",
      "CHAPTER ONE \n",
      " \n",
      "THE BOY WHO LIVED \n",
      " \n",
      "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say  \n",
      "that they were perfectly normal, thank you very much. They were the last  \n",
      "people you'd expect to be involv ed in anything strange or mysterious, \n",
      "because they just didn't hold with such nonsense.  \n",
      " \n",
      "Mr. Dursley was the director of a firm called Grunnings, which made  \n",
      "drills. He was a big, beefy man with hardly any neck, although he did  \n",
      "have a very large mustache. Mrs. Dursley was thin and blonde and had  \n",
      "nearly twice the usual amount of neck, which came in very useful as she  \n",
      "spent so much of her time craning over garden fences, spying on the  \n",
      "neighbors. The Dursleys had a small son called Dudley and in their  \n",
      "opinion there was no finer boy anywhere.\n",
      "=============\n",
      "\"What's his name again? Howard, isn't it?\"  \n",
      " \n",
      "\"Harry. Nasty, common name, if you ask me.\" \n",
      " \n",
      "\"Oh, yes,\" said Mr. Dursley, his heart sinking horribly. \"Yes, I quite  \n",
      "agree.\" \n",
      " \n",
      "He didn't say another word on the subject as they went upstairs to bed.  \n",
      "While Mrs. Dursley was in the bathroom, Mr. Dursley crept to the \n",
      "bedroom \n",
      "window and peered down into the front garden. The cat was still there.  \n",
      "It was staring down Privet Drive as though it were waiting for  \n",
      "something. \n",
      " \n",
      "Was he imagining things? Could all this have anything to do with the\n",
      "=============\n",
      "of it, he wasn't even sure his nephew was called Harry. He'd never even  \n",
      "seen the boy. It might have been Harvey. Or Harold. There was no point  \n",
      "in worrying Mrs. Dursley; she always got so upset at any mention of her  \n",
      "sister. He didn't blame her -- if he'd had a sister like that... but all  \n",
      "the same, those people in cloaks... \n",
      " \n",
      "He found it a lot harder to concentrate on drills that afternoon and  \n",
      "when he left the building at five o'clock, he was still so worried that  \n",
      "he walked straight into someone just outside the door.  \n",
      " \n",
      "\"Sorry,\" he grunted, as the tiny old man stumbled and almost fell. It  \n",
      "was a few seconds before Mr. Dursley realized that the man was wearing a  \n",
      "violet cloak. He didn't seem at all upset at being almost knocked to the\n",
      "=============\n",
      "on the wall outside was showing no sign of sleepiness. It was s itting as \n",
      "still as a statue, its eyes fixed unblinkingly on the far corner of  \n",
      "Privet Drive. It didn't so much as quiver when a car door slammed on the  \n",
      "next street, nor when two owls swooped overhead. In fact, it was nearly  \n",
      "midnight before the cat moved at all. \n",
      " \n",
      "A man appeared on the corner the cat had been watching, appeared so  \n",
      "suddenly and silently you'd have thought he'd just popped out of the  \n",
      "ground. The cat's tail twitched and its eyes narrowed.  \n",
      " \n",
      "Nothing like this man had ever been seen on Pri vet Drive. He was tall, \n",
      "thin, and very old, judging by the silver of his hair and beard, which  \n",
      "were both long enough to tuck into his belt. He was wearing long robes,\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "# query = \"How did Harry's parents die?\"\n",
    "query = \"What is the cat on Privet Drive?\"\n",
    "docs = docsearch_chroma_reloaded.similarity_search(query)\n",
    "print_search_results(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "98270f41-fddd-4be0-909d-c80345e98470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What is the cat on Privet Drive?',\n",
       " 'result': 'The cat on Privet Drive is described as sitting still as a statue, watching the corner of the street with unblinking eyes. It is later revealed that this cat is actually **Professor McGonagall**, who is an Animagus (a witch or wizard who can transform into an animal). She is watching Privet Drive in her cat form before she transforms back into her human form when Albus Dumbledore arrives. \\n\\nSo, the cat is Minerva McGonagall in disguise.'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "43d0d396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search returned 6 results. \n",
      "since they’d seen him make Nevill e’s toad zoom around the class-\n",
      "room. Professor Flitwick put the class into pairs to practice. Harry’s\n",
      "=============\n",
      "ever, she fluttered down between  the marmalade and the sugar \n",
      "bowl and dropped a note onto Harry’s plate. Harry tore it open at \n",
      "once. It said, in a very untidy scrawl: \n",
      " \n",
      "Dear Harry, \n",
      "I know you get Friday aftern oons off so would you like \n",
      "to come and have a  cup of tea with me  around three?\n",
      "=============\n",
      "“Funny stuff on the news,” Mr . Dursley mumbled. “Owls . . . \n",
      "shooting stars . . . and there were a lot of funny-looking people in \n",
      "town today . . .” \n",
      "“So?” snapped Mrs. Dursley. \n",
      "“Well, I just thought . . . maybe . . . it was something to do \n",
      "with . . . you know . . . her crowd.” \n",
      "Mrs. Dursley sipped her tea through pursed lips. Mr. Dursley \n",
      "wondered whether he dared tell he r he’d heard the name “Potter.” \n",
      "He decided he didn’t da re. Instead he said, as casually as he could,\n",
      "=============\n",
      "the library with her, trying to get through all their extra work. \n",
      "“I’ll never remember this,” Ro n burst out one afternoon, throw-\n",
      "ing down his quill and looking lo ngingly out of the library win-\n",
      "dow. It was the first really fine day they’d had in months. The sky \n",
      "was a clear, forget-me-not blue, and there was a feeling in the air of \n",
      "summer coming. \n",
      "Harry, who was looking up “Dittany” in One Thousand Magical  \n",
      "Herbs and Fungi,  didn’t look up until he  heard Ron say, “Hagrid!\n",
      "=============\n",
      "was allowed to finish the first. \n",
      "Harry felt, afterward, that he sh ould have known it was all too \n",
      "good to last. \n",
      "After lunch they went to the rept ile house. It was cool and dark \n",
      "in there, with lit windows all along the walls. Behind the glass, all \n",
      "sorts of lizards and snakes were crawling and slithering over bits of \n",
      "wood and stone. Dudley and Piers wanted to see huge, poisonous\n",
      "=============\n",
      "Harry nodded. \n",
      "“Oh — well, I thought it might be one of Fred and George’s \n",
      "jokes,” said Ron. “And have yo u really got — you know . . .”\n",
      "=============\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Why is Harry left with the Dursleys rather than a Wizard family?',\n",
       " 'result': 'Harry is left with the Dursleys because Albus Dumbledore decides it is the safest place for him. After Voldemort kills Harry\\'s parents, James and Lily Potter, Dumbledore uses powerful magic—specifically, Lily\\'s sacrificial protection—to safeguard Harry. \\n\\nKey reasons Harry stays with the Dursleys:  \\n1. **Blood Protection**: Because Lily\\'s sister, Petunia (Harry’s aunt), shares Lily’s blood, Harry’s mother’s sacrificial protection extends to Petunia’s home. So long as Harry calls that place \"home,\" the protection shields him from Voldemort and his followers due to ancient magical bonds tied to blood.  \\n2. **Secrecy & Safety**: Staying with Muggles hides Harry from the wizarding world, reducing the risk of Death Eaters or allies of Voldemort finding him. The Dursleys’ non-magical status makes them an unlikely target.  \\n3. **Dumbledore’s Plan**: Dumbledore believes isolating Harry from wizard fame will keep him humble and better prepare him for future challenges.  \\n\\nThough the Dursleys are neglectful and cruel, the protection lasts until Harry turns 17 (or no longer calls Privet Drive \"home\"). Later books reveal even greater layers to this arrangement tied to Lily’s magic.  \\n\\n**From the text provided**: While these specific reasons aren’t detailed in the excerpts here, the earlier mention of Mr. Dursley’s unease about \"her crowd\" (Lily’s magical connections) hints at the tension between the magical and non-magical worlds, setting up the Dursleys\\' hostility toward Harry’s true heritage.  \\n\\nIf you\\'d like exact chapters/book references, let me know!'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Your Task ####\n",
    "# Rebuild the chain from the whole book ChromaDB.  Test with one of the following questions (of your choice).\n",
    "#query = 'Why does Dumbledore believe the celebrations may be premature?'\n",
    "#query = 'Why is Harry left with the Dursleys rather than a Wizard family?'\n",
    "#query = 'Why does McGonagall seem concerned about Harry being raised by the Dursleys?'\n",
    "docsearch_chroma_reloaded_01 = Chroma(persist_directory = chroma_dir,\n",
    "                                      collection_name = 'harry-potter-01', \n",
    "                                      embedding_function = baai_embedding)\n",
    "query = 'Why is Harry left with the Dursleys rather than a Wizard family?'\n",
    "docs = docsearch_chroma_reloaded_01.similarity_search(query, k=6)\n",
    "print_search_results(docs)\n",
    "\n",
    "chain_01 = RetrievalQA.from_chain_type(\n",
    "    llm, \n",
    "    chain_type=\"stuff\", \n",
    "    verbose=True, \n",
    "    retriever=docsearch_chroma_reloaded_01.as_retriever(k=5)\n",
    ")\n",
    "chain_01.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c4599ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Tell me about Harry Potter and Quidditch during the first year',\n",
       " 'result': \"During his first year at Hogwarts (as described in *Harry Potter and the Philosopher's Stone*/*Sorcerer's Stone*), Harry Potter plays a pivotal role in Gryffindor's Quidditch team. Here are the key details:  \\n\\n1. **Discovery as Seeker**: After flying expertly during Neville’s rogue Remembrall incident, Professor McGonagall recruits Harry as Gryffindor’s Seeker—making him the youngest player in a century. She gifts him a top-tier **Nimbus 2000** broomstick.  \\n\\n2. **First Match vs. Slytherin**:  \\n   - During the match, Harry’s broom is jinxed (by Quirrell, though Snape is initially suspected).  \\n   - Hermione notices Snape muttering and sets his robes on fire, breaking the curse.  \\n   - Harry nearly **swallows the Golden Snitch** but catches it mid-air, securing victory.  \\n\\n3. **House Matches & Training**:  \\n   - Harry trains extensively with teammates Angelina Johnson, Fred, and George Weasley.  \\n   - His flying skills impress everyone, reinforcing his natural talent.  \\n\\n4. **Final Match & Quidditch Cup**:  \\n   - During a later match, Harry catches the Snitch **in record time**, winning the Quidditch Cup for Gryffindor.  \\n   - It’s later revealed that Quirrell (possessed by Voldemort) had been sabotaging Harry during games.  \\n\\nQuidditch becomes a defining part of Harry’s first year, showcasing his bravery, skill, and importance to Gryffindor’s success. Let me know if you'd like further elaboration!\"}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Your Task ####\n",
    "# Using langchain documentation, find out about the map reduce QA chain.  \n",
    "# answer the following questions using the chain\n",
    "#chain = load_qa_chain(llm, chain_type=\"map_reduce\")\n",
    "# answer one of the following questions of your choice. \n",
    "# query = What happened in the Forbidden Forest during the first year of Harry Potter at Hogwarts?\n",
    "query = 'Tell me about Harry Potter and Quidditch during the first year'\n",
    "chain_02 = RetrievalQA.from_chain_type(\n",
    "    llm, \n",
    "    chain_type=\"map_reduce\", \n",
    "    verbose=True, \n",
    "    retriever=docsearch_chroma_reloaded_01.as_retriever(k=5)\n",
    ")\n",
    "chain_02.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a99610f",
   "metadata": {},
   "source": [
    "### 2.6 (Optional) Use DSPy with ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fe9714a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from dspy.retrieve.chromadb_rm import ChromadbRM\n",
    "\n",
    "lm = dspy.LM(\n",
    "    \"openai/llama-3.3-70b-instruct\",\n",
    "    api_base=os.environ[\"OPENAI_BASE_URL\"],\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "# pinecone retriever has some issues with the current version of dspy so we will use chroma retriever\n",
    "chroma_retrieve = ChromadbRM(\n",
    "    collection_name=\"harry-potter\",\n",
    "    persist_directory=\"/scratch1/chroma_db\",\n",
    "    embedding_function=baai_embedding.embed_documents,\n",
    "    k=5\n",
    ")\n",
    "\n",
    "dspy.settings.configure(\n",
    "    lm=lm,\n",
    "    rm=chroma_retrieve\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8c510ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a class named GenerateAnswer which inherits from dspy.Signature\n",
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Think and Answer questions based on the context provided.\"\"\"\n",
    "\n",
    "    # Defining input fields with descriptions\n",
    "    context = dspy.InputField(desc=\"May contain relevant facts about user query\")\n",
    "    question = dspy.InputField(desc=\"User query\")\n",
    "    \n",
    "    # Defining output field with description\n",
    "    answer = dspy.OutputField(desc=\"Answer in one or two lines\")\n",
    "\n",
    "\n",
    "# Define a class named RAG inheriting from dspy.Module\n",
    "class RAG(dspy.Module):\n",
    "    # Initialize the RAG class\n",
    "    def __init__(self):\n",
    "        # Call the superclass's constructor\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize the retrieve module\n",
    "        self.retrieve = dspy.Retrieve()\n",
    "        \n",
    "        # Initialize the generate_answer module using ChainOfThought with GenerateAnswer\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "    \n",
    "    # Define the forward method\n",
    "    def forward(self, question):\n",
    "        # Retrieve relevant context passages based on the input question\n",
    "        context = self.retrieve(question).passages\n",
    "        \n",
    "        # Generate an answer based on the retrieved context and the input question\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        \n",
    "        # Return the prediction as a dspy.Prediction object containing context and answer\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a3a810f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RAG (Retrieval-Augmented Generation) object\n",
    "RAG_obj = RAG()\n",
    "query = \"Who are the robed people Mr. Dursley sees in the streets?\"\n",
    "# Get the prediction from the RAG model for the given question.\n",
    "# This prediction includes both the context and the answer.\n",
    "predict_response = RAG_obj(query)\n",
    "\n",
    "# Print the question, predicted answer, and truncated retrieved contexts.\n",
    "print(f\"Question: {query}\")\n",
    "print(f\"\\n\\nPredicted Answer: {predict_response.answer}\")\n",
    "print(f\"\\n\\nRetrieved Contexts (truncated): {[c[:200] + '...' for c in predict_response.context]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7072e4fd",
   "metadata": {},
   "source": [
    "Improve the DSPy RAG class, maybe add more hops?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6469c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.dsp.utils import deduplicate\n",
    "\n",
    "# Define a class named GenerateSearchQuery which inherits from dspy.Signature\n",
    "class GenerateSearchQuery(dspy.Signature):\n",
    "    \"\"\"Write a better search query that will help answer a complex question.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    query = dspy.OutputField()\n",
    "\n",
    "class MultiHopRAG(dspy.Module):\n",
    "    def __init__(self, max_hops=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.generate_query = [dspy.ChainOfThought(GenerateSearchQuery) for _ in range(max_hops)]\n",
    "        self.retrieve = dspy.Retrieve()\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "        self.max_hops = max_hops\n",
    "\n",
    "    def forward(self, question):\n",
    "        context = []\n",
    "\n",
    "        for hop in range(self.max_hops):\n",
    "            query = self.generate_query[hop](context=context, question=question).query\n",
    "            passages = self.retrieve(query).passages\n",
    "            context = deduplicate(context + passages)\n",
    "\n",
    "        pred = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=pred.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "10f75fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_obj = MultiHopRAG()\n",
    "\n",
    "# Get the prediction from the RAG model for the given question.\n",
    "# This prediction includes both the context and the answer.\n",
    "predict_response = RAG_obj(query)\n",
    "\n",
    "# Print the question, predicted answer, and truncated retrieved contexts.\n",
    "print(f\"\\n\\nPredicted Answer: {predict_response.answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "789f4d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.inspect_history(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d0d396",
   "metadata": {},
   "source": [
    "### 2.7 (Optional) Using Pinecone, an online vector DB \n",
    "\n",
    "You have many reasons to store your DB online in a SaaS / PaaS service.  For example, \n",
    "- you want to scale the queries to many concurrent users\n",
    "- you want more data reliability without having to worry about DB management\n",
    "- you want to share the DB but without owning any servers\n",
    "\n",
    "If you want to store your embeddings online, try pinecone with the code below. You must go to [Pinecone.io](https://www.pinecone.io/) and set up an account. Then you need to generate an api-key and create an \"index\", this can be done by navigating through the homepage once you've logged in to Pinecone, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "94c7ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need the following code to access OpenAI API or SerpAPI.\n",
    "# os.environ['HTTP_PROXY']=\"http://Clash:QOAF8Rmd@10.1.0.213:7890\"\n",
    "# os.environ['HTTPS_PROXY']=\"http://Clash:QOAF8Rmd@10.1.0.213:7890\"\n",
    "# os.environ['ALL_PROXY']=\"socks5://Clash:QOAF8Rmd@10.1.0.213:7893\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0b75f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "PINECONE_API_KEY = os.environ['PINECONE_API_KEY']\n",
    "PINECONE_INDEX_NAME = os.environ['PINECONE_INDEX_NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f04c5597",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = PINECONE_INDEX_NAME\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "if index_name in existing_indexes:\n",
    "    pc.delete_index(index_name)\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=1024,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    ")\n",
    "    \n",
    "docsearch_pinecone = PineconeVectorStore.from_texts(\n",
    "    [t.page_content for t in texts], baai_embedding, index_name=index_name, namespace=\"harry-potter\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba00d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=CHAT_MODEL)\n",
    "query = '''Who might \"You-Know-Who\" be? Why isn't this person referred to by a given name?'''\n",
    "\n",
    "print_search_results(docsearch_pinecone.similarity_search(query))\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm, chain_type=\"stuff\", verbose=True, retriever=docsearch_pinecone.as_retriever(k=5)\n",
    ")\n",
    "chain.invoke(query)\n",
    "\n",
    "# we can use the full-book to test 'map-reduce', try it !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7453fd84-ba39-4f2b-ab23-23b94d45d727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query with pinecone\n",
    "docs = docsearch_pinecone.similarity_search(query)\n",
    "print_search_results(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c1053e7a-3c56-44d2-9d87-1b08f624dc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Your Task ####\n",
    "# modify the QA chain in Section 2.5 (Chapter 1 only) to use pinecone instead of ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cc6131-6a1a-40f5-8af0-afc5c723e49e",
   "metadata": {},
   "source": [
    "### 2.7 (Optional) Use multiple vector stores in Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1053e7a-3c56-44d2-9d87-1b08f624dc53",
   "metadata": {},
   "source": [
    "In this section, we are going to create a simple QA agent that can decide by itself which of the two vectorstores it should switch to for questions of differnent fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83b4118-4e34-4d3d-8230-a13bf77daa59",
   "metadata": {},
   "source": [
    "#### Preparing the tools for the agent.\n",
    "\n",
    "We will use our chroma_based Harry Potter vectorDB, and let's create another one containing President Biden's State of the Union speech. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "949662aa-5044-4899-ba50-5e06ac7df371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "documents = TextLoader('/ssdshare/share/lab4/state_of_the_union.txt').load()\n",
    "texts = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0).split_documents(documents)\n",
    "docsearch3 = Chroma.from_documents(texts, \n",
    "                                   baai_embedding, \n",
    "                                   collection_name=\"state-of-union\", \n",
    "                                   persist_directory=\"/scratch1/chroma_db\")\n",
    "print(texts[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83b4118-4e34-4d3d-8230-a13bf77daa59",
   "metadata": {},
   "source": [
    "To allow the agent query these databases, we need to define two RetrievalQA chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ccd41e19-fcff-4358-9374-2b36b29d1017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=CHAT_MODEL)\n",
    "\n",
    "harry_potter = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                           chain_type=\"stuff\", \n",
    "                                           retriever=docsearch_chroma_reloaded.as_retriever(\n",
    "                                                  search_kwargs={\"k\": 8}\n",
    "                                           ))\n",
    "state_of_union = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                             chain_type=\"stuff\", \n",
    "                                             retriever=docsearch3.as_retriever(\n",
    "                                                    search_kwargs={\"k\": 8}\n",
    "                                             ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dbe451ef-4137-4b86-9254-4117c6802b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try both chains\n",
    "\n",
    "print_with_type(harry_potter.invoke('Why does McGonagall seem concerned about Harry being raised by the Dursleys?'))\n",
    "print_with_type(state_of_union.invoke(\"What did the president say about justice Breyer?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "73957e1e-f3e2-48e6-91db-d669d5cbe3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, Tool\n",
    "\n",
    "# define tools\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"State of Union QA System\",\n",
    "        func=state_of_union.run,\n",
    "        description=\"useful for when you need to answer questions about the most recent state of the union address. Input should be a fully formed question.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Harry Potter QA System\",\n",
    "        func=harry_potter.run,\n",
    "        description=\"useful for when you need to answer questions about Harry Potter. Input should be a fully formed question.\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe451ef-4137-4b86-9254-4117c6802b6a",
   "metadata": {},
   "source": [
    "Now we can create the Agent giving both chains as tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "11b068ff-d822-44ec-ba63-c47f49b492e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=CHAT_MODEL,\n",
    ")\n",
    "agent = create_react_agent(\n",
    "    llm,\n",
    "    tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=tools, verbose=True, memory=ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b85245e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you find the agent is stuck, you can try other more powerful model, like DeepSeek\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"What did the president say about justice Breyer?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "497fde49",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"Why does McGonagall seem concerned about Harry being raised by the Dursleys?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85245e2",
   "metadata": {},
   "source": [
    "We can see that the agent can \"smartly\" choose which QA system to use given a specific question. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497fde49",
   "metadata": {},
   "source": [
    "## 3 Your Task: putting it all together: Langchain with Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "09e6d104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is LLM-Compiler's main trick to speed up multi-tool workflows?\n",
      " A: \n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "LLM-Compiler speeds up multi-tool workflows by **reusing intermediate results** from previous tool calls, reducing\n",
      "redundant computations. It employs a **caching mechanism** to store and retrieve outputs of recurring sub-tasks,\n",
      "optimizing efficiency across workflows. This is particularly useful when the same tool or sub-task is invoked multiple\n",
      "times with similar inputs. (No page number provided in the context.)\n",
      "Q: How does the paper handle variable-length tool outputs?\n",
      " A: \n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The paper addresses variable-length tool outputs by using a truncation strategy to fit them within fixed-length input\n",
      "slots (Section 3.3). Outputs exceeding the limit are truncated, and critical tokens (e.g., closing tags) are prioritized\n",
      "to preserve structure (p. 6). References are provided if applicable. Let me know if you need further details.\n",
      "(Assuming hypothetical context—replace page numbers/sections with specifics from your source if available.)\n",
      "Q: Does LLM-Compiler need fine-tuning or is it prompting-only?\n",
      " A: \n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "LLM-Compiler does not require fine-tuning; it operates purely through **prompting** (p. 4). It leverages predefined\n",
      "prompts to guide code generation and optimization without task-specific training. This approach ensures generalization\n",
      "across compiler tasks while avoiding the computational cost of fine-tuning.    (Source: *LLM-Compiler* paper, p. 4)\n",
      "(Word count: 50)\n"
     ]
    }
   ],
   "source": [
    "#### Your Task ####\n",
    "# This is a major task that requires some thinking and time. \n",
    "# Build a conversation system from a collection of research papers of your choice. \n",
    "# You can ask specific questions of a method about these papers, and the agent returns a brief answer to you (with no more than 100 words). \n",
    "# Save your data and ChromaDB in the /ssdshare/llm-course/<YOUR-NAME> directory so other people can use it. \n",
    "# Provide at least three query examples so the TAs can review your work. \n",
    "# You may use any tool from the past four labs or from the langchain docs, or any open source project. \n",
    "# write a summary (a Markdown cell) at the end of the notebook summarizing what works and what does not. \n",
    "\n",
    "####  LOAD & CHUNK  ####\n",
    "import textwrap\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "loader  = PyPDFLoader(\"/ssdshare/llm-course/ZhangBin/ASurveyofLargeLanguageModels.pdf\")\n",
    "pages   = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=80)\n",
    "chunks   = splitter.split_documents(pages)\n",
    "\n",
    "####  VECTOR STORE  ####\n",
    "embedding = OpenAIEmbeddings(\n",
    "    model=\"Qwen/Qwen3-Embedding-8B\",\n",
    "    base_url=os.environ.get(\"SF_BASE_URL\"),\n",
    "    api_key=os.environ.get(\"SF_API_KEY\"),\n",
    ")\n",
    "my_chroma_dir = \"/ssdshare/llm-course/ZhangBin/chroma_db\"\n",
    "vectordb = Chroma(\n",
    "    embedding_function=embedding,\n",
    "    persist_directory=chroma_dir,\n",
    "    collection_name=\"research_papers\",\n",
    ")\n",
    "\n",
    "#### QA CHAIN  ####\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=(\n",
    "        \"You are a concise research assistant. \"\n",
    "        \"Answer in ≤100 words and cite the page number if possible.\\n\\n\"\n",
    "        \"Context: {context}\\n\\n\"\n",
    "        \"Question: {question}\\nAnswer:\"\n",
    "    )\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"deepseek-v3\", temperature=0)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    verbose=True,\n",
    "    retriever=vectordb.as_retriever(k=5),\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")\n",
    "def ask_and_answer(question: str):\n",
    "    print(\"Q: \" + question + \"\\n A: \")\n",
    "    res = qa_chain.invoke(question)\n",
    "    print(textwrap.fill(res[\"result\"], width=120))\n",
    "\n",
    "ask_and_answer(\"What is LLM-Compiler's main trick to speed up multi-tool workflows?\")\n",
    "ask_and_answer(\"How does the paper handle variable-length tool outputs?\")\n",
    "ask_and_answer(\"Does LLM-Compiler need fine-tuning or is it prompting-only?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0d4f41",
   "metadata": {},
   "source": [
    "以上工作是将一篇论文pdf载入，切片后存入chroma，并对与论文的相关问题进行回答。\n",
    "没有实现但是有意义的功能可能包括：对回答给出对应论文段落的页码数，通过互联网搜索给出扩展参考文献"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
